{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4e0a6-1ef0-4b29-85cb-0151b8e528db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "\n",
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'fact'\n",
    "\n",
    "evaluator = get_evaluator(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe71618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def convert_to_json(output_list, src_list=None, ref_list=None, context_list=None, \\\n",
    "            scores=None, doc_id=None, system_id=None):\n",
    "    \"\"\"\n",
    "        Convert the data into the json format.\n",
    "\n",
    "        output_list: a list of model output\n",
    "        src_list: source input for different NLG tasks. For example, source document for summarization\n",
    "                  and dialogue history for dialogue response generation\n",
    "        ref_list: human-annotated groundtruth\n",
    "        context_list: the context needed to evaluate several specific dimension. For example,\n",
    "                      additional factual information when evaluating engagingness and groundedness in dialogues\n",
    "        scores: human scores for evaluating the model output. They can be used to calculate the correlation\n",
    "                between evaluators and human judgements. The scores should be stored in a dictionary. For example,\n",
    "                {'fluency': 2.0, 'coherence': 3.0} could be the human score for a sample.\n",
    "        doc_id: the index of the input source. It can be used to calculate summary-level correlation for summarzation\n",
    "        system_id: the index of the generation system. It can be used to calculate system-level correlation.\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    for i in range(len(output_list)):\n",
    "        cur = {}\n",
    "        cur['system_output'] = output_list[i]\n",
    "        if src_list is not None:\n",
    "            cur['source'] = src_list[i]\n",
    "        if ref_list is not None:\n",
    "            cur['reference'] = ref_list[i]\n",
    "        if context_list is not None:\n",
    "            cur['context'] = context_list[i]\n",
    "        if scores is not None:\n",
    "            cur['scores'] = scores[i]\n",
    "        if doc_id is not None:\n",
    "            cur['doc_id'] = doc_id[i]\n",
    "        if system_id is not None:\n",
    "            cur['system_id'] = system_id[i]\n",
    "        json_data.append(cur)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def add_question(dimension, output, src=None, ref=None, context=None, task=None):\n",
    "    \"\"\"\n",
    "        Add questions to generate input in Bool-QA format for UniEval.\n",
    "\n",
    "        dimension: specific dimension to be evaluated\n",
    "        src: source input for different NLG tasks. For example, source document for summarization\n",
    "             and dialogue history for dialogue response generation.\n",
    "        output: output text generated by the models\n",
    "        ref: human-annotataed groundtruth\n",
    "        context: the context needed to evaluate several specific dimension. For example,\n",
    "                 additional factual information when evaluating engagingness and groundedness in dialogues.\n",
    "    \"\"\"\n",
    "\n",
    "    input_with_question = []\n",
    "    for i in range(len(output)):\n",
    "        # For summarization\n",
    "        if task == 'summarization':\n",
    "            if dimension == 'fluency':\n",
    "                cur_input = 'question: Is this a fluent paragraph? </s> paragraph: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent summary to the document? </s> summary: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'relevance':\n",
    "                cur_input = 'question: Is this summary relevant to the reference? </s> summary: ' + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For dialogues\n",
    "        elif task == 'dialogue':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a natural response in the dialogue? </s> response: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent response given the dialogue history? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i]\n",
    "            elif dimension == 'engagingness':\n",
    "                cur_input = 'question: Is this an engaging and informative response according to the dialogue history and fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'groundedness':\n",
    "                cur_input = 'question: Is this response consistent with knowledge in the fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'understandability':\n",
    "                cur_input = 'question: Is this an understandable response in the dialogue? </s> response: ' + output[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For data-to-text\n",
    "        elif task == 'data2text':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a fluent utterance? </s> utterance: ' + output[i]\n",
    "            elif dimension == 'informativeness':\n",
    "                cur_input = 'question: Is this sentence informative according to the reference? </s> sentence: '\\\n",
    "                            + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For factual consistency detection\n",
    "        elif task == 'fact':\n",
    "            if dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            else:\n",
    "                raise NotImplementedError('No other dimensions for the factual consistency detection task.')\n",
    "        # For new customized tasks\n",
    "        else:\n",
    "            raise NotImplementedError('Other tasks are not implemented, please customize specific tasks here.')\n",
    "        input_with_question.append(cur_input)\n",
    "    return input_with_question\n",
    "\n",
    "\n",
    "def print_scores(scores):\n",
    "    table = PrettyTable(['Dimensions','Score'])\n",
    "    print('\\nEvaluation scores are shown below:')\n",
    "    dims = list(scores[0].keys())\n",
    "    for dim in dims:\n",
    "        cur_score = 0\n",
    "        for i in range(len(scores)):\n",
    "            cur_score += scores[i][dim]\n",
    "        table.add_row([dim, round(cur_score / len(scores), 6)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f30faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from scorer import UniEvaluator  # Make sure this import works after placing scorer.py in the same directory\n",
    "\n",
    "def evaluate(data, dims=None, overall=True, print_result=False, model_name_or_path=\"t5-small\", task='summarization', device='cuda:0', individual=True):\n",
    "    \"\"\"\n",
    "    Get the scores of all the given dimensions (fluency, consistency, coherence, relevance)\n",
    "\n",
    "    data: A list of dictionaries, where each dictionary contains:\n",
    "          - 'source': The original text\n",
    "          - 'system_output': The generated system output (summary)\n",
    "          - 'reference' (optional): Reference summary for relevance evaluation\n",
    "\n",
    "    dims: A list of dimensions to be evaluated. If dims is None, it evaluates four default dimensions:\n",
    "          coherence, consistency, fluency, relevance.\n",
    "\n",
    "    overall: Boolean to indicate whether the overall score is calculated as the average of all dimensions.\n",
    "\n",
    "    print_result: Boolean to print the results on the screen.\n",
    "\n",
    "    model_name_or_path: The model name or path to use for evaluation, e.g., 't5-small'\n",
    "\n",
    "    task: The task type (used in scoring if needed, like summarization or other NLP tasks).\n",
    "\n",
    "    device: The device to use for evaluation ('cpu' or 'cuda:0').\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the scorer\n",
    "    scorer = UniEvaluator(model_name_or_path=model_name_or_path, device=device)\n",
    "\n",
    "    n_data = len(data)\n",
    "    eval_scores = [{} for _ in range(n_data)]\n",
    "\n",
    "    # Default dimensions if not provided\n",
    "    if dims is None:\n",
    "        dims = ['coherence', 'consistency', 'fluency', 'factual consistency']   #add relevance\n",
    "\n",
    "    for dim in dims:\n",
    "        print(f'Evaluating {dim} of {n_data} samples !!!')\n",
    "\n",
    "        if dim == 'consistency' or dim == 'fluency':\n",
    "            # Sentence-level scores for consistency and fluency\n",
    "            src_list, output_list = [], []\n",
    "            n_sents = []  # number of sentences in each summary\n",
    "\n",
    "            for i in range(n_data):\n",
    "                if dim == 'consistency':\n",
    "                    source = data[i]['source']\n",
    "                else:\n",
    "                    source = ''\n",
    "                system_outputs = sent_tokenize(data[i]['system_output'])\n",
    "                n_sents.append(len(system_outputs))\n",
    "                for j in range(len(system_outputs)):\n",
    "                    src_list.append(source)\n",
    "                    output_list.append(system_outputs[j])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, task=task)\n",
    "            sent_score = scorer.score(input_list)\n",
    "\n",
    "            # Calculate average sentence-level scores for each sample\n",
    "            start_idx = 0\n",
    "            score = []\n",
    "            for cur_n_sent in n_sents:\n",
    "                score.append(sum(sent_score[start_idx:start_idx + cur_n_sent]) / cur_n_sent)\n",
    "                start_idx += cur_n_sent\n",
    "\n",
    "        elif dim == 'coherence' or dim == 'relevance':\n",
    "            # Summary-level scores for coherence and relevance\n",
    "            src_list, output_list, ref_list = [], [], []\n",
    "\n",
    "            for i in range(n_data):\n",
    "                src_list.append(data[i]['source'])\n",
    "                output_list.append(data[i]['system_output'])\n",
    "                if dim == 'relevance':\n",
    "                    ref_list.append(data[i]['reference'])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, ref=ref_list, task=task)\n",
    "            score = scorer.score(input_list)\n",
    "\n",
    "        elif dim == 'factual consistency':\n",
    "            output_list, src_list = [], []\n",
    "\n",
    "            for i in range(n_data):\n",
    "                src_list.append(data[i]['source'])\n",
    "                output_list.append(data[i]['system_output'])\n",
    "\n",
    "            data = convert_to_json(output_list=output_list, src_list=src_list)\n",
    "            eval_score = evaluator.evaluate(data)\n",
    "            score = []\n",
    "\n",
    "            for i in eval_score:\n",
    "                temp = i['consistency']\n",
    "                score.append(temp)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"The input format for the dimension '{dim}' is still undefined. Please customize it.\")\n",
    "\n",
    "        # Store the scores for the current dimension\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i][dim] = score[i]\n",
    "\n",
    "    # Calculate overall score (average of all evaluated dimensions)\n",
    "    if overall:\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i]['overall'] = np.mean([eval_scores[i][dim] for dim in dims])\n",
    "\n",
    "    # Print the result if requested\n",
    "    if print_result:\n",
    "        print_scores(eval_scores)\n",
    "\n",
    "    if individual:\n",
    "        individual_scores = []\n",
    "        for i in range(n_data):\n",
    "            temp = [eval_scores[i][dim] for dim in dims]\n",
    "            individual_scores.append(temp)\n",
    "\n",
    "        return np.array(individual_scores)\n",
    "\n",
    "    # Calculate average score across all the dimensions except 'overall'\n",
    "    avg_score = []\n",
    "    for i in range(n_data):\n",
    "        # Exclude 'overall' from the averaging\n",
    "        dimensions = [dim for dim in dims if dim != 'overall']\n",
    "        avg_score.append(np.mean([eval_scores[i][dim] for dim in dimensions]))\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32ca14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Import all required libraries\n",
    "# import torch\n",
    "# import transformers\n",
    "# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments\n",
    "# from trl import RewardTrainer, PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "# from datasets import Dataset\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "# import bitsandbytes as bnb\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import sys\n",
    "\n",
    "# # Add UniEval to path and import\n",
    "# sys.path.append(r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "# from utils import convert_to_json\n",
    "# from metric.evaluator import get_evaluator\n",
    "\n",
    "# # Configuration\n",
    "# DATA_PATH = \"combined_clinical_notes.csv\"\n",
    "# # MODEL_PATH = r\"D:\\kshitij-weights-folder\\qwen-aloe-9-4-base-fine-tune\"\n",
    "# MODEL_PATH = \"gpt2\" \n",
    "# # PEFT_ADAPTER_PATH = r\"D:\\kshitij-weights-folder\\qwen-aloe-9-4-base-fine-tune-peft-adapaters\"\n",
    "# MEDICAL_PROMPT = \"\\nGenerate a concise medical summary focusing on key findings and treatment plans:\"\n",
    "\n",
    "# # Load and prepare data\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "# train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "# eval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "# dataset = Dataset.from_pandas(eval_df.rename(columns={\"dialogue\": \"review\"}))\n",
    "\n",
    "# # Tokenizer setup\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # Dataset preprocessing\n",
    "# def preprocess_function(examples):\n",
    "#     return {\n",
    "#         \"input_ids\": tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512),\n",
    "#         \"query\": tokenizer.decode(tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512), skip_special_tokens=True)\n",
    "#     }\n",
    "\n",
    "# dataset = dataset.map(preprocess_function, batched=False)\n",
    "# dataset.set_format(\"pytorch\")\n",
    "\n",
    "# # Model configuration\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "# )\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_PATH,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "# base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# # PEFT/LoRA configuration\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias=\"none\",\n",
    "#     target_modules=[\"c_attn\", \"c_proj\"],\n",
    "# )\n",
    "\n",
    "# # model_with_lora = get_peft_model(base_model, lora_config)\n",
    "# model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model, peft_config=lora_config).to(\"cuda\")\n",
    "\n",
    "# # Reference model\n",
    "# ref_model = create_reference_model(model).to(\"cuda\")\n",
    "# ref_model.eval()\n",
    "# for param in ref_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# NUM_CANDIDATES = 2\n",
    "\n",
    "# # PPO Configuration\n",
    "# ppo_config = PPOConfig(\n",
    "#     model_name=MODEL_PATH,\n",
    "#     ppo_epochs=1,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     steps=5,\n",
    "#     batch_size=1*NUM_CANDIDATES,\n",
    "#     mini_batch_size=1*NUM_CANDIDATES,\n",
    "#     learning_rate=2e-5,\n",
    "#     log_with=None,\n",
    "#     # project_kwargs={\"logging_dir\": r\"D:\\kshitij-weights-folder\\gpt2-rl-logs\"}\n",
    "# )\n",
    "\n",
    "# # optimizer = torch.optim.AdamW(\n",
    "# #     filter(lambda p: p.requires_grad, ppo_model.parameters()),\n",
    "# #     lr=2e-5,\n",
    "# #     eps=1e-5,  # Slightly larger epsilon for stability\n",
    "# # )\n",
    "\n",
    "# # Initialize PPO Trainer\n",
    "# ppo_trainer = PPOTrainer(\n",
    "#     config=ppo_config,\n",
    "#     model=model,\n",
    "#     ref_model=ref_model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     dataset=dataset,\n",
    "#     optimizer=bnb.optim.Adam8bit(model.parameters(), lr=ppo_config.learning_rate)\n",
    "# )\n",
    "\n",
    "# # Evaluation setup\n",
    "# # sum_eval = get_evaluator(\"summarization\", \"cuda\"=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def get_score(src, res):\n",
    "#     # weights = np.array([0.1, 0.2, 0.3, 0.4])  # coherence, consistency, fluency, factual consistency\n",
    "#     # sample_data = [{\"source\": q, \"system_output\": r} for q, r in zip(game_data[\"query\"], game_data[\"response\"])]\n",
    "    \n",
    "#     # scores = sum_eval.evaluate(sample_data, overall=False)\n",
    "#     # scores = evaluate(sample_data, overall=False)\n",
    "#     # weighted_scores = []\n",
    "    \n",
    "#     # for dimension_scores in scores:\n",
    "#     #     adjusted = np.where(\n",
    "#     #         dimension_scores < 0.5,\n",
    "#     #         -dimension_scores * weights,\n",
    "#     #         dimension_scores * weights\n",
    "#     #     )\n",
    "#     #     weighted_scores.append(torch.tensor(np.sum(adjusted)/4, dtype=torch.float32).to(model.pretrained_model.device))\n",
    "    \n",
    "#     # return weighted_scores\n",
    "\n",
    "#     data = convert_to_json(\n",
    "#         output_list=res,\n",
    "#         src_list=src,\n",
    "#     )\n",
    "#     # raw = sum_eval.evaluate(data, print_result=True)\n",
    "#     # dims = ['coherence', 'consistency', 'fluency', 'factual consistency']\n",
    "#     raw = evaluate(data, overall=False)\n",
    "#     score = [\n",
    "#         [d[0], d[1], d[2], d[3]]\n",
    "#         for d in raw\n",
    "#     ]\n",
    "#     scores = torch.tensor(score, dtype=torch.float32).numpy()  # CPU (B,4\n",
    "\n",
    "#     k = len(res)\n",
    "#     dom_counts = np.zeros(k)\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         for j in range(k):\n",
    "#             if i == j:\n",
    "#                 continue\n",
    "#             # Check dominance: i dominates j if all scores are >= and at least one is >\n",
    "#             if np.all(scores[i] >= scores[j]) and np.any(scores[i] > scores[j]):\n",
    "#                 dom_counts[i] += 1\n",
    "    \n",
    "#     # Convert to [-1, 1] range reward\n",
    "#     max_dom = k - 1\n",
    "#     if max_dom > 0:\n",
    "#         rewards = 2 * (dom_counts / max_dom) - 1\n",
    "#     else:\n",
    "#         rewards = np.zeros(k)\n",
    "    \n",
    "#     return rewards\n",
    "\n",
    "\n",
    "# max_position_embeddings = model.pretrained_model.config.max_position_embeddings \n",
    "# # Training loop\n",
    "# generation_kwargs = {\n",
    "#     \"min_length\": -1,\n",
    "#     \"top_k\": 0.0,\n",
    "#     \"top_p\": 1.0,\n",
    "#     \"do_sample\": True,\n",
    "#     \"pad_token_id\": tokenizer.eos_token_id,\n",
    "#     # \"max_new_tokens\": 64,  # Increased for better summary generation\n",
    "#     \"eos_token_id\": -1,\n",
    "#     \"max_length\": max_position_embeddings,\n",
    "#     \"max_new_tokens\": 64\n",
    "# }\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Use consistent compute dtype\n",
    "# COMPUTE_DTYPE = torch.float32  # Using float32 to avoid dtype issues\n",
    "\n",
    "# for epoch in range(1):\n",
    "#     for batch_idx, batch in enumerate(tqdm(ppo_trainer.dataloader)):\n",
    "#         (logs, game_data,) = (\n",
    "#             dict(),\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         # task_list = choices(ctrl_str, k=config.batch_size)\n",
    "#         # game_data[\"query\"] = [t + q for t, q in zip(task_list, batch[\"query\"])]\n",
    "#         game_data[\"query\"] = [q for q in batch[\"query\"]]\n",
    "#         # query_tensors = [torch.cat((ctrl_tokens[t], input_ids)) for t, input_ids in zip(task_list, batch[\"input_ids\"])]\n",
    "#         query_tensors = [input_ids for input_ids in batch[\"input_ids\"]]\n",
    "#         all_outs = []\n",
    "        \n",
    "#         response_tensors = []\n",
    "#         for query in query_tensors:\n",
    "#             for _ in range(NUM_CANDIDATES):\n",
    "#                 original_notes = tokenizer.decode(query)\n",
    "                \n",
    "#                 # Combine with medical prompt only during generation\n",
    "#                 full_prompt = f\"{MEDICAL_PROMPT}{original_notes}\" #TRy with full prompt here\n",
    "#                 full_prompt_tensor = tokenizer.encode(full_prompt, return_tensors=\"pt\").to(\"cuda\").squeeze(0)\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     response = ppo_trainer.generate(\n",
    "#                         full_prompt_tensor,\n",
    "#                         **generation_kwargs\n",
    "#                     )\n",
    "#                 # Ensure response doesn't exceed max length\n",
    "#                 response = response[:, :generation_kwargs[\"max_new_tokens\"]]\n",
    "#                 all_outs.append(response)\n",
    "#                 response_tensors.append(response.squeeze())\n",
    "\n",
    "#             outs = torch.stack(all_outs, dim=1)\n",
    "#             B, K, _ = outs.shape\n",
    "            \n",
    "#             # Decode outputs for evaluation\n",
    "#             hyps = []\n",
    "#             for b in range(B):\n",
    "#                 hyps_b = []\n",
    "#                 for k in range(K):\n",
    "#                     try:\n",
    "#                         text = tokenizer.decode(outs[b, k], skip_special_tokens=True)\n",
    "#                         hyps_b.append(text)\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error decoding text: {e}\")\n",
    "#                         hyps_b.append(\"\")  # Add empty string as fallback\n",
    "#                 hyps.append(hyps_b)\n",
    "\n",
    "#             # rewards = []\n",
    "#             # for b in range(len(batch['input_ids'])):\n",
    "#             #     # Get scores for all candidates (K, 4)\n",
    "#             #     scores = get_score(\n",
    "#             #         batch['query'][b] * NUM_CANDIDATES,\n",
    "#             #         hyps[b]\n",
    "#             #     ).numpy()\n",
    "\n",
    "#             #     print(\"check\")\n",
    "\n",
    "#             #     dom_counts = np.zeros(NUM_CANDIDATES)\n",
    "#             #     for i in range(NUM_CANDIDATES):\n",
    "#             #         for j in range(NUM_CANDIDATES):\n",
    "#             #             if i == j:\n",
    "#             #                 continue\n",
    "#             #             # Check if i dominates j\n",
    "#             #             if np.all(scores[i] >= scores[j]) and np.any(scores[i] > scores[j]):\n",
    "#             #                 dom_counts[i] += 1\n",
    "\n",
    "#             #     max_dom = NUM_CANDIDATES - 1\n",
    "#             #     scalar_rewards = 2 * (dom_counts / max_dom) - 1\n",
    "#             #     rewards.append(scalar_rewards)\n",
    "\n",
    "#             # flat_queries = []\n",
    "#             # flat_responses = []\n",
    "#             # flat_rewards = []\n",
    "\n",
    "#             # for b in range(len(batch['input_ids'])):\n",
    "#             #     for k in range(NUM_CANDIDATES):\n",
    "#             #         flat_queries.append(batch['input_ids'][b])\n",
    "#             #         flat_responses.append(outs[b, k])\n",
    "#             #         flat_rewards.append(torch.tensor([rewards[b][k]], device=\"cuda\"))\n",
    "\n",
    "#             # stats = ppo_trainer.step(\n",
    "#             #     queries   = flat_queries,    # e.g. [ q0, q0 ]\n",
    "#             #     responses = flat_responses,  # e.g. [ r0, r1 ]\n",
    "#             #     scores    = flat_rewards     # e.g. [ s0, s1 ]\n",
    "#             # )\n",
    "\n",
    "#             flat_queries, flat_responses, flat_rewards = [], [], []\n",
    "                    \n",
    "#             for b in range(B):\n",
    "#                 try:\n",
    "#                     # Calculate rewards\n",
    "#                     rewards_b = get_score(\n",
    "#                         [batch['query'][b]] * K, \n",
    "#                         hyps[b],\n",
    "#                     )\n",
    "                    \n",
    "#                     # Flatten for PPO\n",
    "#                     for k in range(K):\n",
    "#                         flat_queries.append(batch['input_ids'][b])\n",
    "#                         flat_responses.append(outs[b, k])\n",
    "#                         flat_rewards.append(torch.tensor([rewards_b[k]], device=DEVICE, dtype=COMPUTE_DTYPE))\n",
    "                        \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error computing rewards: {e}\")\n",
    "#                     continue\n",
    "            \n",
    "#             # Safety check\n",
    "#             if len(flat_queries) != ppo_config.batch_size:\n",
    "#                 print(f\"Batch size mismatch: expected {ppo_config.batch_size}, got {len(flat_queries)}\")\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 # Verify shapes match\n",
    "#                 print(f\"Queries: {len(flat_queries)}, Responses: {len(flat_responses)}, Rewards: {len(flat_rewards)}\")\n",
    "                \n",
    "#                 # Manual memory management\n",
    "#                 # torch.cuda.empty_cache()\n",
    "                \n",
    "#                 # Do PPO step\n",
    "#                 stats = ppo_trainer.step(\n",
    "#                     queries=flat_queries,\n",
    "#                     responses=flat_responses,\n",
    "#                     scores=flat_rewards\n",
    "#                 )\n",
    "                \n",
    "#                 # Success! Log the output\n",
    "#                 print(f\"Batch {batch_idx} PPO step successful!\")\n",
    "#                 print(f\"Sample output: {hyps[0][0][:100]}...\")\n",
    "#                 avg_reward = np.mean([r.item() for r in flat_rewards])\n",
    "#                 print(f\"Average reward: {avg_reward:.4f}\")\n",
    "                \n",
    "#             except RuntimeError as e:\n",
    "#                 print(f\"Error in PPO step: {e}\")\n",
    "                \n",
    "#                 # If still running into CUDA errors, try moving to CPU\n",
    "#                 if \"CUDA\" in str(e) and DEVICE != \"cpu\":\n",
    "#                     print(\"\\nContinuing to encounter CUDA errors. Try two options:\")\n",
    "#                     print(\"1. Change DEVICE = 'cpu' at the top of the script\")\n",
    "#                     print(\"2. Or use the non-quantized model version\\n\")\n",
    "                    \n",
    "#                 # Clear memory and continue\n",
    "#                 # if torch.cuda.is_available():\n",
    "#                 #     torch.cuda.empty_cache()\n",
    "            \n",
    "#             # if batch_idx % 10 == 0:\n",
    "#             #     print(f\"Epoch {epoch+1}, Batch {batch_idx}\")\n",
    "#             #     print(f\"Sample output: {hyps[0][0][:100]}...\")\n",
    "#             #     print(f\"Average reward: {np.mean([r.item() for r in flat_rewards]):.4f}\")\n",
    "\n",
    "#     print(f\"✅ Epoch {epoch+1}/3 complete\")\n",
    "    \n",
    "# print(\"🎉 PPO fine-tuning done\")\n",
    "# #         print(response_tensors)\n",
    "#         # game_data[\"response\"] = [tokenizer.decode(r) for r in response_tensors]\n",
    "\n",
    "#         # print(\"check\")\n",
    "\n",
    "#         # texts = [q + r for q, r in zip(batch[\"query\"], game_data[\"response\"])]\n",
    "#         # logits = get_score(game_data)\n",
    "#         # rewards = logits\n",
    "#         # rewards = pos_logit_to_reward(logits, task_list)\n",
    "#         # rewards = [torch.tensor([1.0], device=query_tensors[0].device) for _ in range(len(texts))]\n",
    "\n",
    "#         #### Run PPO trainings\n",
    "#         # t = time.time()\n",
    "#         # stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcd9dff-d691-4cde-90e5-6fc17244d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading extraction model from bigscience/bloomz-1b7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████████████| 93/93 [00:00<00:00, 143.58 examples/s]\n",
      "WARNING:root:The `device_map` argument is not provided. We will override the device_map argument. to set the entire model on the current device. If you want to set the model on multiple devices, please provide a custom `device_map` argument.\n",
      "  0%|                                                                                 | 0/46 [00:00<?, ?it/s]C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 0 in batch 0 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her symptoms and duration....\n",
      "Sample output: In cases of a woman with bipolar disorder who has never been treated with any sort of medication, sh...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 1 in batch 0 - PPO step successful!\n",
      "Extracted Info: Patient is a 60 year old, right-handed male, referred today for evaluation of numbness and tingling....\n",
      "Sample output: 1. This is a very important and very important issue.\n",
      "\n",
      "2. Patients are suffering at the...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                       | 1/46 [00:25<19:10, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 1 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking medications for his foot pain....\n",
      "Sample output: You can read the medical summary at the beginning of your medical summary.\n",
      "\n",
      "You can read the medical...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                     | 2/46 [00:53<19:49, 27.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 1 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient's knee....\n",
      "Sample output: I'm so glad to see you've read this.\n",
      "\n",
      "I can't believe this.\n",
      "\n",
      "I'm so glad to hear that.\n",
      "\n",
      "I can't beli...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 2 - PPO step successful!\n",
      "Extracted Info: The patient is a 31-year-old female with a history of diabetes and asthma....\n",
      "Sample output: Key:\n",
      "\n",
      "The patient is a young male with an asthma history of diabetes and asthma.\n",
      "\n",
      "The patient is a m...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▊                                                                    | 3/46 [01:20<19:09, 26.74s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 2 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: What is the key to this?\n",
      "\n",
      "Why did you say this?\n",
      "\n",
      "When did you say this?\n",
      "\n",
      "\n",
      "What is the key?\n",
      "\n",
      "WHAT is ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.43s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 3 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: KEY DESCRIPTION:\n",
      "\n",
      "\"You should have a concise medical summary.\n",
      "\"A medical summary of a medical and he...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.38s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▎                                                                  | 4/46 [01:48<19:13, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 3 - PPO step successful!\n",
      "Extracted Info: Michael is seeing a doctor for back pain....\n",
      "Sample output: I have a back pain.\n",
      "\n",
      "Your pain is back pain.\n",
      "\n",
      "I have a back pain.\n",
      "\n",
      "Your pain is back pain.\n",
      "\n",
      "Your bac...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 0 in batch 4 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's past medical history....\n",
      "Sample output: KEY INFO:\n",
      "I've been told that it's not a good idea to use.\n",
      "A good idea.\n",
      "\n",
      "So I decided to look into t...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▉                                                                 | 5/46 [02:15<18:36, 27.23s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 4 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: A doctor will discuss the treatment options, the treatment options, and the current treatment plans....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 5 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: The following are the major problems IHGP's are dealing with:\n",
      "\n",
      "1.The primary goal of the conversatio...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 5 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing pain in her elbow....\n",
      "Sample output: What are the best medical decisions for this patient?\n",
      "\n",
      "You have the best medical opinion.\n",
      "\n",
      "This pati...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▌                                                               | 6/46 [02:46<19:05, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 6 - PPO step successful!\n",
      "Extracted Info: The patient is concerned about her recent blood work....\n",
      "Sample output: KEY INFORMATION:\n",
      "\n",
      "The patient's symptoms, and the way they are treated.\n",
      "\n",
      "This is not a medical revie...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████                                                              | 7/46 [03:10<17:32, 26.99s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 6 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: In a nutshell:\n",
      "\n",
      "The first step is to identify the symptoms:\n",
      "\n",
      "The first step is to identify the speci...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 7 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing a knee pain....\n",
      "Sample output: This is a case case of a knee.\n",
      "\n",
      "This is a case of a knee.\n",
      "\n",
      "This is a case of a knee.\n",
      "\n",
      "This is a case...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████▋                                                            | 8/46 [03:35<16:46, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 7 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Key facts:\n",
      "\n",
      "A doctor who has a primary care diagnosis is considered as a primary care physician.\n",
      "\n",
      "A ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 8 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's health and recommend treatment....\n",
      "Sample output: Here is a list of the top issues of the issue that have been discussed by our physician, and the doc...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.52s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.52it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▎                                                          | 9/46 [04:05<16:53, 27.39s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 8 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: MEDICAL SUMMARY:\n",
      "\n",
      "1. Symptoms and duration\n",
      "\n",
      "2. Drug use, alcohol use, and\n",
      "\n",
      "3. Alcohol use\n",
      "\n",
      "4. Key cl...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.64s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.05 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 9 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Symptoms:\n",
      "\n",
      "What is it?\n",
      "\n",
      "\n",
      "The primary symptom is a severe headache.\n",
      "\n",
      "What is it does it?\n",
      "The primary ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.50s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▋                                                        | 10/46 [04:35<16:55, 28.19s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 9 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: Medical marijuana is on the patient's side.\n",
      "\n",
      "If the patient is serious, the doctor will give the pat...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 10 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: The doctor will take a prescription of the following:\n",
      "\n",
      "a. a. a. a. a.\n",
      "\n",
      "b.\n",
      "\n",
      "c...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 10 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: S:\n",
      "\n",
      "A:\n",
      "\n",
      "C:\n",
      "\n",
      "D:\n",
      "\n",
      "T:\n",
      "T:\n",
      "KEY:\n",
      "\n",
      "C:\n",
      "M:\n",
      "\n",
      "A:\n",
      "\n",
      "D:\n",
      "A...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▏                                                      | 11/46 [04:57<15:22, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 11 - PPO step successful!\n",
      "Extracted Info: The doctor is asking about the symptoms of the patient....\n",
      "Sample output: The doctor is looking for a medical system that is able to provide treatment plans for the patient.\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 26%|██████████████████▊                                                     | 12/46 [05:21<14:31, 25.64s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 11 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Symptoms and duration of treatment:\n",
      "\n",
      "Based on a person's medical history, if it is a person with a d...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 12 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Key findings:\n",
      "\n",
      "What is the current medical status of the patient or the following is a topic of inte...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.24s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 28%|████████████████████▎                                                   | 13/46 [05:45<13:47, 25.08s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 12 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Key:\n",
      "\n",
      "A few key details are included, and this should be used in your discussion.\n",
      "\n",
      "A few details tha...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 13 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Key Words:\n",
      "\"I am a bad doctor and I have no medical practice in my life\"\n",
      "\n",
      "\"I am a bad doctor, and my...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:08<00:08,  8.20s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  1.57it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -5.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 30%|█████████████████████▉                                                  | 14/46 [06:16<14:21, 26.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 13 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old female with a history of hypertension and diabetes ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 14 - PPO step successful!\n",
      "Extracted Info: Lawrence is a 62-year-old male with a past medical history significant for type i diabetes, congesti...\n",
      "Sample output: Lack of care, which is the same for the patient,...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████▍                                                | 15/46 [06:36<12:51, 24.88s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 14 - PPO step successful!\n",
      "Extracted Info: susan is a 26-year-old female who has high blood pressure....\n",
      "Sample output: Treatment plan:\n",
      "\n",
      "The goal is to treat all the symptoms of the disease, including:\n",
      "\n",
      "a low blood press...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 15 - PPO step successful!\n",
      "Extracted Info: chief complaint is chest pain...\n",
      "Sample output: chief complaint is the general general condition of the patient\n",
      "\n",
      "Major complaint is the general cond...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 1 in batch 15 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking painkillers to treat the pain....\n",
      "Sample output: KEY CONCER:\n",
      "The Patient is currently taking painkillers to treat the pain.\n",
      "\n",
      "The Patient is currently...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████                                               | 16/46 [07:02<12:37, 25.25s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 0 in batch 16 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: \"Symptoms:\n",
      "\n",
      "\n",
      "We have the following symptoms:\n",
      "\n",
      "We have the following symptoms:\n",
      "\n",
      "We have the following...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████▌                                             | 17/46 [07:24<11:43, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 16 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and give her a physical exam....\n",
      "Sample output: For a medical summary of the following:\n",
      "\n",
      "\n",
      "The doctor will look at the patient with a medical alert.\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 0 in batch 17 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and recommend a physical exam....\n",
      "Sample output: KEY NOTIFICATION:\n",
      "This is a good summary of the evidence in the doctor's office.\n",
      "\n",
      "The doctor's repor...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████▏                                           | 18/46 [07:51<11:42, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 17 - PPO step successful!\n",
      "Extracted Info: The patient is a female with acid reflux....\n",
      "Sample output: DETERATION:\n",
      "Pregnancy/Pregnancy:\n",
      "\n",
      "DETERMINATION:\n",
      "Hormonal:\n",
      "\n",
      "DETERMATION:\n",
      "\n",
      "H...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 18 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: Medical information about the medical information of the patient.\n",
      "\n",
      "In the event the doctor does not ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 41%|█████████████████████████████▋                                          | 19/46 [08:18<11:35, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 18 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his neck pain....\n",
      "Sample output: The doctor is asking about a specific symptom. The doctor is asking about a specific treatment plan....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.69s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 19 - PPO step successful!\n",
      "Extracted Info: The doctor will recommend a course of antibiotics for the patient....\n",
      "Sample output: The doctor will recommend a course of antibiotics.\n",
      "\n",
      "The doctor will recommend a course of antibiotic...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 43%|███████████████████████████████▎                                        | 20/46 [08:41<10:45, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 19 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 20 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: Juliaia has a heart attack and has had...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -5.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 20 - PPO step successful!\n",
      "Extracted Info: joseph is a 59 year old male who has chronic problems....\n",
      "Sample output: If a medical condition is a problem with the general state of care, it is considered to be a problem...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▊                                       | 21/46 [09:03<10:02, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -7.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 21 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old male with a complaint of left arm pain....\n",
      "Sample output: In case of a patient, they will write a medical summary.\n",
      "\n",
      "IN CASE:\n",
      "\n",
      "The is a medical summary, based...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -6.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 48%|██████████████████████████████████▍                                     | 22/46 [09:28<09:40, 24.17s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 21 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: You can ask a question about the pain and the pain may be mentioned.\n",
      "\n",
      "You can ask for more informati...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 22 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: Julia is on her stent....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████                                    | 23/46 [09:53<09:23, 24.48s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 22 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: The patient's wrist is broken.\n",
      "The patient's wrist is broken.\n",
      "The patient's wrist is broken.\n",
      "The pat...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.15s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 23 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: Your doctor.\n",
      "\n",
      "To determine if your doctor is recommending a treatment for you.\n",
      "\n",
      "Include a list of co...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -7.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████▌                                  | 24/46 [10:18<09:00, 24.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 23 - PPO step successful!\n",
      "Extracted Info: chief complaint is acid reflux...\n",
      "Sample output: KEY INFORMATION:\n",
      "\n",
      "KEY:\n",
      "\n",
      "The primary complaint is acid reflux (acid reflux is a disease caused by the...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -9.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 24 - PPO step successful!\n",
      "Extracted Info: Chief complaint is abnormal renal ultrasound with an atrophic right kidney....\n",
      "Sample output: COURT:\n",
      "\n",
      "Your medical history is:\n",
      "\n",
      "\n",
      "(not included in the discussion)\n",
      "\n",
      "This medical history is:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -9.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 54%|███████████████████████████████████████▏                                | 25/46 [10:41<08:26, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 24 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and will recommend a course of treatment....\n",
      "Sample output: The patient will discuss the condition and cause for their treatment.\n",
      "\n",
      "The patient will recommend a ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 25 - PPO step successful!\n",
      "Extracted Info: The patient is a female who has a severe right upper arm pain....\n",
      "Sample output: PROGUMS:\n",
      "\n",
      "PROGOGY:\n",
      "\n",
      "\n",
      "A:\n",
      "\n",
      "The patient has an issue that can cause problems, and you...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 1 in batch 25 - PPO step successful!\n",
      "Extracted Info: William is a doctor. He is treating a patient who injured his knee....\n",
      "Sample output: Bill is a doctor.\n",
      "\n",
      "Bill, is a doctor.\n",
      "\n",
      "Bill has an injury.\n",
      "\n",
      "Bill is a doctor.\n",
      "\n",
      "Bill is...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████▋                               | 26/46 [11:07<08:17, 24.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.87s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  1.81it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 26 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -10.90 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 59%|██████████████████████████████████████████▎                             | 27/46 [11:40<08:38, 27.29s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 26 - PPO step successful!\n",
      "Extracted Info: chief complaint is back pain...\n",
      "Sample output: ADDITIONAL INFORMATION:\n",
      "\n",
      "Cocaine is a major cause of ailing and/or anemia. Alcohol is an increase in...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -12.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 27 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: INTRUDITION:\n",
      "\n",
      "Treatment Plans\n",
      "\n",
      "INTRUDIERS:\n",
      "\n",
      "A good diagnosis of a major and a minor is required to b...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -11.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 61%|███████████████████████████████████████████▊                            | 28/46 [12:03<07:47, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 27 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: The doctor will call out some of the physical exam findings, to give some insight into the condition...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -10.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 28 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and discuss the cough....\n",
      "Sample output: This is a concise medical summary of the general medicine.\n",
      "\n",
      "This is a medical summary of the patient...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -7.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 63%|█████████████████████████████████████████████▍                          | 29/46 [12:30<07:24, 26.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 28 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: The patient will discuss the current medications, current treatment options, current treatments, and...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -13.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 29 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his current medical condition....\n",
      "Sample output: KEY FEATURES:\n",
      "\n",
      "Key points:\n",
      "\n",
      "Primary causes of death:\n",
      "\n",
      "\n",
      "Major:\n",
      "\n",
      "\n",
      "Minor:\n",
      "\n",
      "Solutions:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -15.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 65%|██████████████████████████████████████████████▉                         | 30/46 [12:51<06:34, 24.68s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 29 - PPO step successful!\n",
      "Extracted Info: Patient is 72-year-old woman with hypertension....\n",
      "Sample output: Key Medical notes:\n",
      "\n",
      "The following is a medical summary of the following patient:\n",
      "\n",
      "The patient's medi...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -18.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 30 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: This is the most important thing I would like to know the best.\n",
      "\n",
      "This is what I would like to know:\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -9.95 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 30 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Key information:\n",
      "\n",
      "\n",
      "DILOGS:\n",
      "\n",
      "Key ideas:\n",
      "\n",
      "WHAT?\n",
      "\n",
      "If you're in the market for a medical summary, you ca...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████▌                       | 31/46 [13:20<06:29, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -14.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 31 - PPO step successful!\n",
      "Extracted Info: The patient is a 57-year-old female who is here for a surgical consult....\n",
      "Sample output: The patient is a male (male) with at least 3 symptoms with a high risk of serious, if not present, f...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -12.61 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 70%|██████████████████████████████████████████████████                      | 32/46 [13:41<05:44, 24.59s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 31 - PPO step successful!\n",
      "Extracted Info: Melissa sanchez is a female patient who is being seen in the office for status post mitral valve rep...\n",
      "Sample output: A brief medical summary of the following medical topic:\n",
      "\n",
      "Anal:\n",
      "\n",
      "\n",
      "A brief medical topic...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -15.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 32 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -6.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████▋                    | 33/46 [14:03<05:08, 23.70s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 32 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: What is happening?\n",
      "\n",
      "What is happening?\n",
      "\n",
      "This is a summary of information that topic has been discuss...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -16.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 33 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: \"You're going to go to the the hospital. What do you do? What do you do? You're going to take it for...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.52s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████▏                  | 34/46 [14:31<04:59, 24.92s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 33 - PPO step successful!\n",
      "Extracted Info: Kayla has been using perc gel and washing regularly which is somewhat helpful....\n",
      "Sample output: There are no medical need for Kayla.\n",
      "\n",
      "It is available in a separate file, separate medical report.\n",
      "I...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -20.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 34 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Symptoms and duration\n",
      "\n",
      "Based on the above, generate a concise medical summary:\n",
      "\n",
      "Summary and duration...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -17.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 76%|██████████████████████████████████████████████████████▊                 | 35/46 [14:52<04:21, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 34 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: In the following, the following is a list of the available medical-relevant medical-related informat...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -9.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 35 - PPO step successful!\n",
      "Extracted Info: The doctor is trying to diagnose the patient with a medical condition....\n",
      "Sample output: The doctor is trying to diagnose a medical condition.\n",
      "\n",
      "The doctor is trying to diagnose a medical co...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -14.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 35 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████▎               | 36/46 [15:22<04:15, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -12.85 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 36 - PPO step successful!\n",
      "Extracted Info: The patient has been in a car accident and has been experiencing neck pain....\n",
      "Sample output: The has been experiencing neck pain.\n",
      "\n",
      "The current condition is not present.\n",
      "\n",
      "\n",
      "The current condition ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -23.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 80%|█████████████████████████████████████████████████████████▉              | 37/46 [15:46<03:46, 25.18s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 36 - PPO step successful!\n",
      "Extracted Info: The patient is an 82-year-old male with past medical history significant for hypertension and stage ...\n",
      "Sample output: A patient with a history...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n",
      "Query 0 in batch 37 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Symptoms\n",
      "\n",
      "Mention and/addiction is the most common symptom\n",
      "\n",
      "The most common medical symptoms that ar...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -22.54 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 83%|███████████████████████████████████████████████████████████▍            | 38/46 [16:11<03:21, 25.13s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 37 - PPO step successful!\n",
      "Extracted Info: The patient is a woman with a history of type 2 diabetes and ovarian cancer....\n",
      "Sample output: GENERAL:\n",
      "\n",
      "A total of 1:\n",
      "\n",
      "The patient is a woman with a history of type 2 diabetes.\n",
      "\n",
      "\n",
      "The...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -16.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 38 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: FAMEMAKED\n",
      "\n",
      "The first two items are for your medical treatment:\n",
      "FAMEMAKED\n",
      "\n",
      "The second item is for you...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.49s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -11.99 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 85%|█████████████████████████████████████████████████████████████           | 39/46 [16:34<02:50, 24.37s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 38 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: The general general idea is that these symptoms are not very common but are very common, in the Unit...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -21.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 39 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: HIV/treatments:\n",
      "HIV/AIDS:\n",
      "\n",
      "Hormone:\n",
      "\n",
      "HIV/AIDS:\n",
      "\n",
      "Hemorrhine:\n",
      "\n",
      "Hormonal:\n",
      "\n",
      "L...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -8.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████▌         | 40/46 [16:55<02:21, 23.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 39 - PPO step successful!\n",
      "Extracted Info: chief complaint is worsening headaches...\n",
      "Sample output: CITOR\n",
      "Key to this call:\n",
      "CITOR\n",
      "Key to this call:\n",
      "CITOR\n",
      "\n",
      "CITOR:\n",
      "CITORGARD:\n",
      "CITOR:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -19.98 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 40 - PPO step successful!\n",
      "Extracted Info: The patient has a foot ulcer that has been there for six weeks....\n",
      "Sample output: GENERAL INFORMATION:\n",
      "\n",
      "Patient's foot ulcer is a condition that has been there for six weeks.\n",
      "\n",
      "The pa...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -23.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 40 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: The patient has been suffering from back pain for a few years.\n",
      "\n",
      "This is a list of the following:\n",
      "\n",
      "Th...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████▏       | 41/46 [17:22<02:01, 24.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -22.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 41 - PPO step successful!\n",
      "Extracted Info: Karen is a 34-year-old female with a history of chronic migraines and hypertension who is here today...\n",
      "Sample output: Karen says that she feels as if she is a pain sufferer....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -24.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████▋      | 42/46 [17:45<01:36, 24.22s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 41 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: You see a doctor who is going through pain.\n",
      "\n",
      "The doctor also needs to explain to make sure the pain ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.33s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -13.38 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 42 - PPO step successful!\n",
      "Extracted Info: The patient is a 41-year-old female....\n",
      "Sample output: (D)This is the patient's current treatment plan.\n",
      "\n",
      "(D) is the current treatment plan.\n",
      "(D) is the curr...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -23.61 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████▎    | 43/46 [18:14<01:16, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 42 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: Please include a diagnosis of the problem.\n",
      "\n",
      "Please include the patient information.\n",
      "\n",
      "Please include ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.84s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -20.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 43 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her knee pain....\n",
      "Sample output: If she has a knee pain, the doctor is a doctor.\n",
      "\n",
      "If she has a hip pain, the doctor is a doctor.\n",
      "\n",
      "She...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -19.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 96%|████████████████████████████████████████████████████████████████████▊   | 44/46 [18:37<00:49, 24.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 43 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: A brief medical summary focusing on the treatment of the patient is provided on the patient's first ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.37s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.50it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -18.95 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 44 - PPO step successful!\n",
      "Extracted Info: The patient has a complaint of knee pain....\n",
      "Sample output: WHAT:\n",
      "Your patient has a complaint of knee pain.\n",
      "\n",
      "Your patient is a doctor.\n",
      "\n",
      "Your patient is a docto...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -22.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 98%|██████████████████████████████████████████████████████████████████████▍ | 45/46 [19:10<00:27, 27.08s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 44 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: The patient has a wrist injury.\n",
      "\n",
      "The patient has a broken wrist.\n",
      "\n",
      "The patient has a broken wrist.\n",
      "\n",
      "\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -31.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 45 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: PROGIC INFO:\n",
      "\n",
      "PROGIC INFO:\n",
      "\n",
      "PROGICIFIC INFO:\n",
      "\n",
      "\n",
      "PROGICIFIC INFO:\n",
      "\n",
      "PROG:\n",
      "\n",
      "PROG:\n",
      "\n",
      "PR...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -26.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 45 - PPO step successful!\n",
      "Extracted Info: The doctor is talking about her patient and the current medications....\n",
      "Sample output: The doctor is talking about her patient and the current medications.\n",
      "\n",
      "\n",
      "The doctor says she is on the...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 46/46 [19:33<00:00, 25.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_45\n",
      "✅ Epoch 1/3 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-epochs/epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/46 [00:00<?, ?it/s]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -28.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 0 - PPO step successful!\n",
      "Extracted Info: The patient is concerned about her recent blood work....\n",
      "Sample output: The patient is concerned about her recent blood work.\n",
      "\n",
      "The patient is concerned about her recent blo...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -15.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 0 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: KEY/PROB:\n",
      "\n",
      "The patient's symptoms should be included in the conversation:\n",
      "\n",
      "PROB:\n",
      "\n",
      "The patient's symp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                       | 1/46 [00:24<18:44, 25.00s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -19.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 1 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her symptoms and duration....\n",
      "Sample output: 1. How did the doctor think the patient was ill or well?\n",
      "2. How did the doctor think the the patient...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -7.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  4%|███▏                                                                     | 2/46 [00:56<21:13, 28.95s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 1 - PPO step successful!\n",
      "Extracted Info: The patient is a female with acid reflux....\n",
      "Sample output: The is a male with acid reflux.\n",
      "The patient is in a female with acid reflux.\n",
      "\n",
      "The patient has acid r...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -21.96 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 2 - PPO step successful!\n",
      "Extracted Info: Patient is a 60 year old, right-handed male, referred today for evaluation of numbness and tingling....\n",
      "Sample output: Patient is a 60 year old, right-handed male, referred today for medical evaluation of numb...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -16.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  7%|████▊                                                                    | 3/46 [01:20<18:59, 26.50s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 2 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: Key Information:\n",
      "The doctor will discuss the current medical condition.\n",
      "\n",
      "The doctor will discuss the...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -38.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 3 - PPO step successful!\n",
      "Extracted Info: The patient is a 57-year-old female who is here for a surgical consult....\n",
      "Sample output: The patient is here for medical consultation:\n",
      "\n",
      "The patient is here for a surgical procedure:\n",
      "\n",
      "The pa...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -34.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  9%|██████▎                                                                  | 4/46 [01:47<18:44, 26.77s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 3 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Frequency of discussion with relevant participants:\n",
      "ININININATION:\n",
      "\n",
      "Symptoms and duration:\n",
      "\n",
      "SUMMARY:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.45s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -39.90 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 4 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: KEY CHART:\n",
      "\n",
      "The doctor is asking if the patient is experiencing any special pain.\n",
      "\n",
      "Key needs to be:\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -28.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 11%|███████▉                                                                 | 5/46 [02:13<18:12, 26.64s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 4 - PPO step successful!\n",
      "Extracted Info: The doctor is talking about her patient and the current medications....\n",
      "Sample output: Key:\n",
      "\n",
      "Majora.\n",
      "\n",
      "Major:\n",
      "\n",
      "Major:\n",
      "If:\n",
      "\n",
      "A:\n",
      "\n",
      "A.\n",
      "\n",
      "Major:\n",
      "A:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -47.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 5 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Symptoms and duration\n",
      "AAS: \"We are currently considering a diagnosis of a condition that is not curr...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -24.90 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 5 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: The doctor:\n",
      "The doctor:\n",
      "The patient:\n",
      "\n",
      "The doctor:\n",
      "\n",
      "The doctor:\n",
      "The doctor:\n",
      "\n",
      "The doctor:\n",
      "\n",
      "The doctor:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▌                                                               | 6/46 [02:36<16:48, 25.22s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -26.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 6 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: -\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "-...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -46.64 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 15%|███████████                                                              | 7/46 [02:58<15:49, 24.34s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 6 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and discuss the cough....\n",
      "Sample output: The medical summary includes the symptoms, and the symptoms,\n",
      "The doctor will review the current medi...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.94s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.43s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  1.70it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -41.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 7 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -16.75 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████▋                                                            | 8/46 [03:29<16:35, 26.20s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 7 - PPO step successful!\n",
      "Extracted Info: William is a doctor. He is treating a patient who injured his knee....\n",
      "Sample output: Key symptoms:\n",
      "\n",
      "He is a doctor.\n",
      "\n",
      "He is a doctor.\n",
      "\n",
      "He is a doctor.\n",
      "\n",
      "(This is a statement...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -57.64 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 8 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: This is a list of what the person said was \"not sure\" if mentioned.\n",
      "\n",
      "The person:\n",
      "The person:\n",
      "\n",
      "the pe...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -56.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 20%|██████████████▎                                                          | 9/46 [03:54<16:04, 26.07s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 8 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: If the doctor believes that it is an incontinence, it is not a doctor's opinion:\n",
      "\n",
      "If the doctor beli...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -44.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 9 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: SUMMARY:\n",
      "The initial medical summary was not in the discussion of this article.\n",
      "SUMMARY:\n",
      "\n",
      "If the dis...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.54s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.52it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -16.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 22%|███████████████▋                                                        | 10/46 [04:22<15:57, 26.60s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 9 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking medications for his foot pain....\n",
      "Sample output: The patient is currently taking medications for his foot pain.\n",
      "\n",
      "The patient is currently taking medi...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -34.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 10 - PPO step successful!\n",
      "Extracted Info: Lawrence is a 62-year-old male with a past medical history significant for type i diabetes, congesti...\n",
      "Sample output: If you are a patient, will be sure to include your medical record...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -27.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 10 - PPO step successful!\n",
      "Extracted Info: Karen is a 34-year-old female with a history of chronic migraines and hypertension who is here today...\n",
      "Sample output: Karen is a 35-year-old male male with a history of chronic pain...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▏                                                      | 11/46 [04:44<14:43, 25.24s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -43.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 11 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: COMMENT:\n",
      "\n",
      "COMMENT:\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "-\n",
      "\n",
      "-\n",
      "-\n",
      "\n",
      "-...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -42.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 26%|██████████████████▊                                                     | 12/46 [05:05<13:28, 23.78s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 11 - PPO step successful!\n",
      "Extracted Info: The patient has been in a car accident and has been experiencing neck pain....\n",
      "Sample output: 1:\n",
      "2:\n",
      "3:\n",
      "\n",
      "4:\n",
      "\n",
      "5:\n",
      "\n",
      "6:\n",
      "\n",
      "7:\n",
      "8:\n",
      "\n",
      "9...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.30s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.44it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -63.74 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 12 - PPO step successful!\n",
      "Extracted Info: The patient has a complaint of knee pain....\n",
      "Sample output: - medical summary:\n",
      "\n",
      "-1.\n",
      "\n",
      "-2.\n",
      "\n",
      "-1.\n",
      "\n",
      "-2.\n",
      "\n",
      "-2.\n",
      "\n",
      "-2.\n",
      "\n",
      "-...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -51.76 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 28%|████████████████████▎                                                   | 13/46 [05:34<14:02, 25.54s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 12 - PPO step successful!\n",
      "Extracted Info: chief complaint is worsening headaches...\n",
      "Sample output: KEY:\n",
      "\n",
      "Key:\n",
      "\n",
      "Migraine and other headache conditions\n",
      "\n",
      "Migraine is a symptom of:\n",
      "\n",
      "a history of:\n",
      "\n",
      "anxiet...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -61.36 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 13 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: (1) If the doctor thinks the ankle and the medicine is too good, call the doctor\n",
      "\n",
      "(2) The physician ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -53.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 30%|█████████████████████▉                                                  | 14/46 [06:01<13:47, 25.86s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 13 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: I. Information:\n",
      "A. Information:\n",
      "A. Brief description of the condition\n",
      "Brief description of the sympt...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.52s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -64.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 14 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: D: Treatment plan:\n",
      "Drug:\n",
      "\n",
      "TRAIN:\n",
      "\n",
      "General:\n",
      "\n",
      "D:\n",
      "\n",
      "T:\n",
      "\n",
      "D:\n",
      "\n",
      "General:\n",
      "General:\n",
      "\n",
      "D:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.45s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -65.60 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████▍                                                | 15/46 [06:26<13:15, 25.66s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 14 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: INFORMATION:\n",
      "\n",
      "Treatments:\n",
      "\n",
      "CITY:\n",
      "\n",
      "The following topics:\n",
      "1.\n",
      "Innal,2\n",
      "2\n",
      "\n",
      "C:\n",
      "\n",
      "The following topics:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.39s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -51.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 15 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: I. The doctor's concern about the patient's health.\n",
      "\n",
      "The doctor's concern is about the patient's hea...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -66.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 15 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's health and recommend treatment....\n",
      "Sample output: If the doctor is a doctor who is taking your doctor's recommendation:\n",
      "\n",
      "the doctor will check up on y...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████                                               | 16/46 [06:55<13:17, 26.57s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -40.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 16 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and recommend a physical exam....\n",
      "Sample output: The doctor will discuss the results of the physical exam, and then ask the patient if they have any ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -53.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████▌                                             | 17/46 [07:21<12:51, 26.60s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 16 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: HOSPITAL:\n",
      "\n",
      "If you have a medical condition, call 1-1-1.\n",
      "\n",
      "If you have a condition, you should contact...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -67.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 17 - PPO step successful!\n",
      "Extracted Info: The doctor is asking about the symptoms of the patient....\n",
      "Sample output: The doctor is asking the patient about the symptoms.\n",
      "\n",
      "The doctor is asking about the symptoms.\n",
      "\n",
      "the ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -58.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████▏                                           | 18/46 [07:47<12:16, 26.30s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 17 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her knee pain....\n",
      "Sample output: If there is a joint pain,\n",
      "\n",
      "to the patient:\n",
      "\n",
      "If there is a pain:\n",
      "The doctor asks the patient if he is...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -63.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 18 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Treatments that are discussed:\n",
      "\n",
      "COURS:\n",
      "Treatments that are discussed:\n",
      "COURS:\n",
      "\n",
      "COURS:\n",
      "\n",
      "Treatments tha...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -81.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 41%|█████████████████████████████▋                                          | 19/46 [08:10<11:20, 25.19s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 18 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking painkillers to treat the pain....\n",
      "Sample output: If you mention this, you are a patient.\n",
      "\n",
      "If you have a question, you want to discuss this\n",
      "\n",
      "If you ha...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -76.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 19 - PPO step successful!\n",
      "Extracted Info: The patient has a foot ulcer that has been there for six weeks....\n",
      "Sample output: Key:\n",
      "Symptoms:\n",
      "The patient has a foot ulcer that has been there for six weeks.\n",
      "The patient has a foo...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -50.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 43%|███████████████████████████████▎                                        | 20/46 [08:32<10:29, 24.22s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 19 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: Julia's main concern: The doctor has been...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -85.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 20 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: INSTRUCTIONS:\n",
      "1. Discuss the main topics of the conversation:\n",
      "\n",
      "This is a conversation with a patient...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -96.73 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 20 - PPO step successful!\n",
      "Extracted Info: The patient is a woman with a history of type 2 diabetes and ovarian cancer....\n",
      "Sample output: Key symptoms, symptoms and symptoms:\n",
      "\n",
      "\"ADVERSE:\n",
      "\n",
      "\"\n",
      "\"\n",
      "\n",
      "\"ADVANCIC:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▊                                       | 21/46 [08:54<09:54, 23.77s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.47s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -65.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 21 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's past medical history....\n",
      "Sample output: The doctor will check up on the patient's medical history.\n",
      "\n",
      "The doctor will check up on the patient'...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -55.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 48%|██████████████████████████████████▍                                     | 22/46 [09:20<09:44, 24.34s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 21 - PPO step successful!\n",
      "Extracted Info: chief complaint is chest pain...\n",
      "Sample output: Related topics:\n",
      "The topic(s):\n",
      "The discussion(s):\n",
      "\n",
      "The discussion(s):\n",
      "\n",
      "CARE:\n",
      "The conversation(s):\n",
      "\n",
      "Th...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -41.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 22 - PPO step successful!\n",
      "Extracted Info: The patient is an 82-year-old male with past medical history significant for hypertension and stage ...\n",
      "Sample output: {:A recent study...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -100.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 50%|████████████████████████████████████                                    | 23/46 [09:46<09:31, 24.84s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 22 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: GENERAL INFO:\n",
      "General information about the underlying and current treatment of the problem\n",
      "\n",
      "The pat...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -71.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 23 - PPO step successful!\n",
      "Extracted Info: The patient is a 31-year-old female with a history of diabetes and asthma....\n",
      "Sample output: (a)\n",
      "\n",
      "(b)\n",
      "\n",
      "(c)\n",
      "\n",
      "(d)\n",
      "\n",
      "(e)\n",
      "\n",
      "(d...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -61.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████▌                                  | 24/46 [10:07<08:38, 23.57s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 23 - PPO step successful!\n",
      "Extracted Info: The doctor will recommend a course of antibiotics for the patient....\n",
      "Sample output: [The following are the same notes:\n",
      "\n",
      "[1]\n",
      "\n",
      "[2]\n",
      "\n",
      "[1]\n",
      "\n",
      "\n",
      "[2]\n",
      "[3]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -60.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 24 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and give her a physical exam....\n",
      "Sample output: *(d) The doctor will discuss the patient's medical history, history, and/or recommend treatment plan...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -73.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 54%|███████████████████████████████████████▏                                | 25/46 [10:32<08:26, 24.11s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 24 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:07<00:07,  7.48s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.79it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -78.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 25 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: -1.\n",
      "\n",
      "-1.\n",
      "\n",
      "-1.\n",
      "\n",
      "-\n",
      "-1.\n",
      "-1.\n",
      "\n",
      "-1.\n",
      "\n",
      "-2.\n",
      "\n",
      "-1...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -135.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 25 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: What the doctor is asking the patient:\n",
      "\n",
      "WHAT:\n",
      "\n",
      "The doctor is interested in the conversation.\n",
      "\n",
      "The do...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████▋                               | 26/46 [11:00<08:28, 25.41s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -90.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 26 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: Policies:\n",
      "MYG:\n",
      "\n",
      "Policious medicines:\n",
      "\n",
      "MYG::\n",
      "\n",
      "Policies:\n",
      "MYG:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -122.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 59%|██████████████████████████████████████████▎                             | 27/46 [11:21<07:33, 23.89s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 26 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Diseasell:\n",
      "\n",
      "Dise:\n",
      "Treatment:\n",
      "\n",
      "(a)\n",
      "\n",
      "Treatment:\n",
      "\n",
      "(a)\n",
      "\n",
      "Frequency:\n",
      "(a)\n",
      "\n",
      "F...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -66.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 27 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: IN:\n",
      "\n",
      "SUM:\n",
      "\n",
      "SUM:\n",
      "\n",
      "SUM:\n",
      "SUM:\n",
      "\n",
      "SUM:\n",
      "\n",
      "\n",
      "SUM:\n",
      "SUM:\n",
      "\n",
      "SUM:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -112.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 61%|███████████████████████████████████████████▊                            | 28/46 [11:45<07:10, 23.92s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 27 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: 1. The patient is suffering from a broken wrist.\n",
      "\n",
      "2. The patient has a broken wrist.\n",
      "\n",
      "\n",
      "The patient:\n",
      "...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -44.99 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 28 - PPO step successful!\n",
      "Extracted Info: Michael is seeing a doctor for back pain....\n",
      "Sample output: The following is an important message to the user that was sent:\n",
      "The following is a medical summary ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -60.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 63%|█████████████████████████████████████████████▍                          | 29/46 [12:05<06:28, 22.86s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 28 - PPO step successful!\n",
      "Extracted Info: susan is a 26-year-old female who has high blood pressure....\n",
      "Sample output: CALL:\n",
      "\n",
      "S:\n",
      "\n",
      "M:\n",
      "\n",
      "P:\n",
      "S:\n",
      "a:\n",
      "\n",
      "::\n",
      "\n",
      "c...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -77.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 29 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old male with a complaint of left arm pain....\n",
      "Sample output: What did you call?\n",
      "\n",
      "The patient is a 37-year-old male with a right arm pain.\n",
      "\n",
      "What were...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -107.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 65%|██████████████████████████████████████████████▉                         | 30/46 [12:28<06:07, 22.96s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 29 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his neck pain....\n",
      "Sample output: A person is being asked about the current situation.\n",
      "\n",
      "The doctor asks if the person is in the area w...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -95.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 30 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: PRACTIVE:\n",
      "\n",
      "Please note that this is not an opiate\n",
      "\n",
      "PRACTIVE:\n",
      "\n",
      "ALL:\n",
      ":\n",
      "\n",
      "PRACT:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.36s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.16s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -75.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 30 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old female with a history of hypertension and diabetes ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████▌                       | 31/46 [12:57<06:09, 24.60s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -43.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 31 - PPO step successful!\n",
      "Extracted Info: Kayla has been using perc gel and washing regularly which is somewhat helpful....\n",
      "Sample output: Key:\n",
      "[{i:{a:at:]]{}(a)\n",
      "\n",
      ":callor:call:}...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -87.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 70%|██████████████████████████████████████████████████                      | 32/46 [13:18<05:31, 23.69s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 31 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: HIV/A:\n",
      "* If:\n",
      "* (1)* is an emergency (if present)\n",
      "if (2)\n",
      "if (3)\n",
      "*(1)*(1)*...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -41.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 32 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: [ { \"1.5b-1.6:\" :[ 0 ]{ \"1-2.5:\" :[{ \"1-2:1:{:i:{:\"...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -55.50 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████▋                    | 33/46 [13:38<04:53, 22.58s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 32 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: [c] Medical history of the patient\n",
      "\n",
      "[c]\n",
      "\n",
      "[c]\n",
      "[c]\n",
      "[c]\n",
      "\n",
      "[c]\n",
      "[c]\n",
      "\n",
      "[c]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -115.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 33 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: KEY:\n",
      "(1) :[\n",
      "a) What is your patient's complaint:\n",
      ":\n",
      "(a)\n",
      "<b>\n",
      "(1)\n",
      "\n",
      "[{id:\n",
      "{\n",
      "}...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -132.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████▏                  | 34/46 [13:59<04:23, 21.98s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 33 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: [MEDC] The doctor discusses:\n",
      "\n",
      "[QUESTION:\n",
      "\n",
      "[PROPOSED]\n",
      "\n",
      "[CONTACT]\n",
      "\n",
      "[]\n",
      "[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -82.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 34 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: Julia:\n",
      "1. This includes:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -151.98 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 76%|██████████████████████████████████████████████████████▊                 | 35/46 [14:20<03:59, 21.75s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 34 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: TALK:\n",
      "\n",
      "I:\n",
      "[t]\n",
      "\n",
      "[msg1]\n",
      "\n",
      "[msg2]\n",
      "\n",
      "[t2] [t2]\n",
      "\n",
      "[[t]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -86.64 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 35 - PPO step successful!\n",
      "Extracted Info: The patient is a female who has a severe right upper arm pain....\n",
      "Sample output: PROGIC:\n",
      "\n",
      "Your patient has a severe upper arm pain:\n",
      "\n",
      "in the patient's current medical history:\n",
      "\n",
      "PROPI...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -84.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 35 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: Ray...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████▎               | 36/46 [14:39<03:29, 20.99s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -81.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 36 - PPO step successful!\n",
      "Extracted Info: Chief complaint is abnormal renal ultrasound with an atrophic right kidney....\n",
      "Sample output: 1. \"What is the most important medical thing you're doing right now?\"\n",
      "\n",
      "2. \"The most important medica...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -65.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 80%|█████████████████████████████████████████████████████████▉              | 37/46 [15:06<03:24, 22.72s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 36 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: 1. What is the diagnosis?\n",
      "[(a) What is the condition?\n",
      "[b] [c]\n",
      "[c][b] [c]\n",
      "[c][d]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.54s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -106.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 37 - PPO step successful!\n",
      "Extracted Info: chief complaint is back pain...\n",
      "Sample output: #[all patients: name:s]\n",
      "\n",
      "[all patients:name:[all patients]\n",
      "\n",
      "[name:]\n",
      "[all_info:name]\n",
      "[#[all...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -88.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 83%|███████████████████████████████████████████████████████████▍            | 38/46 [15:29<03:00, 22.62s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 37 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his current medical condition....\n",
      "Sample output: [1]# (1)\n",
      "\n",
      "[INDEX:\n",
      "\n",
      "[1][1]#([2)][[[INDEX:][...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -106.73 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 38 - PPO step successful!\n",
      "Extracted Info: chief complaint is acid reflux...\n",
      "Sample output: 1. [PTSD:Addiction]\n",
      "[:PTS]\n",
      "[PTSD:Cannot_advocate_:PTS]\n",
      "[PTSD:\n",
      "I...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -72.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 85%|█████████████████████████████████████████████████████████████           | 39/46 [15:50<02:35, 22.19s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 38 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: PRACT:\n",
      "\n",
      "<a href=\"https://www.cannabis.com/research/cannab\n",
      ">Possible referral:\n",
      "\n",
      "https://www.cannabis....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -92.90 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 39 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: INDEX:\n",
      "\n",
      "PATORY:\n",
      "[PREvention(s):\n",
      "\n",
      "Positives\n",
      "[b]--[b]\n",
      "\n",
      "[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -119.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████▌         | 40/46 [16:11<02:11, 21.83s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 39 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and will recommend a course of treatment....\n",
      "Sample output: WHAT:\n",
      "The doctor\n",
      "\n",
      "INTR:The doctor is calling for a\n",
      "\n",
      "MUST:\n",
      "\n",
      "Possible cause(s):...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -146.96 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 40 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient's knee....\n",
      "Sample output: If the person:\n",
      "isn't talking:\n",
      "The conversation is over.\n",
      "\n",
      "\n",
      "Possible future\n",
      "\n",
      "The conversation:\n",
      "The con...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -105.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 40 - PPO step successful!\n",
      "Extracted Info: joseph is a 59 year old male who has chronic problems....\n",
      "Sample output: GENERAL:\n",
      "josephant is a current or current medical condition\n",
      "\n",
      "I am an in conversation with a patient...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████▏       | 41/46 [16:33<01:50, 22.01s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -158.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 41 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing a knee pain....\n",
      "Sample output: CALL:\n",
      "\n",
      "[01]\n",
      "[22]\n",
      "[05]\n",
      "\n",
      "[23]\n",
      "\n",
      "[24]\n",
      "\n",
      "\n",
      "[25]\n",
      "\n",
      "[26]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -114.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████▋      | 42/46 [16:53<01:25, 21.32s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 41 - PPO step successful!\n",
      "Extracted Info: Melissa sanchez is a female patient who is being seen in the office for status post mitral valve rep...\n",
      "Sample output: MULTIMED_:\n",
      "\n",
      "(not in the conversation)MIS_CLINARITY:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -83.98 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 42 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: -\n",
      "[ID]\n",
      "\n",
      "https://www.healthcare.com/professions/medicine-profession/citation-pro-sus-ad-ad_01_fb_...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -107.65 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████▎    | 43/46 [17:15<01:04, 21.66s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 42 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing pain in her elbow....\n",
      "Sample output: This conversation is now closed.\n",
      "\n",
      "Anonymous 06/10/17\n",
      "AnonymousAnonymousAnonymous: My girlfriend, I h...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -159.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 43 - PPO step successful!\n",
      "Extracted Info: The patient is a 41-year-old female....\n",
      "Sample output: [msg]Announce[this:\n",
      "\n",
      "[all:[this:]]adverification:\n",
      "\n",
      "[title:this]patient#.cnnant[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -109.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 96%|████████████████████████████████████████████████████████████████████▊   | 44/46 [17:36<00:42, 21.33s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 43 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: WHAT CONSIDER:\n",
      "problems in the case\n",
      "The caller:\n",
      "cannotate\n",
      "\n",
      ":\n",
      "(1)a(front)call:\n",
      "ad#...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -129.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 44 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -111.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 98%|██████████████████████████████████████████████████████████████████████▍ | 45/46 [17:54<00:20, 20.46s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 44 - PPO step successful!\n",
      "Extracted Info: The doctor is trying to diagnose the patient with a medical condition....\n",
      "Sample output: {title:clarval:selection:[all:title:\"\n",
      "\n",
      "[all:flair:brand:doctor=P&key:no:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -155.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 45 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: LOCATION:\n",
      "I'm inpatient,researching:\n",
      "[research topic]\n",
      "research topic:\n",
      "ad=%&action=&i=&action=&c=%&f&...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -138.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 45 - PPO step successful!\n",
      "Extracted Info: Patient is 72-year-old woman with hypertension....\n",
      "Sample output: PATP1:\n",
      "\n",
      "PID:patient\n",
      "\n",
      "AdvC:\n",
      "\n",
      "patient:\n",
      "\n",
      "hpetpetpetpetpetpetpetpet:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 46/46 [18:18<00:00, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_45\n",
      "✅ Epoch 2/3 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-epochs/epoch_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/46 [00:00<?, ?it/s]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -188.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 0 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: PREDICT:\n",
      "I. Know what this is:\n",
      "I.explanation:\n",
      "I. Know what this is the topic:\n",
      "My.explanation:\n",
      "My:pet...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -147.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 0 - PPO step successful!\n",
      "Extracted Info: joseph is a 59 year old male who has chronic problems....\n",
      "Sample output: cognis is a patient in conversation\n",
      "\n",
      "your conversation:\n",
      "\n",
      "please provide a phone number for your conc...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                       | 1/46 [00:23<17:38, 23.52s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -117.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 1 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking medications for his foot pain....\n",
      "Sample output: WHAT: The conversation:\n",
      "The conversation is about the patient's symptoms:\n",
      "What is going on\n",
      "ad:\n",
      "The c...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -145.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  4%|███▏                                                                     | 2/46 [00:43<15:48, 21.55s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 1 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: PACTOR:\n",
      "anyone:frontline or:frontline#PR:p\n",
      "\n",
      "INDEX:\n",
      "I:[current=TRUNC:currentbalance[1-4]{1...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -161.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 2 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: PATIENTS:\n",
      "\n",
      "Comment:\n",
      "*[MEDLINE_ID:1210]\n",
      "[D] Patient:\n",
      "a.\n",
      "PAT...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -194.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  7%|████▊                                                                    | 3/46 [01:05<15:27, 21.57s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 2 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: (Adv. to mention)\n",
      "\n",
      "\"The day after I woke up.\n",
      "\n",
      "[The emergency medical that the caller reported:\n",
      "\"The ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -157.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 3 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: --\n",
      ":--\n",
      "Advocate\n",
      "\n",
      "neutral:--\n",
      "Advice:--\n",
      "hotfrontp://frontpa.comfrontportal.comfrontfrontpage.com|msg=%...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -141.64 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "  9%|██████▎                                                                  | 4/46 [01:25<14:36, 20.87s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 3 - PPO step successful!\n",
      "Extracted Info: The patient has been suffering from back pain for a few years....\n",
      "Sample output: [fronttitle]expand(this[_{}\\]]{:clinchtitletitle}advancedrad:ex:report{title=}}]...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -160.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 4 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: your health care provider:\n",
      "\n",
      "your health caret:cjohnstoner@gmail.com\n",
      "\n",
      "is:johnston,v=respondin...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -214.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 11%|███████▉                                                                 | 5/46 [01:45<14:05, 20.62s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 4 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing a knee pain....\n",
      "Sample output: (front)\n",
      "\n",
      "[back]\n",
      "-\n",
      "Anonymous, research_state:\n",
      "There are currently unengaging thoughts and symptoms in...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -209.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 5 - PPO step successful!\n",
      "Extracted Info: The patient is a female who has a severe right upper arm pain....\n",
      "Sample output: INDEX:\n",
      "\"myastr:fronte:frontfront:front_138\n",
      "​Dawn: A few months ago, when I was...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -189.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 5 - PPO step successful!\n",
      "Extracted Info: The patient is concerned about her recent blood work....\n",
      "Sample output: Why (please stateprovid=comparison included(and=in)&data={prevention:partner} alert(am)existing_stat...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▌                                                               | 6/46 [02:06<13:58, 20.97s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -166.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 6 - PPO step successful!\n",
      "Extracted Info: chief complaint is chest pain...\n",
      "Sample output: PRACTING:\n",
      "your patient is complaining symptoms\n",
      "your emergency flu-related (provide a flu-aid:))provi...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -320.36 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 15%|███████████                                                              | 7/46 [02:26<13:24, 20.62s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 6 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: (...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -210.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 7 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his neck pain....\n",
      "Sample output: — The alert thought\n",
      "— The patient's complaint is reported safely usinghotfluidapiall,fastingfrontfli...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -212.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████▋                                                            | 8/46 [02:46<12:54, 20.37s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 7 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and give her a physical exam....\n",
      "Sample output: result in the research, reported case[(advengeng)f.google.your.us.flax,advengengant&share=&...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -193.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 8 - PPO step successful!\n",
      "Extracted Info: The doctor is asking about the symptoms of the patient....\n",
      "Sample output: FINDS:antaiplan[front-your-opportunity] •providerprovidersmet:probplan[advices wereproviderpristcess...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -204.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 20%|██████████████▎                                                          | 9/46 [03:07<12:38, 20.51s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 8 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: ploSound:frontlinefrontpagerfrontpaey:frontlocationfrontpagerinfofrontcellphonefrontpradeparmusfront...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -183.74 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 9 - PPO step successful!\n",
      "Extracted Info: The patient is experiencing pain in her elbow....\n",
      "Sample output: Patient(s):\n",
      "Medlineer rfer@hot.com\n",
      "flvmarkup.google:beamfrontup alert alertadvmsg:close=coflvv...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -216.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 22%|███████████████▋                                                        | 10/46 [03:28<12:25, 20.72s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 9 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: frontistingresearchfrontistingresearchadvadv thoughtspr\n",
      "\n",
      "48. Discussion:\n",
      "Possible patientengaging th...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -239.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 10 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: investigator4(s)flair:com:bmco:uk/pr13114\n",
      "\n",
      "Brand the fluflair:aberoncom,researchprobe:engaginglucyt1...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -244.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 10 - PPO step successful!\n",
      "Extracted Info: The patient is a woman with a history of type 2 diabetes and ovarian cancer....\n",
      "Sample output: investigate the patient's thoughts\n",
      "\n",
      "Advice acetam notexpiry Protect safe,pirational,neutral,:\n",
      "\n",
      "— abo...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▏                                                      | 11/46 [03:49<12:07, 20.78s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -244.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 11 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old female with a history of hypertension and diabetes ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -209.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 26%|██████████████████▊                                                     | 12/46 [04:14<12:28, 22.02s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 11 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: Pat\\t:f\\partay patient:sym\\romedays:proced_pillnum thoughts:possible_diagnose:{advadv_hy...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -166.78 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 12 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: —\n",
      "vincent_data\n",
      "advanced_plan_navigator6565\n",
      "\n",
      "(0793)​antinfo:\n",
      "met://65ageant%20advanced_03:discrep837...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -221.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 28%|████████████████████▎                                                   | 13/46 [04:36<12:04, 21.95s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 12 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and discuss the cough....\n",
      "Sample output: RROG:neutral\n",
      "\n",
      "antever(:the research.\n",
      "P65Wasser30:frontiere,luxant[fronter:uniplanay.com\\...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -341.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 13 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: neutral:|hot flaxed|...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -204.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 30%|█████████████████████▉                                                  | 14/46 [04:56<11:23, 21.36s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 13 - PPO step successful!\n",
      "Extracted Info: chief complaint is worsening headaches...\n",
      "Sample output: The alert The conversation revolved:pl Interested patient: Thisenger research:1:637ays includedadvon...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -176.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 14 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: consisting of:\n",
      "\n",
      "userdata,analysis (new alert from there)\n",
      "investengaginguserdata, user alert[.dat) al...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -174.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████▍                                                | 15/46 [05:17<10:58, 21.25s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 14 - PPO step successful!\n",
      "Extracted Info: Kayla has been using perc gel and washing regularly which is somewhat helpful....\n",
      "Sample output: —lu.\n",
      "provhotephothot[provhotpetpetpetpet]\n",
      " • (please, provider, Krebeck,metusfer...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -185.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 15 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: is coed best describes a possible day\n",
      "\n",
      "[Reference]\n",
      "[(new evidence)fl4765067 discussion(ant)advant in...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -200.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 15 - PPO step successful!\n",
      "Extracted Info: susan is a 26-year-old female who has high blood pressure....\n",
      "Sample output: hotfli\n",
      "hotfliapiattant—: hot fli, best flufahy flp syn syni fluerobic...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████                                               | 16/46 [05:38<10:33, 21.12s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -192.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 16 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: investigate why wronguse,flflcommonplace.com:\n",
      "engagingengantupdateshotfront.comfront.infrontpage 271...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -211.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████▌                                             | 17/46 [05:59<10:14, 21.20s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 16 - PPO step successful!\n",
      "Extracted Info: The doctor will call out some of the physical exam findings....\n",
      "Sample output: ( PLAT1)flavor text:\n",
      "hotfl conversation ideaflpack\n",
      "Want the most recent news, science alert:related ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -200.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 17 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: piracetone: http://www.clinney.com/patientshotarticlebreakfastpoeline:47_117316\n",
      "monthstatepiratoradv...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -252.63 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████▏                                           | 18/46 [06:19<09:46, 20.95s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 17 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: your complaint: This may be a:\n",
      "\\_related_id:flair: alert[msg]bh:kidile\\\n",
      "\n",
      "icious_info...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -254.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 18 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and recommend a physical exam....\n",
      "Sample output: best thought #1442538: •Peng related alert,prin includedplainedplusspro.ainer potential,plup. #14425...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -141.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 41%|█████████████████████████████▋                                          | 19/46 [06:40<09:24, 20.90s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 18 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: possible helpful, ifaction:advise patient,antennant—no,engostays: included,partnerflin_packattantinf...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -272.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 19 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -236.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 43%|███████████████████████████████▎                                        | 20/46 [07:05<09:33, 22.07s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 19 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: http://www.commetresearch.com/resources/pr_05065112001_pheninf_pr_052.html\n",
      "\n",
      "[ PART(8) #17761 #3771:[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -245.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 20 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her symptoms and duration....\n",
      "Sample output: PNU:theplanet[ang71[8]plains[msg32]>[PBRainerant[]\n",
      "\n",
      "Symples:prist[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -264.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 20 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's past medical history....\n",
      "Sample output: adverse_patient:[relevant]report[ alert alert] Your best patient:|[[*]report{expression:bhub}[focuse...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▊                                       | 21/46 [07:27<09:11, 22.07s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -261.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 21 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: pirations needed the previous_analysts included thoughts:\n",
      "\n",
      "favorite author better_analysts not yet a...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.73s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -262.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 48%|██████████████████████████████████▍                                     | 22/46 [07:48<08:41, 21.73s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 21 - PPO step successful!\n",
      "Extracted Info: The patient is a female with acid reflux....\n",
      "Sample output: —provide information or the research.\n",
      "nyseless_bi:\n",
      "—(leagueantas_adv thoughts, \"Hey from my research...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -264.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 22 - PPO step successful!\n",
      "Extracted Info: The doctor will recommend a course of antibiotics for the patient....\n",
      "Sample output: PFLIDINGPLAPTERID:\n",
      "Pat_|lux:|Your research result:[brighterblue}hothot[hot>bh\\resourceshot@@...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -428.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 50%|████████████████████████████████████                                    | 23/46 [08:07<08:04, 21.08s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 22 - PPO step successful!\n",
      "Extracted Info: Raymond has been having trouble swallowing for a period of time. He has been having trouble swallowi...\n",
      "Sample output: ...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -310.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 23 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient 's recent illness ....\n",
      "Sample output: \n",
      "Generate a concise medical summary focusing on key findings and treatment plans. Include chief comp...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -353.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████▌                                  | 24/46 [08:32<08:08, 22.20s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 23 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: procedant:\n",
      "Your patientresearching:[attention]uppectingant[is the likely outcome of the forward rese...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -311.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 24 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: report thesym in the safe alert patient(s:\n",
      "investigator[:[:]pi_pl[msg][[ ]adavant]|[i[](pl[result|[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -364.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 54%|███████████████████████████████████████▏                                | 25/46 [08:53<07:34, 21.66s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 24 - PPO step successful!\n",
      "Extracted Info: Lawrence is a 62-year-old male with a past medical history significant for type i diabetes, congesti...\n",
      "Sample output: <paran|in|in search for research[.]\n",
      "<...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -457.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 25 - PPO step successful!\n",
      "Extracted Info: Julia has had a heart attack and is undergoing treatment. She has had a stent placed in her heart. J...\n",
      "Sample output: [br][ci][(eng)pr[001...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -296.23 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 25 - PPO step successful!\n",
      "Extracted Info: The patient is currently taking painkillers to treat the pain....\n",
      "Sample output: [par alert alert]\n",
      "[investigation recommended patient information:\n",
      "[Pup:[]([[]black[avi][[[Current al...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████▋                               | 26/46 [09:13<07:08, 21.42s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -252.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 26 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: You should:\n",
      "\n",
      "[This topic: reported symptoms[msg]report[[relevant]]\n",
      "[[this7165[][report]msg[[[#[{[[1....\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -190.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 59%|██████████████████████████████████████████▎                             | 27/46 [09:35<06:45, 21.33s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 26 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: [relevant_plains[msg]patient[1]is ill[[msg] Dr[[[this] explains howphenmet[[[[[Brand[[[[[][case[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -364.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 27 - PPO step successful!\n",
      "Extracted Info: The patient is a 31-year-old female with a history of diabetes and asthma....\n",
      "Sample output: [sym:]keypro_238 patient[ant[: patient[[]this[report]][met[key[ex[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -381.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 61%|███████████████████████████████████████████▊                            | 28/46 [09:54<06:15, 20.87s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 27 - PPO step successful!\n",
      "Extracted Info: The doctor will check up on the patient's health and recommend treatment....\n",
      "Sample output: Pus:you reported theengustant[ant's physician:your{investigation[:bhup_pack\\attpro_1][[](...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -264.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 28 - PPO step successful!\n",
      "Extracted Info: Patient is a 60 year old, right-handed male, referred today for evaluation of numbness and tingling....\n",
      "Sample output: invested information:\n",
      "plant, hypothesis[13[[ patient included]*, patient[eng...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -294.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 63%|█████████████████████████████████████████████▍                          | 29/46 [10:14<05:47, 20.42s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 28 - PPO step successful!\n",
      "Extracted Info: Chief complaint is abnormal renal ultrasound with an atrophic right kidney....\n",
      "Sample output: PLUG:\n",
      "[insert patient]{friend[2][{:[msg[1]report[[[[_key[[[]{...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -455.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 29 - PPO step successful!\n",
      "Extracted Info: William is a doctor. He is treating a patient who injured his knee....\n",
      "Sample output: hotflair thoughtsplainingpricplound patient:\n",
      "beck:\n",
      "investing[ACTION_PLU[keykey:key]result[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -365.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 65%|██████████████████████████████████████████████▉                         | 30/46 [10:34<05:23, 20.23s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 29 - PPO step successful!\n",
      "Extracted Info: Michael is seeing a doctor for back pain....\n",
      "Sample output: invest in:\n",
      "[: patient]msg08[[research]\n",
      "[Michael Dr[[[[[[[up[[[[[[[P][{#ad...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -338.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 30 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient's knee....\n",
      "Sample output: :: The guest reported the thought patient:\n",
      "[adrow thoughts[1][Advicious thoughts[7][met[[2018:[[]([u...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -247.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 30 - PPO step successful!\n",
      "Extracted Info: Melissa sanchez is a female patient who is being seen in the office for status post mitral valve rep...\n",
      "Sample output: (:\n",
      "report fl:>pulsefl Ms.sympor flpray incengenging{avi thought...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████▌                       | 31/46 [10:54<05:05, 20.37s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -229.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 31 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: .\n",
      "no longer should mention:\n",
      "[symple[report](treatment thoughtivation[newengplplex patient[[name|new[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -300.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 70%|██████████████████████████████████████████████████                      | 32/46 [11:16<04:49, 20.65s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 31 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the patient and will recommend a course of treatment....\n",
      "Sample output: plaint: the alert patienteng:\n",
      "lookup: thehotfl: this topiceng:plkid todaypartagen:bhk:hanalertplkid...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -305.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 32 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: INP:\n",
      "investing the thoughts, ideas, andpr comments your patient:\n",
      "kid thoughts:\n",
      "result:pro patient,<k...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -321.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████▋                    | 33/46 [11:36<04:25, 20.46s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 32 - PPO step successful!\n",
      "Extracted Info: The doctor is concerned about the patient's health....\n",
      "Sample output: expiration:engile seeking new information[amerant contact included:\n",
      "Neet:Dric(8)hotex[newengengant p...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -254.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 33 - PPO step successful!\n",
      "Extracted Info: The patient has been in a car accident and has been experiencing neck pain....\n",
      "Sample output: adverse_plist:<br_viner<\\ patient wasprov[msg[(friend.sym[key[msg>]}:[{...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -289.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████▏                  | 34/46 [11:55<04:03, 20.26s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 33 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about her knee pain....\n",
      "Sample output: Pound:ant or\n",
      "[swedinger_pi]ant:key idea patient reportedkey topic:\n",
      "[1 theadpr using rhumbian prospec...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -353.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 34 - PPO step successful!\n",
      "Extracted Info: The patient has a foot ulcer that has been there for six weeks....\n",
      "Sample output: invest interest in the patient: theenger reported best care ProviderPossible patient:expirater the p...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -278.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 76%|██████████████████████████████████████████████████████▊                 | 35/46 [12:15<03:42, 20.18s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 34 - PPO step successful!\n",
      "Extracted Info: The doctor will examine the ankle and will recommend a course of treatment....\n",
      "Sample output: Sym report:\n",
      "my health care[feynreport included included[{keyprkeyname[ Schiurgant[luxlux[result thou...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.24s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -288.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 35 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: investigating treatmentplan idea:\n",
      "patient:co:leagueantpeng\n",
      "eng[parpet patient[pet[P[2013]*[invest[[P...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -256.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 35 - PPO step successful!\n",
      "Extracted Info: Karen is a 34-year-old female with a history of chronic migraines and hypertension who is here today...\n",
      "Sample output: PACTION:\n",
      "P([K]up)�[[ult[bre_...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████▎               | 36/46 [12:36<03:24, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -333.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 36 - PPO step successful!\n",
      "Extracted Info: The patient has a complaint of ankle pain after a fall....\n",
      "Sample output: (:)[adpiantultulinstainingmedicmsgile patient[:[[{possible patient[key1]][[[[[[[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -379.71 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 80%|█████████████████████████████████████████████████████████▉              | 37/46 [12:57<03:04, 20.47s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 36 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: Possible complaint(s):\n",
      "Possible patient(thisengengengengengengengengengengengeng[[{[hotengengengenge...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -337.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 37 - PPO step successful!\n",
      "Extracted Info: The patient has a broken wrist....\n",
      "Sample output: :\n",
      "ENGRAIND EXplan: your patient's research.:\n",
      "KP: yourhotant patient[patient]{facingant[new[[[[[][ Pl...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -205.74 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 83%|███████████████████████████████████████████████████████████▍            | 38/46 [13:18<02:45, 20.63s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 37 - PPO step successful!\n",
      "Extracted Info: Patient is 72-year-old woman with hypertension....\n",
      "Sample output: [:[ Advicult(prot=[[]([[[[[[present[[[[[[[Med[[[pic[hot...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -326.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 38 - PPO step successful!\n",
      "Extracted Info: The patient is a 37-year-old male with a complaint of left arm pain....\n",
      "Sample output: pir_pr:pa_bh_hotami patient[bh[P_bh]patient[{p1}[bh]pl...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -223.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 85%|█████████████████████████████████████████████████████████████           | 39/46 [13:38<02:22, 20.36s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 38 - PPO step successful!\n",
      "Extracted Info: The doctor is trying to diagnose the patient with a medical condition....\n",
      "Sample output: Couples are the most important relationships in your relationship.You are a family seeking a romanti...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -314.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 39 - PPO step successful!\n",
      "Extracted Info: The patient is a 41-year-old female....\n",
      "Sample output: MIND:\n",
      "[lux topic]t:[collux[Pager]bi[{[phenet[cell[result]]{plant[@@[pr...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -268.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████▌         | 40/46 [13:58<02:01, 20.20s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 39 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: FINANAST:PR:[patient[random patient[f[related]expired_sym[]]p[[P[[agenic][[[charged...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -339.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 40 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: symferred:\n",
      "Advant[[c]investing[[[[[[[[[{[Eco[[[[[[[[[[[[[[[[ult...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -273.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 40 - PPO step successful!\n",
      "Extracted Info: The patient is a 57-year-old female who is here for a surgical consult....\n",
      "Sample output: (pr:leagueant:[[key]patient[[related] patient included[[[Reference[[[[[[[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████▏       | 41/46 [14:19<01:42, 20.47s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -355.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 41 - PPO step successful!\n",
      "Extracted Info: chief complaint is acid reflux...\n",
      "Sample output: prister:key[[Symple patient:key[ex[[[[[[[[[[[[[[[[[[[[[[[[[[[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -322.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████▋      | 42/46 [14:39<01:21, 20.36s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 41 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his back pain....\n",
      "Sample output: ex:[1][:[[[[[[[{ Hulsult[[[[[[[current patient[ Huls[[engant[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -288.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 42 - PPO step successful!\n",
      "Extracted Info: The patient is an 82-year-old male with past medical history significant for hypertension and stage ...\n",
      "Sample output: sym reported in the discussion:...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -338.50 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████▎    | 43/46 [14:59<01:00, 20.19s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 42 - PPO step successful!\n",
      "Extracted Info: The patient has a complaint of knee pain....\n",
      "Sample output: possible patient: patient in discussion topic:\n",
      "co:\n",
      "investing in the discussion:\n",
      "pr:\n",
      "luk:>>>>>>>>>>>>...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -346.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 43 - PPO step successful!\n",
      "Extracted Info: The doctor is asking the patient about his current medical condition....\n",
      "Sample output: Pus: included patient.flunk the patient information:pr comment patient in the patient[[investing]:\n",
      "1...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -293.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 96%|████████████████████████████████████████████████████████████████████▊   | 44/46 [15:18<00:40, 20.13s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 43 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: call:\n",
      "cenging:met patient[behavior thoughtspr[behavior[[[related[:key][ant[[case[[br[[[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -268.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 44 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: in interested, based in the discussion\n",
      "IN:\n",
      "Neeting: Sunkprowult[relevant[[ P ]erer[ Ms.P[@[ Ms.S[[[@...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -292.49 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 98%|██████████████████████████████████████████████████████████████████████▍ | 45/46 [15:39<00:20, 20.09s/it]Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 44 - PPO step successful!\n",
      "Extracted Info: The doctor will discuss the patient's symptoms and current medications....\n",
      "Sample output: investing thoughts:\n",
      "pr[[adpet the topic] patient:[[[Pat[[ Mikkel Ackes]([[[[[[[[...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -324.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 in batch 45 - PPO step successful!\n",
      "Extracted Info: chief complaint is back pain...\n",
      "Sample output: partic the idea:\n",
      "(plains: patient recommended co:\n",
      "engile patient[[bre: patient[[[{P24[[[Pat[[P] rhyn...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=96) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 2 samples !!!\n",
      "Error in evaluate: 'reference'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -309.50 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 in batch 45 - PPO step successful!\n",
      "Extracted Info: Symptoms and duration...\n",
      "Sample output: if:\n",
      "expiratory thoughts:\n",
      "yn:[relevant relenged no symptoms orexing.P inpiration:enging discussion[en...\n",
      "Average reward: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 46/46 [16:00<00:00, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_45\n",
      "✅ Epoch 3/3 complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch checkpoint saved to D:/kshitij-weights-folder/gpt-2-tuned-ppo-epochs/epoch_3\n",
      "🎉 PPO fine-tuning done\n",
      "Model saved to D:\\kshitij-weights-folder\\gpt-2-tuned-ppo-extracted\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments\n",
    "from trl import RewardTrainer, PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "import bitsandbytes as bnb\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "# Add UniEval to path and import\n",
    "sys.path.append(r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"combined_clinical_notes.csv\"\n",
    "MODEL_PATH = \"gpt2\" \n",
    "EXTRACTION_MODEL_PATH = \"bigscience/bloomz-1b7\"  # Model for extracting key information\n",
    "# Enhanced prompt with more guidance\n",
    "MEDICAL_PROMPT = \"\\nGenerate a concise medical summary focusing on key findings and treatment plans. Include chief complaints, symptoms, medications, and recommendations if mentioned in the conversation:\"\n",
    "\n",
    "# Initialize the extraction model\n",
    "print(f\"Loading extraction model from {EXTRACTION_MODEL_PATH}...\")\n",
    "extraction_tokenizer = AutoTokenizer.from_pretrained(EXTRACTION_MODEL_PATH)\n",
    "extraction_model = AutoModelForCausalLM.from_pretrained(\n",
    "    EXTRACTION_MODEL_PATH,\n",
    "    torch_dtype=torch.float16,  # Use fp16 for efficiency\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "def extract_medical_info(conversation, max_length=300):\n",
    "    \"\"\"Use the extraction model to pull out key medical information\"\"\"\n",
    "    extraction_prompt = (\n",
    "        \"Extract these key medical information points from the conversation below:\\n\"\n",
    "        \"- Chief complaint\\n\"\n",
    "        \"- Symptoms and duration\\n\"\n",
    "        \"- Current medications\\n\"\n",
    "        \"- Vital signs\\n\"\n",
    "        \"- Physical exam findings\\n\"\n",
    "        \"- Recommendations\\n\\n\"\n",
    "        f\"Conversation:\\n{conversation}\\n\\n\"\n",
    "        \"Extracted information:\"\n",
    "    )\n",
    "    \n",
    "    # Truncate long conversations if needed\n",
    "    if len(extraction_prompt.split()) > 800:\n",
    "        conversation_words = conversation.split()\n",
    "        truncated_conversation = \" \".join(conversation_words[:700])\n",
    "        extraction_prompt = extraction_prompt.replace(conversation, truncated_conversation)\n",
    "    \n",
    "    inputs = extraction_tokenizer(extraction_prompt, return_tensors=\"pt\").to(extraction_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            outputs = extraction_model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=len(inputs.input_ids[0]) + max_length,  # Allow for generated content\n",
    "                temperature=0.3,  # Lower temperature for more deterministic extraction\n",
    "                top_p=0.95\n",
    "            )\n",
    "            \n",
    "            extracted_info = extraction_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Remove the prompt part\n",
    "            if extraction_prompt in extracted_info:\n",
    "                extracted_info = extracted_info.replace(extraction_prompt, \"\").strip()\n",
    "            else:\n",
    "                # Try to find a reasonable place to split the text\n",
    "                # This helps when the model modifies the prompt slightly\n",
    "                prompt_end = \"Extracted information:\"\n",
    "                if prompt_end in extracted_info:\n",
    "                    extracted_info = extracted_info.split(prompt_end)[1].strip()\n",
    "            \n",
    "            return extracted_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in extraction model: {e}\")\n",
    "            # Return a simplified fallback extraction\n",
    "            return \"Unable to extract detailed information. Please see the original conversation.\"\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "eval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "dataset = Dataset.from_pandas(eval_df.rename(columns={\"dialogue\": \"review\"}))\n",
    "\n",
    "# Tokenizer setup\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Dataset preprocessing\n",
    "def preprocess_function(examples):\n",
    "    return {\n",
    "        \"input_ids\": tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512),\n",
    "        \"query\": tokenizer.decode(tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512), skip_special_tokens=True)\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=False)\n",
    "dataset.set_format(\"pytorch\")\n",
    "\n",
    "# Model configuration\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# PEFT/LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model, peft_config=lora_config).to(\"cuda\")\n",
    "\n",
    "# Reference model\n",
    "ref_model = create_reference_model(model).to(\"cuda\")\n",
    "ref_model.eval()\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "NUM_CANDIDATES = 2\n",
    "\n",
    "# PPO Configuration\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=MODEL_PATH,\n",
    "    ppo_epochs=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    steps=5,\n",
    "    batch_size=1*NUM_CANDIDATES,\n",
    "    mini_batch_size=1*NUM_CANDIDATES,\n",
    "    learning_rate=2e-5,\n",
    "    log_with=None,\n",
    ")\n",
    "\n",
    "# Initialize PPO Trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=ppo_config,\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    optimizer=bnb.optim.Adam8bit(model.parameters(), lr=ppo_config.learning_rate)\n",
    ")\n",
    "\n",
    "# Initialize evaluation model\n",
    "sum_eval = get_evaluator(\"summarization\", device=\"cpu\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(data, overall=False):\n",
    "    \"\"\"Wrapper around sum_eval.evaluate to handle errors\"\"\"\n",
    "    try:\n",
    "        return sum_eval.evaluate(data, overall=overall)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluate: {e}\")\n",
    "        # Return default scores if evaluation fails\n",
    "        return [[0.5, 0.5, 0.5, 0.5]] * len(data)\n",
    "\n",
    "def get_score(src, res):\n",
    "    \"\"\"Calculate rewards based on evaluation scores\"\"\"\n",
    "    data = convert_to_json(\n",
    "        output_list=res,\n",
    "        src_list=src,\n",
    "    )\n",
    "    \n",
    "    raw = evaluate(data, overall=False)\n",
    "    score = [\n",
    "        [d[0], d[1], d[2], d[3]]\n",
    "        for d in raw\n",
    "    ]\n",
    "    scores = np.array(score, dtype=np.float32)\n",
    "    k = len(res)\n",
    "    dom_counts = np.zeros(k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            if i == j:\n",
    "                continue\n",
    "            # Check dominance: i dominates j if all scores are >= and at least one is >\n",
    "            if np.all(scores[i] >= scores[j]) and np.any(scores[i] > scores[j]):\n",
    "                dom_counts[i] += 1\n",
    "    \n",
    "    # Convert to [-1, 1] range reward\n",
    "    max_dom = k - 1\n",
    "    if max_dom > 0:\n",
    "        rewards = 2 * (dom_counts / max_dom) - 1\n",
    "    else:\n",
    "        rewards = np.zeros(k)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "max_position_embeddings = model.pretrained_model.config.max_position_embeddings \n",
    "\n",
    "# Training loop with improved generation parameters\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"eos_token_id\": -1,\n",
    "    \"max_length\": max_position_embeddings,\n",
    "    \"max_new_tokens\": 96,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "COMPUTE_DTYPE = torch.float32  # Using float32 to avoid dtype issues\n",
    "\n",
    "# Track extract-summarize cache to avoid recomputing\n",
    "extract_cache = {}\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch_idx, batch in enumerate(tqdm(ppo_trainer.dataloader)):\n",
    "        logs, game_data = dict(), dict()\n",
    "        game_data[\"query\"] = [q for q in batch[\"query\"]]\n",
    "        query_tensors = [input_ids for input_ids in batch[\"input_ids\"]]\n",
    "        \n",
    "        # Process one query at a time to prevent batch size mismatch\n",
    "        for query_idx, query in enumerate(query_tensors):\n",
    "            try:\n",
    "                # Skip empty or very short queries\n",
    "                if len(query) < 10:\n",
    "                    print(f\"Skipping query {query_idx}: too short\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate NUM_CANDIDATES responses for this query\n",
    "                responses = []\n",
    "                decoded_responses = []\n",
    "                \n",
    "                # Get original text and extract key information\n",
    "                original_notes = tokenizer.decode(query)\n",
    "                \n",
    "                # Check cache first to avoid redundant extractions\n",
    "                if original_notes in extract_cache:\n",
    "                    extracted_info = extract_cache[original_notes]\n",
    "                else:\n",
    "                    extracted_info = extract_medical_info(original_notes)\n",
    "                    extract_cache[original_notes] = extracted_info\n",
    "                \n",
    "                # Construct enhanced prompt with extracted information\n",
    "                full_prompt = (\n",
    "                    f\"{MEDICAL_PROMPT}\\n\"\n",
    "                    f\"KEY INFORMATION:\\n{extracted_info}\\n\\n\"\n",
    "                    \"Based on the above, generate a concise medical summary:\"\n",
    "                )\n",
    "                \n",
    "                # Encode the full prompt\n",
    "                full_prompt_tensor = tokenizer.encode(full_prompt, return_tensors=\"pt\").to(\"cuda\").squeeze(0)\n",
    "                \n",
    "                for _ in range(NUM_CANDIDATES):\n",
    "                    with torch.no_grad():\n",
    "                        response = ppo_trainer.generate(\n",
    "                            full_prompt_tensor,\n",
    "                            **generation_kwargs\n",
    "                        )\n",
    "                    # Ensure response doesn't exceed max length\n",
    "                    response = response[:, :generation_kwargs[\"max_new_tokens\"]]\n",
    "                    responses.append(response.squeeze())\n",
    "                    \n",
    "                    # Decode for evaluation\n",
    "                    text = tokenizer.decode(response.squeeze(), skip_special_tokens=True)\n",
    "                    \n",
    "                    # Extract just the generated part (often it repeats the prompt)\n",
    "                    if full_prompt in text:\n",
    "                        generated_text = text.split(full_prompt)[1].strip()\n",
    "                    else:\n",
    "                        generated_text = text\n",
    "                        \n",
    "                    decoded_responses.append(generated_text)\n",
    "                \n",
    "                # Calculate rewards\n",
    "                rewards = get_score(\n",
    "                    [game_data[\"query\"][query_idx]] * NUM_CANDIDATES, \n",
    "                    decoded_responses\n",
    "                )\n",
    "                \n",
    "                # Prepare data for PPO step\n",
    "                flat_queries = [query] * NUM_CANDIDATES\n",
    "                flat_responses = responses\n",
    "                flat_rewards = [torch.tensor([r], device=DEVICE, dtype=COMPUTE_DTYPE) for r in rewards]\n",
    "                \n",
    "                # Verify sizes match\n",
    "                if len(flat_queries) == NUM_CANDIDATES and len(flat_responses) == NUM_CANDIDATES and len(flat_rewards) == NUM_CANDIDATES:\n",
    "                    # Do PPO step for this query\n",
    "                    stats = ppo_trainer.step(\n",
    "                        queries=flat_queries,\n",
    "                        responses=flat_responses,\n",
    "                        scores=flat_rewards\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"Query {query_idx} in batch {batch_idx} - PPO step successful!\")\n",
    "                    print(f\"Extracted Info: {extracted_info[:100]}...\")\n",
    "                    print(f\"Sample output: {decoded_responses[0][:100]}...\")\n",
    "                    avg_reward = np.mean([r.item() for r in flat_rewards])\n",
    "                    print(f\"Average reward: {avg_reward:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Skipping query {query_idx} due to size mismatch: queries={len(flat_queries)}, responses={len(flat_responses)}, rewards={len(flat_rewards)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query {query_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Save checkpoint after each batch\n",
    "        if batch_idx % 5 == 0:\n",
    "            checkpoint_path = f\"D:/kshitij-weights-folder/gpt-2-tuned-ppo-checkpoints/batch_{batch_idx}\"\n",
    "            try:\n",
    "                os.makedirs(checkpoint_path, exist_ok=True)\n",
    "                ppo_trainer.model.pretrained_model.save_pretrained(checkpoint_path)\n",
    "                tokenizer.save_pretrained(checkpoint_path)\n",
    "                print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving checkpoint: {e}\")\n",
    "                \n",
    "    print(f\"✅ Epoch {epoch+1}/3 complete\")\n",
    "    \n",
    "    # Save epoch checkpoint\n",
    "    epoch_path = f\"D:/kshitij-weights-folder/gpt-2-tuned-ppo-epochs/epoch_{epoch+1}\"\n",
    "    os.makedirs(epoch_path, exist_ok=True)\n",
    "    ppo_trainer.model.pretrained_model.save_pretrained(epoch_path)\n",
    "    tokenizer.save_pretrained(epoch_path)\n",
    "    print(f\"Epoch checkpoint saved to {epoch_path}\")\n",
    "    \n",
    "print(\"🎉 PPO fine-tuning done\")\n",
    "\n",
    "# Save the final model\n",
    "save_path = r\"D:\\kshitij-weights-folder\\gpt-2-tuned-ppo-extracted\"\n",
    "ppo_trainer.model.pretrained_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d9abf-ba31-4f69-9a1b-1b219279ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer.model.pretrained_model.save_pretrained(\"D:\\kshitij-weights-folder\\gpt-2-tuned-ppo\")\n",
    "tokenizer.save_pretrained(\"D:\\kshitij-weights-folder\\gpt-2-tuned-ppo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26e958d-e7e3-466a-9961-7a6163a44cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda for inference\n",
      "Loading model from C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\reward_model_best_20250504-131132\\best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries with multiple strategies...\n",
      "\n",
      "Generating with template: basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█████████▎                                                                | 1/8 [00:08<01:00,  8.68s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██████████████████▌                                                       | 2/8 [00:17<00:51,  8.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███████████████████████████▊                                              | 3/8 [00:25<00:42,  8.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████████████████████████████████████                                     | 4/8 [00:33<00:33,  8.41s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████████████████████████████████████████████▎                           | 5/8 [00:41<00:24,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████████████████████████████████████████████████████▌                  | 6/8 [00:49<00:16,  8.21s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████████████████████████████████████████████████████████████▊         | 7/8 [00:58<00:08,  8.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 8/8 [01:03<00:00,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating with template: medical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█████████▎                                                                | 1/8 [00:08<00:58,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██████████████████▌                                                       | 2/8 [00:16<00:50,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███████████████████████████▊                                              | 3/8 [00:25<00:41,  8.39s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████████████████████████████████████                                     | 4/8 [00:33<00:33,  8.36s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████████████████████████████████████████████▎                           | 5/8 [00:41<00:24,  8.29s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████████████████████████████████████████████████████▌                  | 6/8 [00:49<00:16,  8.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████████████████████████████████████████████████████████████▊         | 7/8 [00:57<00:08,  8.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 8/8 [01:02<00:00,  7.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating with template: extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█████████▎                                                                | 1/8 [00:08<00:56,  8.12s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██████████████████▌                                                       | 2/8 [00:16<00:49,  8.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███████████████████████████▊                                              | 3/8 [00:24<00:41,  8.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████████████████████████████████████                                     | 4/8 [00:33<00:33,  8.31s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████████████████████████████████████████████▎                           | 5/8 [00:41<00:24,  8.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████████████████████████████████████████████████████▌                  | 6/8 [00:49<00:16,  8.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████████████████████████████████████████████████████████████▊         | 7/8 [00:57<00:08,  8.22s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 8/8 [01:03<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating with template: summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█████████▎                                                                | 1/8 [00:08<00:57,  8.24s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██████████████████▌                                                       | 2/8 [00:16<00:49,  8.21s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 38%|███████████████████████████▊                                              | 3/8 [00:24<00:40,  8.12s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████████████████████████████████████                                     | 4/8 [00:32<00:32,  8.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████████████████████████████████████████████▎                           | 5/8 [00:41<00:24,  8.25s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████████████████████████████████████████████████████▌                  | 6/8 [00:48<00:15,  7.88s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████████████████████████████████████████████████████████████▊         | 7/8 [00:55<00:07,  7.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 8/8 [01:00<00:00,  7.60s/it]\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating template: basic\n",
      "Running UniEval for basic...\n",
      "Evaluating coherence of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 53/53 [00:38<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 53/53 [00:08<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------+----------+\n",
      "|  Dimensions |  Score   |\n",
      "+-------------+----------+\n",
      "|  coherence  | 0.729489 |\n",
      "| consistency | 0.693662 |\n",
      "|   fluency   | 0.664537 |\n",
      "|  relevance  | 0.637932 |\n",
      "|   overall   | 0.681405 |\n",
      "+-------------+----------+\n",
      "\n",
      "Evaluating template: medical\n",
      "Running UniEval for medical...\n",
      "Evaluating coherence of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 54/54 [00:40<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 54/54 [00:08<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------+----------+\n",
      "|  Dimensions |  Score   |\n",
      "+-------------+----------+\n",
      "|  coherence  | 0.714625 |\n",
      "| consistency | 0.696109 |\n",
      "|   fluency   | 0.642933 |\n",
      "|  relevance  | 0.59011  |\n",
      "|   overall   | 0.660944 |\n",
      "+-------------+----------+\n",
      "\n",
      "Evaluating template: extract\n",
      "Running UniEval for extract...\n",
      "Evaluating coherence of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 55/55 [00:48<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 55/55 [00:08<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------+----------+\n",
      "|  Dimensions |  Score   |\n",
      "+-------------+----------+\n",
      "|  coherence  | 0.771288 |\n",
      "| consistency | 0.725809 |\n",
      "|   fluency   | 0.646127 |\n",
      "|  relevance  | 0.659091 |\n",
      "|   overall   | 0.700579 |\n",
      "+-------------+----------+\n",
      "\n",
      "Evaluating template: summary\n",
      "Running UniEval for summary...\n",
      "Evaluating coherence of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 54/54 [00:46<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 54/54 [00:08<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating relevance of 30 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------+----------+\n",
      "|  Dimensions |  Score   |\n",
      "+-------------+----------+\n",
      "|  coherence  | 0.690897 |\n",
      "| consistency | 0.696593 |\n",
      "|   fluency   | 0.627376 |\n",
      "|  relevance  | 0.621353 |\n",
      "|   overall   | 0.659055 |\n",
      "+-------------+----------+\n",
      "\n",
      "=== Basic Template Results ===\n",
      "Average Coherence: 0.7295\n",
      "Average Consistency: 0.6937\n",
      "Average Fluency: 0.6645\n",
      "Average Relevance: 0.6379\n",
      "Overall Average: 0.6814\n",
      "\n",
      "=== Medical Template Results ===\n",
      "Average Coherence: 0.7146\n",
      "Average Consistency: 0.6961\n",
      "Average Fluency: 0.6429\n",
      "Average Relevance: 0.5901\n",
      "Overall Average: 0.6609\n",
      "\n",
      "=== Extract Template Results ===\n",
      "Average Coherence: 0.7713\n",
      "Average Consistency: 0.7258\n",
      "Average Fluency: 0.6461\n",
      "Average Relevance: 0.6591\n",
      "Overall Average: 0.7006\n",
      "\n",
      "=== Summary Template Results ===\n",
      "Average Coherence: 0.6909\n",
      "Average Consistency: 0.6966\n",
      "Average Fluency: 0.6274\n",
      "Average Relevance: 0.6214\n",
      "Overall Average: 0.6591\n",
      "\n",
      "🏆 Best Template: Extract with Overall Score: 0.7006\n"
     ]
    }
   ],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "# Enhanced Testing Script for Reward-Based Trained Model\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Create results directory\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RESULTS_DIR = f\"evaluation_results_{timestamp}\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Check if CUDA is available for inference\n",
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "DEVICE = \"cuda\" if CUDA_AVAILABLE else \"cpu\"\n",
    "print(f\"Using device: {DEVICE} for inference\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1) Load the trained model weights\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Path to the saved model weights - try all promising models\n",
    "MODEL_PATHS = [\n",
    "    r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\reward_model_best_20250504-131132\\best_model\",  # Best model if available\n",
    "]\n",
    "\n",
    "# Try to load the best available model\n",
    "loaded_model_path = None\n",
    "for path in MODEL_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        loaded_model_path = path\n",
    "        break\n",
    "\n",
    "if not loaded_model_path:\n",
    "    raise ValueError(\"No valid model path found. Please check the model paths.\")\n",
    "\n",
    "print(f\"Loading model from {loaded_model_path}\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(loaded_model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(loaded_model_path)\n",
    "\n",
    "# Ensure pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"  # Important for decoder-only models\n",
    "model = model.to(DEVICE)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define prompt templates to test - using the same ones from training\n",
    "PROMPT_TEMPLATES = [\n",
    "    \"Summarize the following conversation:\\n\\n\",\n",
    "    \"Generate a concise medical summary of the conversation:\\n\\n\",\n",
    "    \"Extract key medical information from the following conversation:\\n\\n\",\n",
    "    \"Provide a summary of this medical dialogue:\\n\\n\"\n",
    "]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2) Prepare test dataset with more samples\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Load test data\n",
    "df = pd.read_csv(r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\combined_clinical_notes.csv\")\n",
    "test_size = 30  # Using more samples for more robust evaluation\n",
    "test_df = df.sample(test_size, random_state=42)  # Fixed random state for reproducibility\n",
    "\n",
    "# Prepare test dialogues and references\n",
    "dialogues = test_df[\"dialogue\"].tolist()\n",
    "references = test_df[\"note\"].tolist()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3) Generate summaries with multiple generation strategies\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "print(\"Generating summaries with multiple strategies...\")\n",
    "\n",
    "# We'll test different generation strategies\n",
    "generation_strategies = {\n",
    "    \"greedy\": {\n",
    "        \"description\": \"Greedy Decoding\",\n",
    "        \"params\": {\n",
    "            \"do_sample\": False,\n",
    "            \"num_beams\": 1,\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"no_repeat_ngram_size\": 3,\n",
    "        }\n",
    "    },\n",
    "    \"beam\": {\n",
    "        \"description\": \"Beam Search\",\n",
    "        \"params\": {\n",
    "            \"do_sample\": False,\n",
    "            \"num_beams\": 5,\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"no_repeat_ngram_size\": 3,\n",
    "        }\n",
    "    },\n",
    "    \"sample\": {\n",
    "        \"description\": \"Sampling\",\n",
    "        \"params\": {\n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.92,\n",
    "            \"top_k\": 50,\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"no_repeat_ngram_size\": 3,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Try all prompt templates with best generation strategy\n",
    "prompt_results = {}\n",
    "for template_name, template in zip([\"basic\", \"medical\", \"extract\", \"summary\"], PROMPT_TEMPLATES):\n",
    "    print(f\"\\nGenerating with template: {template_name}\")\n",
    "    \n",
    "    batch_size = 4\n",
    "    num_samples = len(dialogues)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        start, end = i*batch_size, min((i+1)*batch_size, num_samples)\n",
    "        convs = dialogues[start:end]\n",
    "        \n",
    "        # Create prompts with this template\n",
    "        prompts = [\n",
    "            f\"{template}{c}\"\n",
    "            for c in convs if len(str(c).strip()) > 10\n",
    "        ]\n",
    "        \n",
    "        if not prompts:\n",
    "            continue\n",
    "        \n",
    "        # Tokenize\n",
    "        enc = tokenizer(\n",
    "            prompts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # Use beam search for best quality\n",
    "        with torch.no_grad():\n",
    "            out_ids = model.generate(\n",
    "                input_ids=enc.input_ids,\n",
    "                attention_mask=enc.attention_mask,\n",
    "                **generation_strategies[\"beam\"][\"params\"]\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        dec = tokenizer.batch_decode(out_ids, skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the generated part (not including the prompt)\n",
    "        cleaned_predictions = []\n",
    "        for p, original_prompt in zip(dec, prompts):\n",
    "            # Try to extract just the generated part\n",
    "            if original_prompt in p:\n",
    "                generated_part = p[p.find(original_prompt) + len(original_prompt):]\n",
    "                cleaned_predictions.append(generated_part.strip())\n",
    "            else:\n",
    "                # If we can't find the prompt, use the whole generation\n",
    "                cleaned_predictions.append(p.strip())\n",
    "        \n",
    "        predictions.extend(cleaned_predictions)\n",
    "    \n",
    "    prompt_results[template_name] = predictions[:num_samples]  # Ensure same length\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4) Evaluate with UniEval\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "# Keep UniEval on CPU (more stable)\n",
    "sum_eval = get_evaluator(\"summarization\", device=\"cuda\")\n",
    "\n",
    "# Evaluate each prompt template\n",
    "template_scores = {}\n",
    "\n",
    "for template_name, predictions in prompt_results.items():\n",
    "    print(f\"\\nEvaluating template: {template_name}\")\n",
    "    \n",
    "    # Trim predictions and references to the same length\n",
    "    min_len = min(len(predictions), len(references), len(dialogues))\n",
    "    template_predictions = predictions[:min_len]\n",
    "    template_references = references[:min_len]\n",
    "    template_dialogues = dialogues[:min_len]\n",
    "    \n",
    "    # Create JSON data for UniEval\n",
    "    data = convert_to_json(\n",
    "        src_list=[str(d) for d in template_dialogues],\n",
    "        ref_list=[str(r) for r in template_references],\n",
    "        output_list=[str(p) for p in template_predictions]\n",
    "    )\n",
    "    \n",
    "    # Run evaluation\n",
    "    print(f\"Running UniEval for {template_name}...\")\n",
    "    scores = sum_eval.evaluate(data, print_result=True)\n",
    "    template_scores[template_name] = scores\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5) Find the best template and analyze results\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "template_avgs = {}\n",
    "\n",
    "for template_name, scores in template_scores.items():\n",
    "    coherence_scores = [item[\"coherence\"] for item in scores]\n",
    "    consistency_scores = [item[\"consistency\"] for item in scores]\n",
    "    fluency_scores = [item[\"fluency\"] for item in scores]\n",
    "    relevance_scores = [item[\"relevance\"] for item in scores]\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_coherence = sum(coherence_scores) / len(coherence_scores)\n",
    "    avg_consistency = sum(consistency_scores) / len(consistency_scores)\n",
    "    avg_fluency = sum(fluency_scores) / len(fluency_scores)\n",
    "    avg_relevance = sum(relevance_scores) / len(relevance_scores)\n",
    "    overall_avg = (avg_coherence + avg_consistency + avg_fluency + avg_relevance) / 4\n",
    "    \n",
    "    template_avgs[template_name] = {\n",
    "        \"coherence\": avg_coherence,\n",
    "        \"consistency\": avg_consistency,\n",
    "        \"fluency\": avg_fluency,\n",
    "        \"relevance\": avg_relevance,\n",
    "        \"overall\": overall_avg\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {template_name.title()} Template Results ===\")\n",
    "    print(f\"Average Coherence: {avg_coherence:.4f}\")\n",
    "    print(f\"Average Consistency: {avg_consistency:.4f}\")\n",
    "    print(f\"Average Fluency: {avg_fluency:.4f}\")\n",
    "    print(f\"Average Relevance: {avg_relevance:.4f}\")\n",
    "    print(f\"Overall Average: {overall_avg:.4f}\")\n",
    "\n",
    "# Find the best template\n",
    "best_template = max(template_avgs.items(), key=lambda x: x[1][\"overall\"])\n",
    "print(f\"\\n🏆 Best Template: {best_template[0].title()} with Overall Score: {best_template[1]['overall']:.4f}\")\n",
    "\n",
    "# Use the best template's predictions and scores for the rest of the analysis\n",
    "best_predictions = prompt_results[best_template[0]]\n",
    "best_scores = template_scores[best_template[0]]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6) Visualize results with enhanced charts\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Set up the plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Prepare data for visualization\n",
    "template_names = list(template_avgs.keys())\n",
    "coherence_avgs = [data[\"coherence\"] for data in template_avgs.values()]\n",
    "consistency_avgs = [data[\"consistency\"] for data in template_avgs.values()]\n",
    "fluency_avgs = [data[\"fluency\"] for data in template_avgs.values()]\n",
    "relevance_avgs = [data[\"relevance\"] for data in template_avgs.values()]\n",
    "overall_avgs = [data[\"overall\"] for data in template_avgs.values()]\n",
    "\n",
    "# Create comparison bar chart\n",
    "metrics = ['Coherence', 'Consistency', 'Fluency', 'Relevance', 'Overall']\n",
    "x = np.arange(len(template_names))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.figure(figsize=(14, 8)), plt.subplot(111)\n",
    "rects1 = ax.bar(x - 2*width, coherence_avgs, width, label='Coherence', color='#3274A1')\n",
    "rects2 = ax.bar(x - width, consistency_avgs, width, label='Consistency', color='#E1812C')\n",
    "rects3 = ax.bar(x, fluency_avgs, width, label='Fluency', color='#3A923A')\n",
    "rects4 = ax.bar(x + width, relevance_avgs, width, label='Relevance', color='#C03D3E')\n",
    "rects5 = ax.bar(x + 2*width, overall_avgs, width, label='Overall', color='#9372B2')\n",
    "\n",
    "ax.set_title('Performance Comparison by Prompt Template', fontsize=16)\n",
    "ax.set_xlabel('Prompt Template', fontsize=14)\n",
    "ax.set_ylabel('Score', fontsize=14)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([name.title() for name in template_names], fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Add value labels on bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"template_comparison.png\"), dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7910eec2-4339-41a4-a2d7-ada5d0a26a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards:   0%|                                                              | 0/4 [00:00<?, ?it/s]C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.cache\\huggingface\\hub\\models--HPAI-BSC--Qwen2.5-Aloe-Beta-7B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████████████████████████████████████████████████| 4/4 [03:57<00:00, 59.38s/it]\n",
      "Loading checkpoint shards:   0%|                                                       | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "The paging file is too small for this operation to complete. (os error 1455)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m model_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mkshitij-weights-folder\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mqwen-aloe-rl-12-4-ppo-tuned\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_path)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Ensure pad token is set\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    560\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    565\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\modeling_utils.py:3502\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3494\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   3495\u001b[39m     (\n\u001b[32m   3496\u001b[39m         model,\n\u001b[32m   3497\u001b[39m         missing_keys,\n\u001b[32m   3498\u001b[39m         unexpected_keys,\n\u001b[32m   3499\u001b[39m         mismatched_keys,\n\u001b[32m   3500\u001b[39m         offload_index,\n\u001b[32m   3501\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m3502\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[32m   3506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3509\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3510\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3513\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3514\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3520\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   3521\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\modeling_utils.py:3903\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[39m\n\u001b[32m   3901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[32m   3902\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3903\u001b[39m state_dict = \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3905\u001b[39m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[32m   3906\u001b[39m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[32m   3907\u001b[39m mismatched_keys += _find_mismatched_keys(\n\u001b[32m   3908\u001b[39m     state_dict,\n\u001b[32m   3909\u001b[39m     model_state_dict,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3913\u001b[39m     ignore_mismatched_sizes,\n\u001b[32m   3914\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\kshitij\\Lib\\site-packages\\transformers\\modeling_utils.py:505\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_file)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03mReads a PyTorch checkpoint file, returning properly formatted errors if they arise.\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_file.endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_safetensors_available():\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Check format of the archive\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    506\u001b[39m         metadata = f.metadata()\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata.get(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mflax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[31mOSError\u001b[39m: The paging file is too small for this operation to complete. (os error 1455)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the trained model\n",
    "model_path = r\"D:\\kshitij-weights-folder\\qwen-aloe-rl-12-4-ppo-tuned\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Ensure pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set up device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create a synthetic medical conversation\n",
    "synthetic_conversation = \"\"\"\n",
    "[doctor] Good morning, Mrs. Johnson. How are you feeling today?\n",
    "[patient] Good morning, Doctor. Not too well. I've been having this persistent cough for about 3 weeks now. It's worse at night and I'm bringing up yellowish phlegm.\n",
    "[doctor] I'm sorry to hear that. Have you had any fever or chills?\n",
    "[patient] Yes, I've had a low-grade fever of about 99.5°F for the past week. I've also been feeling unusually tired.\n",
    "[doctor] And how about shortness of breath or chest pain?\n",
    "[patient] I do get short of breath sometimes, especially when walking up stairs. No chest pain though.\n",
    "[doctor] Are you taking any medications currently?\n",
    "[patient] Just my regular blood pressure medicine - Lisinopril 10mg once daily. I've been taking some over-the-counter cough syrup but it's not helping much.\n",
    "[doctor] Have you had any recent illnesses or been around anyone who's been sick?\n",
    "[patient] My grandson had a bad cold about a month ago. I was taking care of him for a few days.\n",
    "[doctor] Let me examine you. Your temperature is 99.8°F now. Blood pressure is 138/85, which is slightly elevated. Your oxygen saturation is 94%, which is a bit lower than I'd like to see.\n",
    "[doctor] When I listen to your lungs, I can hear some crackles in the lower right lobe. I think we should get a chest X-ray to rule out pneumonia.\n",
    "[patient] That sounds concerning. Do you think it's serious?\n",
    "[doctor] It could be a case of bacterial pneumonia. I'll prescribe an antibiotic - azithromycin - for 5 days. If it is pneumonia, you should start feeling better within 48-72 hours on the antibiotics.\n",
    "[doctor] I'd also like you to use this inhaler - it's albuterol - to help with the breathing when you feel short of breath. Two puffs every 4-6 hours as needed.\n",
    "[patient] Should I continue with the over-the-counter cough medicine?\n",
    "[doctor] You can continue with it at night if the cough is keeping you up, but it's actually good to cough during the day to clear the infection from your lungs.\n",
    "[doctor] Make sure to drink plenty of fluids, get rest, and come back if you don't start feeling better in a few days, or if you develop high fever, severe shortness of breath, or chest pain.\n",
    "[patient] Thank you, Doctor. I'll follow your instructions.\n",
    "[doctor] I'll see you for a follow-up in one week, but call if anything worsens before then.\n",
    "\"\"\"\n",
    "\n",
    "# Use the \"medical\" template which performed best in your evaluation\n",
    "prompt_template = \"Generate a concise medical summary of the conversation:\\n\\n\"\n",
    "prompt = f\"{prompt_template}{synthetic_conversation}\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate summary with beam search for better quality\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        do_sample=False,\n",
    "        num_beams=5,\n",
    "        max_new_tokens=128,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Extract just the generated part\n",
    "if prompt in generated_text:\n",
    "    summary = generated_text[generated_text.find(prompt) + len(prompt):]\n",
    "else:\n",
    "    summary = generated_text\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== Input Medical Conversation ===\")\n",
    "print(synthetic_conversation[:300] + \"...\")\n",
    "print(\"\\n=== Generated Medical Summary ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6b33c-183b-4595-8ccd-cf62af9423ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kshitij)",
   "language": "python",
   "name": "kshitij"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
