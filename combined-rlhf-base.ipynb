{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e4e0a6-1ef0-4b29-85cb-0151b8e528db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "\n",
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'fact'\n",
    "\n",
    "evaluator = get_evaluator(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe71618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def convert_to_json(output_list, src_list=None, ref_list=None, context_list=None, \\\n",
    "            scores=None, doc_id=None, system_id=None):\n",
    "    \"\"\"\n",
    "        Convert the data into the json format.\n",
    "\n",
    "        output_list: a list of model output\n",
    "        src_list: source input for different NLG tasks. For example, source document for summarization\n",
    "                  and dialogue history for dialogue response generation\n",
    "        ref_list: human-annotated groundtruth\n",
    "        context_list: the context needed to evaluate several specific dimension. For example,\n",
    "                      additional factual information when evaluating engagingness and groundedness in dialogues\n",
    "        scores: human scores for evaluating the model output. They can be used to calculate the correlation\n",
    "                between evaluators and human judgements. The scores should be stored in a dictionary. For example,\n",
    "                {'fluency': 2.0, 'coherence': 3.0} could be the human score for a sample.\n",
    "        doc_id: the index of the input source. It can be used to calculate summary-level correlation for summarzation\n",
    "        system_id: the index of the generation system. It can be used to calculate system-level correlation.\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    for i in range(len(output_list)):\n",
    "        cur = {}\n",
    "        cur['system_output'] = output_list[i]\n",
    "        if src_list is not None:\n",
    "            cur['source'] = src_list[i]\n",
    "        if ref_list is not None:\n",
    "            cur['reference'] = ref_list[i]\n",
    "        if context_list is not None:\n",
    "            cur['context'] = context_list[i]\n",
    "        if scores is not None:\n",
    "            cur['scores'] = scores[i]\n",
    "        if doc_id is not None:\n",
    "            cur['doc_id'] = doc_id[i]\n",
    "        if system_id is not None:\n",
    "            cur['system_id'] = system_id[i]\n",
    "        json_data.append(cur)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def add_question(dimension, output, src=None, ref=None, context=None, task=None):\n",
    "    \"\"\"\n",
    "        Add questions to generate input in Bool-QA format for UniEval.\n",
    "\n",
    "        dimension: specific dimension to be evaluated\n",
    "        src: source input for different NLG tasks. For example, source document for summarization\n",
    "             and dialogue history for dialogue response generation.\n",
    "        output: output text generated by the models\n",
    "        ref: human-annotataed groundtruth\n",
    "        context: the context needed to evaluate several specific dimension. For example,\n",
    "                 additional factual information when evaluating engagingness and groundedness in dialogues.\n",
    "    \"\"\"\n",
    "\n",
    "    input_with_question = []\n",
    "    for i in range(len(output)):\n",
    "        # For summarization\n",
    "        if task == 'summarization':\n",
    "            if dimension == 'fluency':\n",
    "                cur_input = 'question: Is this a fluent paragraph? </s> paragraph: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent summary to the document? </s> summary: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'relevance':\n",
    "                cur_input = 'question: Is this summary relevant to the reference? </s> summary: ' + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For dialogues\n",
    "        elif task == 'dialogue':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a natural response in the dialogue? </s> response: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent response given the dialogue history? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i]\n",
    "            elif dimension == 'engagingness':\n",
    "                cur_input = 'question: Is this an engaging and informative response according to the dialogue history and fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'groundedness':\n",
    "                cur_input = 'question: Is this response consistent with knowledge in the fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'understandability':\n",
    "                cur_input = 'question: Is this an understandable response in the dialogue? </s> response: ' + output[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For data-to-text\n",
    "        elif task == 'data2text':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a fluent utterance? </s> utterance: ' + output[i]\n",
    "            elif dimension == 'informativeness':\n",
    "                cur_input = 'question: Is this sentence informative according to the reference? </s> sentence: '\\\n",
    "                            + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For factual consistency detection\n",
    "        elif task == 'fact':\n",
    "            if dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            else:\n",
    "                raise NotImplementedError('No other dimensions for the factual consistency detection task.')\n",
    "        # For new customized tasks\n",
    "        else:\n",
    "            raise NotImplementedError('Other tasks are not implemented, please customize specific tasks here.')\n",
    "        input_with_question.append(cur_input)\n",
    "    return input_with_question\n",
    "\n",
    "\n",
    "def print_scores(scores):\n",
    "    table = PrettyTable(['Dimensions','Score'])\n",
    "    print('\\nEvaluation scores are shown below:')\n",
    "    dims = list(scores[0].keys())\n",
    "    for dim in dims:\n",
    "        cur_score = 0\n",
    "        for i in range(len(scores)):\n",
    "            cur_score += scores[i][dim]\n",
    "        table.add_row([dim, round(cur_score / len(scores), 6)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f30faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from scorer import UniEvaluator  # Make sure this import works after placing scorer.py in the same directory\n",
    "\n",
    "def evaluate(data, dims=None, overall=True, print_result=False, model_name_or_path=\"t5-small\", task='summarization', device='cuda:0', individual=True):\n",
    "    \"\"\"\n",
    "    Get the scores of all the given dimensions (fluency, consistency, coherence, relevance)\n",
    "\n",
    "    data: A list of dictionaries, where each dictionary contains:\n",
    "          - 'source': The original text\n",
    "          - 'system_output': The generated system output (summary)\n",
    "          - 'reference' (optional): Reference summary for relevance evaluation\n",
    "\n",
    "    dims: A list of dimensions to be evaluated. If dims is None, it evaluates four default dimensions:\n",
    "          coherence, consistency, fluency, relevance.\n",
    "\n",
    "    overall: Boolean to indicate whether the overall score is calculated as the average of all dimensions.\n",
    "\n",
    "    print_result: Boolean to print the results on the screen.\n",
    "\n",
    "    model_name_or_path: The model name or path to use for evaluation, e.g., 't5-small'\n",
    "\n",
    "    task: The task type (used in scoring if needed, like summarization or other NLP tasks).\n",
    "\n",
    "    device: The device to use for evaluation ('cpu' or 'cuda:0').\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the scorer\n",
    "    scorer = UniEvaluator(model_name_or_path=model_name_or_path, device=device)\n",
    "\n",
    "    n_data = len(data)\n",
    "    eval_scores = [{} for _ in range(n_data)]\n",
    "\n",
    "    # Default dimensions if not provided\n",
    "    if dims is None:\n",
    "        dims = ['coherence', 'consistency', 'fluency', 'factual consistency']   #add relevance\n",
    "\n",
    "    for dim in dims:\n",
    "        print(f'Evaluating {dim} of {n_data} samples !!!')\n",
    "\n",
    "        if dim == 'consistency' or dim == 'fluency':\n",
    "            # Sentence-level scores for consistency and fluency\n",
    "            src_list, output_list = [], []\n",
    "            n_sents = []  # number of sentences in each summary\n",
    "\n",
    "            for i in range(n_data):\n",
    "                if dim == 'consistency':\n",
    "                    source = data[i]['source']\n",
    "                else:\n",
    "                    source = ''\n",
    "                system_outputs = sent_tokenize(data[i]['system_output'])\n",
    "                n_sents.append(len(system_outputs))\n",
    "                for j in range(len(system_outputs)):\n",
    "                    src_list.append(source)\n",
    "                    output_list.append(system_outputs[j])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, task=task)\n",
    "            sent_score = scorer.score(input_list)\n",
    "\n",
    "            # Calculate average sentence-level scores for each sample\n",
    "            start_idx = 0\n",
    "            score = []\n",
    "            for cur_n_sent in n_sents:\n",
    "                score.append(sum(sent_score[start_idx:start_idx + cur_n_sent]) / cur_n_sent)\n",
    "                start_idx += cur_n_sent\n",
    "\n",
    "        elif dim == 'coherence' or dim == 'relevance':\n",
    "            # Summary-level scores for coherence and relevance\n",
    "            src_list, output_list, ref_list = [], [], []\n",
    "\n",
    "            for i in range(n_data):\n",
    "                src_list.append(data[i]['source'])\n",
    "                output_list.append(data[i]['system_output'])\n",
    "                if dim == 'relevance':\n",
    "                    ref_list.append(data[i]['reference'])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, ref=ref_list, task=task)\n",
    "            score = scorer.score(input_list)\n",
    "\n",
    "        elif dim == 'factual consistency':\n",
    "            output_list, src_list = [], []\n",
    "\n",
    "            for i in range(n_data):\n",
    "                src_list.append(data[i]['source'])\n",
    "                output_list.append(data[i]['system_output'])\n",
    "\n",
    "            data = convert_to_json(output_list=output_list, src_list=src_list)\n",
    "            eval_score = evaluator.evaluate(data)\n",
    "            score = []\n",
    "\n",
    "            for i in eval_score:\n",
    "                temp = i['consistency']\n",
    "                score.append(temp)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"The input format for the dimension '{dim}' is still undefined. Please customize it.\")\n",
    "\n",
    "        # Store the scores for the current dimension\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i][dim] = score[i]\n",
    "\n",
    "    # Calculate overall score (average of all evaluated dimensions)\n",
    "    if overall:\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i]['overall'] = np.mean([eval_scores[i][dim] for dim in dims])\n",
    "\n",
    "    # Print the result if requested\n",
    "    if print_result:\n",
    "        print_scores(eval_scores)\n",
    "\n",
    "    if individual:\n",
    "        individual_scores = []\n",
    "        for i in range(n_data):\n",
    "            temp = [eval_scores[i][dim] for dim in dims]\n",
    "            individual_scores.append(temp)\n",
    "\n",
    "        return np.array(individual_scores)\n",
    "\n",
    "    # Calculate average score across all the dimensions except 'overall'\n",
    "    avg_score = []\n",
    "    for i in range(n_data):\n",
    "        # Exclude 'overall' from the averaging\n",
    "        dimensions = [dim for dim in dims if dim != 'overall']\n",
    "        avg_score.append(np.mean([eval_scores[i][dim] for dim in dimensions]))\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d32ca14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████████████| 93/93 [00:00<00:00, 141.35 examples/s]\n",
      "WARNING:root:The `device_map` argument is not provided. We will override the device_map argument. to set the entire model on the current device. If you want to set the model on multiple devices, please provide a custom `device_map` argument.\n",
      "  0%|                                                                                 | 0/46 [00:00<?, ?it/s]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.63it/s]\u001b[A\n",
      "  2%|█▌                                                                       | 1/46 [00:05<04:28,  5.97s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.57it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 67.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.00it/s]\u001b[A\n",
      "  4%|███▏                                                                     | 2/46 [00:11<04:00,  5.47s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.91it/s]\u001b[A\n",
      "  7%|████▊                                                                    | 3/46 [00:16<03:49,  5.34s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 44.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 69.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s]\u001b[A\n",
      "  9%|██████▎                                                                  | 4/46 [00:21<03:45,  5.38s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 39.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\u001b[A\n",
      " 11%|███████▉                                                                 | 5/46 [00:27<03:42,  5.44s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 37.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 76.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.11it/s]\u001b[A\n",
      " 13%|█████████▌                                                               | 6/46 [00:32<03:41,  5.53s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 15%|███████████                                                              | 7/46 [00:38<03:30,  5.39s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 67.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████▋                                                            | 8/46 [00:43<03:24,  5.37s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.88it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 20%|██████████████▎                                                          | 9/46 [00:48<03:15,  5.29s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 22%|███████████████▋                                                        | 10/46 [00:53<03:08,  5.24s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 24%|█████████████████▏                                                      | 11/46 [00:58<03:03,  5.24s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 77.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.42it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 26%|██████████████████▊                                                     | 12/46 [01:04<02:59,  5.28s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.75it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 82.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\u001b[A\n",
      " 28%|████████████████████▎                                                   | 13/46 [01:09<02:54,  5.28s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 35.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.15 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 30%|█████████████████████▉                                                  | 14/46 [01:14<02:49,  5.28s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████▍                                                | 15/46 [01:19<02:41,  5.22s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 38.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 77.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.98it/s]\u001b[A\n",
      " 35%|█████████████████████████                                               | 16/46 [01:25<02:41,  5.38s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 67.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.51it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.75 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████▌                                             | 17/46 [01:30<02:33,  5.31s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 35.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.76it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████▏                                           | 18/46 [01:36<02:30,  5.37s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 41%|█████████████████████████████▋                                          | 19/46 [01:41<02:25,  5.37s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 71.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.52it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 43%|███████████████████████████████▎                                        | 20/46 [01:46<02:17,  5.29s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 71.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.99 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 46%|████████████████████████████████▊                                       | 21/46 [01:52<02:12,  5.29s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 48%|██████████████████████████████████▍                                     | 22/46 [01:57<02:09,  5.39s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 77.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.80it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 50%|████████████████████████████████████                                    | 23/46 [02:02<02:01,  5.30s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.55it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.50 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████▌                                  | 24/46 [02:08<01:56,  5.31s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 35.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 73.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 1/2 [00:00<00:00,  2.66it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.49it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.93 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 54%|███████████████████████████████████████▏                                | 25/46 [02:13<01:54,  5.45s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 71.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -7.65 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 57%|████████████████████████████████████████▋                               | 26/46 [02:18<01:46,  5.35s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 67.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 77.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 59%|██████████████████████████████████████████▎                             | 27/46 [02:24<01:42,  5.37s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 82.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.61it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████▊                            | 28/46 [02:29<01:35,  5.30s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 71.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -2.38 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 63%|█████████████████████████████████████████████▍                          | 29/46 [02:34<01:29,  5.29s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 77.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.26it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.54 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 65%|██████████████████████████████████████████████▉                         | 30/46 [02:40<01:28,  5.51s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 81.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -6.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 67%|████████████████████████████████████████████████▌                       | 31/46 [02:46<01:22,  5.47s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 46.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.40it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 70%|██████████████████████████████████████████████████                      | 32/46 [02:53<01:22,  5.87s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -1.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████▋                    | 33/46 [02:58<01:15,  5.77s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 39.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████▏                  | 34/46 [03:03<01:07,  5.62s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 69.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -4.27 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 76%|██████████████████████████████████████████████████████▊                 | 35/46 [03:09<01:00,  5.53s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.24it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.56it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -5.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 78%|████████████████████████████████████████████████████████▎               | 36/46 [03:14<00:54,  5.43s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 79.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.76it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -6.69 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 80%|█████████████████████████████████████████████████████████▉              | 37/46 [03:19<00:48,  5.40s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -12.75 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 83%|███████████████████████████████████████████████████████████▍            | 38/46 [03:25<00:43,  5.48s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.74it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -8.61 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 85%|█████████████████████████████████████████████████████████████           | 39/46 [03:30<00:37,  5.36s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.84it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -13.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████▌         | 40/46 [03:35<00:31,  5.30s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -14.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 89%|████████████████████████████████████████████████████████████████▏       | 41/46 [03:40<00:26,  5.25s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 76.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.81it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -9.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████▋      | 42/46 [03:45<00:21,  5.25s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 30.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 82.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.14it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -13.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████▎    | 43/46 [03:51<00:15,  5.29s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.64it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -11.78 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 96%|████████████████████████████████████████████████████████████████████▊   | 44/46 [03:56<00:10,  5.32s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 59.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 80.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.75it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -3.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      " 98%|██████████████████████████████████████████████████████████████████████▍ | 45/46 [04:01<00:05,  5.28s/it]Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=64) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Evaluating coherence of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 54.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating factual consistency of 2 samples !!!\n",
      "Evaluating consistency of 2 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.86it/s]\u001b[A\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1266: UserWarning: KL divergence is starting to become negative: -11.68 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████| 46/46 [04:09<00:00,  5.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments\n",
    "from trl import RewardTrainer, PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "import bitsandbytes as bnb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Add UniEval to path and import\n",
    "sys.path.append(r\"C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\Downloads\\kshitij\\UniEval\")\n",
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"combined_clinical_notes.csv\"\n",
    "# MODEL_PATH = r\"D:\\kshitij-weights-folder\\qwen-aloe-9-4-base-fine-tune\"\n",
    "MODEL_PATH = \"gpt2\" \n",
    "# PEFT_ADAPTER_PATH = r\"D:\\kshitij-weights-folder\\qwen-aloe-9-4-base-fine-tune-peft-adapaters\"\n",
    "MEDICAL_PROMPT = \"\\nGenerate a concise medical summary focusing on key findings and treatment plans:\"\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "eval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "dataset = Dataset.from_pandas(eval_df.rename(columns={\"dialogue\": \"review\"}))\n",
    "\n",
    "# Tokenizer setup\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Dataset preprocessing\n",
    "def preprocess_function(examples):\n",
    "    return {\n",
    "        \"input_ids\": tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512),\n",
    "        \"query\": tokenizer.decode(tokenizer.encode(examples[\"review\"], truncation=True, padding=\"max_length\", max_length=512), skip_special_tokens=True)\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=False)\n",
    "dataset.set_format(\"pytorch\")\n",
    "\n",
    "# Model configuration\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# PEFT/LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    ")\n",
    "\n",
    "# model_with_lora = get_peft_model(base_model, lora_config)\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model, peft_config=lora_config).to(\"cuda\")\n",
    "\n",
    "# Reference model\n",
    "ref_model = create_reference_model(model).to(\"cuda\")\n",
    "ref_model.eval()\n",
    "for param in ref_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# PPO Configuration\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=MODEL_PATH,\n",
    "    ppo_epochs=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    steps=5,\n",
    "    batch_size=2,\n",
    "    mini_batch_size=1,\n",
    "    learning_rate=2e-5,\n",
    "    log_with='tensorboard',\n",
    "    project_kwargs={\"logging_dir\": r\"D:\\kshitij-weights-folder\\gpt2-rl-logs\"}\n",
    ")\n",
    "\n",
    "# Initialize PPO Trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=ppo_config,\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    optimizer=bnb.optim.Adam8bit(model.parameters(), lr=ppo_config.learning_rate)\n",
    ")\n",
    "\n",
    "# Evaluation setup\n",
    "# sum_eval = get_evaluator(\"summarization\", \"cuda\"=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_score(game_data):\n",
    "    weights = np.array([0.1, 0.2, 0.3, 0.4])  # coherence, consistency, fluency, factual consistency\n",
    "    sample_data = [{\"source\": q, \"system_output\": r} for q, r in zip(game_data[\"query\"], game_data[\"response\"])]\n",
    "    \n",
    "    # scores = sum_eval.evaluate(sample_data, overall=False)\n",
    "    scores = evaluate(sample_data, overall=False)\n",
    "    weighted_scores = []\n",
    "    \n",
    "    for dimension_scores in scores:\n",
    "        adjusted = np.where(\n",
    "            dimension_scores < 0.5,\n",
    "            -dimension_scores * weights,\n",
    "            dimension_scores * weights\n",
    "        )\n",
    "        weighted_scores.append(torch.tensor(np.sum(adjusted)/4, dtype=torch.float32).to(model.pretrained_model.device))\n",
    "    \n",
    "    return weighted_scores\n",
    "\n",
    "max_position_embeddings = model.pretrained_model.config.max_position_embeddings \n",
    "# Training loop\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    # \"max_new_tokens\": 64,  # Increased for better summary generation\n",
    "    \"eos_token_id\": -1,\n",
    "    \"max_length\": max_position_embeddings,\n",
    "    \"max_new_tokens\": 64\n",
    "}\n",
    "\n",
    "for epoch in range(1):\n",
    "    for batch in tqdm(ppo_trainer.dataloader):\n",
    "        (logs, game_data,) = (\n",
    "            dict(),\n",
    "            dict(),\n",
    "        )\n",
    "\n",
    "        # task_list = choices(ctrl_str, k=config.batch_size)\n",
    "        # game_data[\"query\"] = [t + q for t, q in zip(task_list, batch[\"query\"])]\n",
    "        game_data[\"query\"] = [q for q in batch[\"query\"]]\n",
    "        # query_tensors = [torch.cat((ctrl_tokens[t], input_ids)) for t, input_ids in zip(task_list, batch[\"input_ids\"])]\n",
    "        query_tensors = [input_ids for input_ids in batch[\"input_ids\"]]\n",
    "        \n",
    "        response_tensors = []\n",
    "        for query in query_tensors:\n",
    "            original_notes = tokenizer.decode(query)\n",
    "            \n",
    "            # Combine with medical prompt only during generation\n",
    "            full_prompt = f\"{MEDICAL_PROMPT}{original_notes}\"\n",
    "            full_prompt_tensor = tokenizer.encode(full_prompt, return_tensors=\"pt\").to(\"cuda\").squeeze(0)\n",
    "            \n",
    "            response = ppo_trainer.generate(\n",
    "                full_prompt_tensor,\n",
    "                **generation_kwargs\n",
    "            )\n",
    "            # Ensure response doesn't exceed max length\n",
    "            response = response[:, :generation_kwargs[\"max_new_tokens\"]]\n",
    "            response_tensors.append(response.squeeze())\n",
    "#         print(response_tensors)\n",
    "        game_data[\"response\"] = [tokenizer.decode(r) for r in response_tensors]\n",
    "\n",
    "        print(\"check\")\n",
    "\n",
    "        texts = [q + r for q, r in zip(batch[\"query\"], game_data[\"response\"])]\n",
    "        logits = get_score(game_data)\n",
    "        rewards = logits\n",
    "        # rewards = pos_logit_to_reward(logits, task_list)\n",
    "        # rewards = [torch.tensor([1.0], device=query_tensors[0].device) for _ in range(len(texts))]\n",
    "\n",
    "        #### Run PPO training\n",
    "        t = time.time()\n",
    "        stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d9abf-ba31-4f69-9a1b-1b219279ebdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kshitij)",
   "language": "python",
   "name": "kshitij"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
