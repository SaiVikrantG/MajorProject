{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7dDyW84futj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7dDyW84futj",
    "outputId": "3bae5516-cdeb-427c-9a54-0b4dd56a2509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ZL9wcvcle3iT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZL9wcvcle3iT",
    "outputId": "6a197a41-8ccd-4778-c1b9-6f868e6ee91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trl==0.7.4 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (0.7.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.4) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.18.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.4) (4.38.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from trl==0.7.4) (1.26.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.4) (0.28.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.4) (3.4.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.4) (0.9.17)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.4) (78.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.4) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.7.4) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (4.66.4)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (13.3.5)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.4) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.4) (4.4.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate->trl==0.7.4) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.4) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets->trl==0.7.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets->trl==0.7.4) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.4) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets->trl==0.7.4) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.4) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2023.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.4) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (3.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.29.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.38.2 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.38.2) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.38.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.38.2) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.38.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.38.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.38.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.38.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.38.2) (2024.8.30)\n",
      "^C\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft==0.10.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from peft==0.10.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from peft==0.10.0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from peft==0.10.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from peft==0.10.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.10.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.10.0) (4.38.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from peft==0.10.0) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.10.0) (0.28.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.10.0) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.10.0) (0.29.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.10.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.10.0) (78.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->peft==0.10.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers->peft==0.10.0) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from transformers->peft==0.10.0) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2024.8.30)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate==0.28.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate==0.28.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate==0.28.0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate==0.28.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate==0.28.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.28.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.28.0) (0.29.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.28.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (78.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.28.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate==0.28.0) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate==0.28.0) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.28.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2024.8.30)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (0.45.2)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch<3,>=2.0->bitsandbytes) (78.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bmsce cse.desktop-iub6tha\\appdata\\roaming\\python\\python312\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install trl==0.7.4\n",
    "!pip install datasets\n",
    "!pip install transformers==4.38.2\n",
    "!pip install peft==0.10.0\n",
    "!pip install accelerate==0.28.0\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed9e28-2389-4799-b1a6-bb98a4c654f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3ac56-ecdf-4098-8562-3e5319d613fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trl==0.4.7 transformers==4.29.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fd2d2-5e5e-4952-960e-95d912ae104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade peft\n",
    "!pip install --upgrade trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4329b-4006-43b1-93d4-9ac40abcae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trl==0.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa80b0e",
   "metadata": {
    "id": "2fa80b0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    ")\n",
    "\n",
    "def set_seed(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#Configuration options\n",
    "train_batch_size = 16\n",
    "gradient_accumulation_steps = 1\n",
    "learning_rate = 1e-5\n",
    "eval_batch_size = 1\n",
    "eval_steps = 500\n",
    "max_input_length = 550\n",
    "save_steps = 1000\n",
    "num_train_epochs = 20\n",
    "random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018c6ca",
   "metadata": {
    "id": "4018c6ca"
   },
   "source": [
    "## Creating the policy model for human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "_W6O243ZgLwz",
   "metadata": {
    "id": "_W6O243ZgLwz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-e8c59e5cf7bce1c0.parquet', 'test': 'data/test-00000-of-00001-59ffb27399371eac.parquet', 'valid': 'data/valid-00000-of-00001-0e33e6bd86e3edc9.parquet'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90da8c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f90da8c2",
    "outputId": "6fb90686-d77c-4e61-e7c1-d08fc23f593b"
   },
   "outputs": [],
   "source": [
    " df = pd.read_parquet(\"hf://datasets/CarperAI/openai_summarize_tldr/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72f4acc-334b-40a2-9fb1-46c2c09695e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0670ff5e",
   "metadata": {
    "id": "0670ff5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1) 4-bit quant config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "# 2) Load base model in 4-bit\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"left\"\n",
    "\n",
    "# 3) Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], \n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# 4) Enable gradient checkpointing\n",
    "model.enable_input_require_grads()\n",
    "model.gradient_checkpointing_enable()\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "class TLDRDataset(Dataset):\n",
    "    def __init__(self, train_path, tokenizer, split, max_length=256):\n",
    "        self.post_list = []\n",
    "        dataset = (pd.read_parquet(train_path))[:1000]\n",
    "        self.labels = []\n",
    "\n",
    "        for sample in dataset.iterrows():\n",
    "            self.post_list.append(sample[1][\"prompt\"])\n",
    "            self.labels.append(sample[1][\"label\"])\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.post_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.post_list[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
    "        # encodings_dict_label = self.tokenizer(label,truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
    "        # input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
    "        # attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n",
    "        # labels_ids = torch.tensor(encodings_dict_label[\"input_ids\"])\n",
    "        # return {\n",
    "        #     \"input_ids\": input_ids,\n",
    "        #     \"attention_mask\": attn_masks,\n",
    "        #     \"labels\": labels_ids,\n",
    "        # }\n",
    "\n",
    "        encodings = self.tokenizer(\n",
    "            txt,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encodings[\"input_ids\"].squeeze()\n",
    "        attention_mask = encodings[\"attention_mask\"].squeeze()\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1f17d-d079-4fa1-80e0-163ba67203a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all model parameters require gradients\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f0a73ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329,
     "referenced_widgets": [
      "2ee036dcaea94adeb294a7844f837d85",
      "b404c085709e4493845ead1ad89a48e6",
      "12ad38cbe85c4b9ab63138939053cccc",
      "29b2f761b5b349bd8aa098de4770f244",
      "1a279ec52b2b466397bd52667b626d74",
      "4653fda4c1dd448e80ef14ef606ea511",
      "9adb359c88b24046b0f814383eb38f0a",
      "f8e42567b9344eb4abeb99efdb48e744",
      "50b95db77526424291212b467db215e1",
      "130acc8ffbfd49b08ef5e4829f867f98",
      "4a0096bcfe934c159d14aa6d349d65ea",
      "f63062b8b9b94fc88a99829df2b471fb",
      "53630455dcc44a0a907800d718710082",
      "23ad95fdeee4464d9513e96e015bce96",
      "6967ad3dd572446089ff72ea632f3cb8",
      "401c8c8ee6844e96aa40bced0b7c3ade",
      "bcb3647203504274bfb3ff1fc6c44e08",
      "273fb44aecc947f4815d68ea9ca13670",
      "10003b1b208f4adcab19037fc8da5889",
      "f7f98e0f85f64a4b83d7c1d78cbb8bd7",
      "9150276882d141be82bfc82ed896a337",
      "5b0d43101036469c95b6a31f037ef0ef",
      "861f9a6fe2484be98f394c8ee28502ab",
      "48971a2be26b41dfa9fd106cbed6d2fc",
      "82da4d1b78e54f578fbd4aa260c2f9b7",
      "e2e6186a6bdf4898b6c2aaecd91dcca0",
      "1d97a59cd150445d89a8cf3a306c408f",
      "26be8d89ca904c9d9ece12fc5c1a01ff",
      "b2800791e45446da8005e119d32d3a8e",
      "e258ce9e8dd3427da51991741635c2be",
      "551521a2eb034679a56fd55d61611326",
      "9ef779a51f2642e3b29b5f99a4926724",
      "b396c7d525a94e3daa639377f5a8747c",
      "00625022a7dc4d5199606952a22f80ce",
      "7846d74db1024f7abd48c41012faee4a",
      "6549e8a2fe714ed7a54cf0839d949db9",
      "ae688f7eba434a4a9ee146604c672e46",
      "e85964b9fce9460fbefb051b68b0b3b6",
      "ebd38b8bd46b4998a88818587318e79e",
      "a410a688f326419e8e14385a46c850c0",
      "1806e01023874dbaa0e1e1a27fcfb7af",
      "d00cd587a0e440cf9bcc97a48c7b2d06",
      "73e9a6b36c7649af950272da35bb00df",
      "a4ef1cf1efaa427e8d2762826d6669d6",
      "3987baa9a0fd49fbac56ed62fa864e0e",
      "6c8caecbdcad4d2989428d72786b00c1",
      "4619ba9bdb1e4f1bbdbb0948c953f574",
      "d2a849fe48964923b51af64144fe8125",
      "090e95d21e074d45b4424a1208e2b0f5",
      "1c6e7613dbcc4297a48dc95b4c223efa",
      "d91967e1f7c34d67a4f673b109e952d8",
      "5b66974c6e3045f5a4fcf18750e36c28",
      "5622aade820f472db2a7a8aee703cefd",
      "79bed7e6b98b4b43a11968c7fb9226e5",
      "88a330bb657a447cbe54a4186e6d0733",
      "da5f875c9faa4fe6b42be094adae0a16",
      "cc8edf2b13414ed08b8e994302084194",
      "63d1a6412dd04fc6962a4e37a853fa75",
      "05b072bdee2f464fbd8d8a0a5f073446",
      "b8737afab12f4f76941d89ec0d09bcf9",
      "419c8a47f5a247a18578afc8791db2f1",
      "23308a73d9664a6caf52d89199cdab52",
      "fef6bb6f6f5b4ba09117ccf3846604e9",
      "8294ac6ca34445f5a4802b44eac51c4e",
      "43962267006440248906ff7c8c4dd8c6",
      "b1664e0e4ccc4349a67407bf799f5bec",
      "77d3860815a44df1a74fd825424c01df",
      "b08f80b4caf44fc39575ecf7ee568602",
      "a690f4a1b5884914bf6ba158efaea980",
      "a58a2a7696fd450999502438dc7e4fed",
      "f1edb1b0218a4a84a98a8962ace2aeeb",
      "e89d6959ed7a444992c43a7b2518f930",
      "94e72ccb8df1400b97164c2ffc0d2a95",
      "4fbc3ad1dd6747a7ac184bf90a737a4a",
      "163f6a03558545b498a83b39b9a856d2",
      "032839edec244213888db5edccc5f8f2",
      "2cca1e938b53495e90f01f0e1f5e5ea5",
      "a06498f69a104dceb7cbbc4b7861c100",
      "f142622223614832a2c86be61e7ef21b",
      "56a9b7628bd547b7937bba6016ab5328",
      "8e7341e3add74b2abca6d6b80b1cb0ea",
      "9bcac87327ba469b8d38eec46341f7e3",
      "3a353215523b4b228a791ae60f8c8ef6",
      "e8a0f2f8c5d74ced9ffba971450c51e7",
      "22237b431c8e4a37bad57b3a420803d6",
      "c5c3aa5fcdd94a3d8fb331b054faf810",
      "1c5eb40b7f9b4dfa99ad6119308a42bb",
      "8974689e8d954cc7ba35a7224c3d6702"
     ]
    },
    "id": "7f0a73ab",
    "outputId": "e8838e2b-d714-4d6e-8cfa-2fd60af5d18c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.end_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbc6aad5",
   "metadata": {
    "id": "dbc6aad5"
   },
   "outputs": [],
   "source": [
    "# Set up the datasets\n",
    "data_path = \"hf://datasets/CarperAI/openai_summarize_tldr/\" + splits[\"train\"]\n",
    "train_dataset = TLDRDataset(\n",
    "    data_path,\n",
    "    tokenizer,\n",
    "    \"train\",\n",
    "    max_length=256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f16a19aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f16a19aa",
    "outputId": "045b4de3-c71f-4dcb-a057-1ecb4b934ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([29038,   787,  4103,   952,    25,   435,    14, 85824,   198, 50328,\n",
      "           25,   358,   320,    69,    14,    17,    17,     8,   614,   311,\n",
      "         7071,   700,   421,   358,  1366,   311,  2058,  1414,  1493,  7571,\n",
      "          476,   537,   323,  1035, 12213,   311,  5112, 67092,   198,  2946,\n",
      "           25,  2806,  2704,   421,   419, 17180,  1588,   714,   432,   594,\n",
      "         5802,   264,  1430,    13,  4710,  3707, 26485,   510,  4498,   358,\n",
      "          320,    69,    14,    17,    17,     8,  3937,  1526,   847,  1156,\n",
      "         1931, 84498,   220,    17,  1635,  4134,  1576,   566,  4362,  3550,\n",
      "         1283,   264,  1042,   315,  4924,   926,   437,   220,   432, 88489,\n",
      "          752,   803,  1091,   358,  3381,    13,  1084,   572,   264, 27102,\n",
      "          882,   304,   847,  2272,  4152,   311,  5382,   448,   847,  6554,\n",
      "          323,  5499,  3432,   279,  6012,   311,  3931,  1059,   700,   315,\n",
      "          847,  2272,    13,   358,   646, 16698,  1576,   315,   432,   572,\n",
      "          458, 14269, 35750,   323,   419,  7412,   572, 15175,   323,  3207,\n",
      "          944,  1414,  1246,   311,  3484,   448,   752,    13,  1205,  9482,\n",
      "          553,  1435, 30426,   369,   264,  2254,   476,   773,  1283,  2087,\n",
      "          311,   264, 18780,   448,   847,  4780,    13,  3197,   358,  1744,\n",
      "         1182,   358,  6426,   566,  1101,  9482,    13,  2055,  1283,   566,\n",
      "         9482,   432,  3694,   847, 18210,   358, 16256,   714,   847,  4780,\n",
      "         8910,   752,  1526,   432,   323,   358,  2684,  9279,   315,  4297,\n",
      "          504,  1435,  3156,   448, 14376,  3645,    13,  4710,  7039,    25,\n",
      "        11445,  1012,  4558,   220,    18,  1635,  1431,   323,   358,  3003,\n",
      "        17019,  2664,  1283, 82681,   323, 23034,  7147, 38200,  1783,    13,\n",
      "         3017,  6554,   702,  1012,   700,   315,   847,  2272,  2474,  1221,\n",
      "          773,  1052,   594,  1012, 56238,   315,  5098,    13, 20690, 16245,\n",
      "         1283,  6832,  1045, 18366,  1052,  1012]) tensor([29038,   787,  4103,   952,    25,   435,    14, 85824,   198, 50328,\n",
      "           25,   358,   320,    69,    14,    17,    17,     8,   614,   311,\n",
      "         7071,   700,   421,   358,  1366,   311,  2058,  1414,  1493,  7571,\n",
      "          476,   537,   323,  1035, 12213,   311,  5112, 67092,   198,  2946,\n",
      "           25,  2806,  2704,   421,   419, 17180,  1588,   714,   432,   594,\n",
      "         5802,   264,  1430,    13,  4710,  3707, 26485,   510,  4498,   358,\n",
      "          320,    69,    14,    17,    17,     8,  3937,  1526,   847,  1156,\n",
      "         1931, 84498,   220,    17,  1635,  4134,  1576,   566,  4362,  3550,\n",
      "         1283,   264,  1042,   315,  4924,   926,   437,   220,   432, 88489,\n",
      "          752,   803,  1091,   358,  3381,    13,  1084,   572,   264, 27102,\n",
      "          882,   304,   847,  2272,  4152,   311,  5382,   448,   847,  6554,\n",
      "          323,  5499,  3432,   279,  6012,   311,  3931,  1059,   700,   315,\n",
      "          847,  2272,    13,   358,   646, 16698,  1576,   315,   432,   572,\n",
      "          458, 14269, 35750,   323,   419,  7412,   572, 15175,   323,  3207,\n",
      "          944,  1414,  1246,   311,  3484,   448,   752,    13,  1205,  9482,\n",
      "          553,  1435, 30426,   369,   264,  2254,   476,   773,  1283,  2087,\n",
      "          311,   264, 18780,   448,   847,  4780,    13,  3197,   358,  1744,\n",
      "         1182,   358,  6426,   566,  1101,  9482,    13,  2055,  1283,   566,\n",
      "         9482,   432,  3694,   847, 18210,   358, 16256,   714,   847,  4780,\n",
      "         8910,   752,  1526,   432,   323,   358,  2684,  9279,   315,  4297,\n",
      "          504,  1435,  3156,   448, 14376,  3645,    13,  4710,  7039,    25,\n",
      "        11445,  1012,  4558,   220,    18,  1635,  1431,   323,   358,  3003,\n",
      "        17019,  2664,  1283, 82681,   323, 23034,  7147, 38200,  1783,    13,\n",
      "         3017,  6554,   702,  1012,   700,   315,   847,  2272,  2474,  1221,\n",
      "          773,  1052,   594,  1012, 56238,   315,  5098,    13, 20690, 16245,\n",
      "         1283,  6832,  1045, 18366,  1052,  1012])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:\n",
    "    print(i[\"input_ids\"], i[\"labels\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "500301ac",
   "metadata": {
    "id": "500301ac"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "rPWzhVtfjXQf",
   "metadata": {
    "id": "rPWzhVtfjXQf"
   },
   "outputs": [],
   "source": [
    "output_dir = \"./aloe-qwen-rl-trial-run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3801788",
   "metadata": {
    "id": "d3801788"
   },
   "outputs": [],
   "source": [
    "# Prepare the trainer and start training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    num_train_epochs=2,\n",
    "    warmup_steps=100,\n",
    "    gradient_accumulation_steps=8,      # accumulate to compensate for small batch\n",
    "    # evaluation_strategy=\"epoch\",       # you can skip or reduce evaluation\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_drop_last=True,\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "baefacaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baefacaf",
    "outputId": "2f9403f1-0056-49b5-8dc8-c67898f37c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90ba4710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "90ba4710",
    "outputId": "58f76e90-2053-4e52-a291-4d5f088101f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\accelerate\\accelerator.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 04:19, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=2.557460512433733, metrics={'train_runtime': 278.8468, 'train_samples_per_second': 7.172, 'train_steps_per_second': 0.05, 'total_flos': 1.9475853943504896e+16, 'train_loss': 2.557460512433733, 'epoch': 1.81})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     data_collator=default_data_collator,\n",
    "#     preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3dfc50c2",
   "metadata": {
    "id": "3dfc50c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"aloe-qwen-rl-trial-run/\")   ##path to save policy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D9_2HLyqgg2T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9_2HLyqgg2T",
    "outputId": "8309e769-db80-4f48-d516-31af3d96f75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /content/summarization_policy_new to /content/drive/MyDrive/Medical Dialogue Summarization using PPO/summarization_policy_new\n",
      "Copied /content/wandb to /content/drive/MyDrive/Medical Dialogue Summarization using PPO/wandb\n",
      "Copied /content/Output to /content/drive/MyDrive/Medical Dialogue Summarization using PPO/Output\n",
      "Copy operation completed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dirs = [\"/content/drive/MyDrive/BMS/Medical Dialogue Summarization using PPO/summarization_policy_new\", \"/content/wandb\", \"/content/Output\"]\n",
    "destination = \"/content/drive/MyDrive/BMS/Medical Dialogue Summarization using PPO\"\n",
    "\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Copy each directory to the destination\n",
    "for src in source_dirs:\n",
    "    if os.path.exists(src):\n",
    "        dest_path = os.path.join(destination, os.path.basename(src))\n",
    "        shutil.copytree(src, dest_path, dirs_exist_ok=True)  # Copy with merging existing directories\n",
    "        print(f\"Copied {src} to {dest_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {src}, does not exist.\")\n",
    "\n",
    "print(\"Copy operation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b373c19c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b373c19c",
    "outputId": "261fc8ca-181f-4221-bcd6-ee256889445c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[29038,   787,  4103,   952,    25,   435,    14, 85824,   198, 50328,\n",
       "            25,   576,  3743,   508,    17,    21,   434,    60,   358,   508,\n",
       "            17,    17,   386,    60,   614,  1012,  9120,   369,   264,  2254,\n",
       "          3207,   944,  5889,   311,   752,   518,   678, 13671,  1393, 20704,\n",
       "           700,   448,   264,  4238,   508,    93,    18,    15,    30,   386,\n",
       "         26126,  2946,    25,  2932,  5221, 17478,  2473,  1393,   518,  1059,\n",
       "          3753,    11,   714,   358,  1467,   291,  1059,   220,    18,  3039,\n",
       "         13671,    11,   220,    19,    12,    20,  4115, 10747,    13,  2932,\n",
       "          3207,   944,  1618,   752,  3080,  4124,   419,  6556,   323,  2115,\n",
       "           264,  4069, 86283,   429,  1340,   572, 13028,   678,  1899,   448,\n",
       "           264,  4238,   879,  8542,   705,   700,   315,   279,  6303,   382,\n",
       "            40,  5485,   429,  1340,  8454,   264,  6802,   315,   279,  1378,\n",
       "           315,  1105,   700,   315,  1059,  5593, 10143,  3753,   389, 22943,\n",
       "          1573,   358,  1467,   291,  1059,   279,  1537,   882,   382,    40,\n",
       "          1513,   944,  3971,   429,  1340, 58341,   700,   448,  4780,    11,\n",
       "           323,   358,  1414,   432,   594,  5020,  4124,   304,   279,  5025,\n",
       "            11,   714,  1079,   358,  4969,   311,   387,   264,  2632, 56030,\n",
       "           429,  1340,  3207,   944,  5889,  3080,   220,    17,    19,  4115,\n",
       "          1283,   847,  1156,  1467,  5267, 13470,    26,  7687,    25,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"aloe-qwen-rl-trial-run/\")\n",
    "model_path = \"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation=True, max_length=256, padding=\"max_length\")\n",
    "text = df.iloc[2][\"prompt\"]\n",
    "tokenized_text = tokenizer(text, return_tensors=\"pt\", max_length=256)\n",
    "\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421708e",
   "metadata": {
    "id": "8421708e"
   },
   "source": [
    "## Traning the reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b607ce4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "5b607ce4",
    "outputId": "758568b9-7b4b-4b46-ed56-83b6f13eed82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "from trl import RewardTrainer, SFTTrainer\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e849ca0f",
   "metadata": {
    "id": "e849ca0f"
   },
   "outputs": [],
   "source": [
    "##model path\n",
    "MODEL_PATH = \"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\"\n",
    "\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-3cbd295cedeecf91.parquet', 'test': 'data/test-00000-of-00001-0845e2eec675b16a.parquet', 'valid1': 'data/valid1-00000-of-00001-b647616a2be5f333.parquet', 'valid2': 'data/valid2-00000-of-00001-2655c5b3621b6116.parquet'}\n",
    "DATA_PATH = \"hf://datasets/CarperAI/openai_summarize_comparisons/\" + splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ddb7e5",
   "metadata": {
    "id": "14ddb7e5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)\n",
    "df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2209d915",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2209d915",
    "outputId": "b3a4a535-2bd8-4263-fd94-3549ccf4ba8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "##defininig the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368defaa",
   "metadata": {
    "id": "368defaa"
   },
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "def formatting_func(examples):\n",
    "    kwargs = {\"padding\": \"max_length\",\n",
    "              \"truncation\": True,\n",
    "              \"max_length\": 256,\n",
    "              \"return_tensors\": \"pt\"\n",
    "              }\n",
    "\n",
    "    # Prepend the prompt and a line break to the original_response and response-1 fields.\n",
    "    prompt_plus_chosen_response = examples[\"prompt\"] + \"\\n\" + examples[\"chosen\"]\n",
    "    prompt_plus_rejected_response = examples[\"prompt\"] + \"\\n\" + examples[\"rejected\"]\n",
    "\n",
    "    # Then tokenize these modified fields.\n",
    "    tokens_chosen = tokenizer.encode_plus(prompt_plus_chosen_response, **kwargs)\n",
    "    tokens_rejected = tokenizer.encode_plus(prompt_plus_rejected_response, **kwargs)\n",
    "\n",
    "    return {\n",
    "        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n",
    "        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4afbee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "23ec4ae465144516a3db9dc4c805b414",
      "addd67047e754832b862754ecbefaf3b",
      "99f7484691804d619e4bc1968c83ca0b",
      "45eb596290b042b9b20fd8b91624ddf5",
      "f0cf686dc0a748d79d35c04b10512018",
      "bc3ce597378a478695879fdb4db904f2",
      "8c8b7de980d84bf189b633d360e2c03a",
      "7f14f14bd8984cf5a48175d074f4338c",
      "7f99f8beda08491db4d43ebf22e1e7fe",
      "747d77f3993e4a2dbb9390a81aa02dde",
      "d29c98a970694ce7ad8b26b7f645dfdf"
     ]
    },
    "id": "0f4afbee",
    "outputId": "afc24ee3-d833-4af2-b888-5d4784559ef5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 493.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = Dataset.from_pandas(df)\n",
    "formatted_dataset = raw_dataset.map(formatting_func)\n",
    "formatted_dataset = formatted_dataset.train_test_split()\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43490bac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "43490bac",
    "outputId": "47e8975c-4e48-4b16-8437-29f2e498bc3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_name_or_path\": \"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151644,\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3584,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 18944,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"max_window_layers\": 28,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 28,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 4,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"use_cache\": false,\n",
       "  \"use_mrope\": false,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 152064\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3aef6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dce3aef6",
    "outputId": "a5210569-4fd5-4434-e21a-42b23093d9f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1376: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ### Loading the TRL reward trainer and training the trainer\n",
    "# training_args = TrainingArguments(\n",
    "#         output_dir=\"rm_checkpoint/\",\n",
    "#         num_train_epochs=1,\n",
    "#         logging_steps=10,\n",
    "#         gradient_accumulation_steps=1,\n",
    "#         save_strategy=\"steps\",\n",
    "#         evaluation_strategy=\"steps\",\n",
    "#         per_device_train_batch_size=2,\n",
    "#         per_device_eval_batch_size=1,\n",
    "#         eval_accumulation_steps=1,\n",
    "#         eval_steps=500,\n",
    "#         save_steps=500,\n",
    "#         warmup_steps=100,\n",
    "#         logging_dir=\"./logs\",\n",
    "#         learning_rate=1e-5,\n",
    "#         save_total_limit=1,\n",
    "#         no_cuda=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ad45a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "d06ad45a",
    "outputId": "ce768007-2846-40b4-c812-89586a222812"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/reward_trainer.py:106: FutureWarning: Using `transformers.TrainingArguments` for `args` is deprecated and will be removed in a future version. Please use `RewardConfig` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/reward_trainer.py:166: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/reward_trainer.py:191: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.7631033062934875, metrics={'train_runtime': 52.1582, 'train_samples_per_second': 0.134, 'train_steps_per_second': 0.077, 'total_flos': 0.0, 'train_loss': 0.7631033062934875, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer = RewardTrainer(model=model,\n",
    "#                         tokenizer=tokenizer,\n",
    "#                         train_dataset=formatted_dataset['train'],\n",
    "#                         eval_dataset=formatted_dataset['test'],\n",
    "#                         args= training_args,\n",
    "#                         )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8620e81",
   "metadata": {
    "id": "c8620e81"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"rm_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jDuvN-0YuoYv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDuvN-0YuoYv",
    "outputId": "1290c4a8-b4f8-4c9d-e945-89485af678b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /content/rm_model to /content/drive/MyDrive/Medical Dialogue Summarization using PPO/rm_model\n",
      "Copied /content/rm_checkpoint to /content/drive/MyDrive/Medical Dialogue Summarization using PPO/rm_checkpoint\n",
      "Copy operation completed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dirs = [\"/content/rm_model\", \"/content/rm_checkpoint\"]\n",
    "destination = \"/content/drive/MyDrive/Medical Dialogue Summarization using PPO\"\n",
    "\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Copy each directory to the destination\n",
    "for src in source_dirs:\n",
    "    if os.path.exists(src):\n",
    "        dest_path = os.path.join(destination, os.path.basename(src))\n",
    "        shutil.copytree(src, dest_path, dirs_exist_ok=True)  # Copy with merging existing directories\n",
    "        print(f\"Copied {src} to {dest_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {src}, does not exist.\")\n",
    "\n",
    "print(\"Copy operation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56a13c",
   "metadata": {
    "id": "1d56a13c"
   },
   "outputs": [],
   "source": [
    "## inference the model\n",
    "rm_model = AutoModelForCausalLM.from_pretrained(\"rm_model/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rm_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694fbc6",
   "metadata": {
    "id": "e694fbc6"
   },
   "outputs": [],
   "source": [
    "def get_score(model, tokenizer, prompt, response):\n",
    "\n",
    "    instructions = tokenizer.encode_plus(prompt,\n",
    "                                       response,\n",
    "                                       padding=\"max_length\",\n",
    "                                       max_length=256,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                        truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**instructions)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed481305",
   "metadata": {
    "id": "ed481305"
   },
   "outputs": [],
   "source": [
    "# usage with prompt\n",
    "prompt = df.iloc[0][\"prompt\"]\n",
    "example_prefered_response = df.iloc[0][\"chosen\"]\n",
    "example_unprefered_response = df.iloc[0][\"rejected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d513768",
   "metadata": {
    "id": "1d513768"
   },
   "outputs": [],
   "source": [
    "loss1 = get_score(model, tokenizer, prompt, example_prefered_response)\n",
    "loss2= get_score(model, tokenizer, prompt, example_unprefered_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95e92f",
   "metadata": {
    "id": "bc95e92f"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "loss = -nn.functional.logsigmoid(loss1 - loss2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92769534",
   "metadata": {
    "id": "92769534"
   },
   "source": [
    "# Policy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9cb217",
   "metadata": {
    "id": "bb9cb217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "from trl import RewardTrainer\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50d0acdb",
   "metadata": {
    "id": "50d0acdb"
   },
   "outputs": [],
   "source": [
    "##model path\n",
    "# MODEL_PATH = \"C:\\\\Users\\\\BMSCE CSE.DESKTOP-IUB6THA\\\\Downloads\\\\kshitij\\\\aloe_qwen_aci-bench-peft-old\"\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-3cbd295cedeecf91.parquet', 'test': 'data/test-00000-of-00001-0845e2eec675b16a.parquet', 'valid1': 'data/valid1-00000-of-00001-b647616a2be5f333.parquet', 'valid2': 'data/valid2-00000-of-00001-2655c5b3621b6116.parquet'}\n",
    "DATA_PATH = \"hf://datasets/CarperAI/openai_summarize_comparisons/\" + splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "221cfe68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "221cfe68",
    "outputId": "d8463bca-07a7-4d0f-f228-485a3f9a9451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_PATH)\n",
    "df = df[:1000]\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05f02097",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05f02097",
    "outputId": "1107e5e5-f0e0-4247-bdb4-c1da038160cd"
   },
   "outputs": [],
   "source": [
    "sentiment_pipe_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\"}\n",
    "\n",
    "config = PPOConfig(\n",
    "    steps=51200, learning_rate=1.41e-5, remove_unused_columns=True\n",
    ")\n",
    "\n",
    "txt_in_len = 5\n",
    "txt_out_len = 20\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5769b3",
   "metadata": {
    "id": "6e5769b3"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40d0ef6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "57a9590522364deebf5d963a44725d19",
      "e47fd10eefce4f04bfdd745e499a53bd",
      "a1057f1a6a1847908edd764652d87ea2",
      "f2389500717747cc94b49d3ec1917d69",
      "eb1d82a8695745569e2f44a4aed34e42",
      "07220bd5d9374cfb86bc3d935f61e3c2",
      "156c1c0838e0439fa604616923cbf17c",
      "c0791f63c8df4705891523af478a29e8",
      "9550de7afeff4fe5b1d4077c0305225a",
      "0ff1a125eef34ba18e2d46cfee1398e0",
      "ecb29c53bf9949ef9135023ef1ebe9cc",
      "51ba5cd2426648769a50236999c38437",
      "82f0521b6d3e47a79d12fdd677c504a1",
      "ca5504c34424487fa8b2a045410c2624",
      "6787c0d77a9f41df96f1c408243d40a3",
      "7d1be533e8c94f9bb328b9b612eae6b6",
      "6ac5f67698ad4d3b8ab52cc73ceea831",
      "ce3aefd48c934dccbb8e04691c4b493b",
      "b9561b3fb184448ab5fdeddf7dd240a7",
      "237b0586ad444b588fdce72d637cb04c",
      "cf1ae3271e3e4b0bb9208410ad3c2fca",
      "cd871da0e7f441418e14ffffa4d98a2f"
     ]
    },
    "id": "40d0ef6a",
    "outputId": "c9725b20-825c-4087-b037-f510e3815ab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 165201.62 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 16350.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.rename_columns({\"prompt\": \"review\"})\n",
    "dataset = dataset.filter(lambda x: len(x[\"review\"]) > 500, batched=False)\n",
    "dataset = dataset.map(lambda x: {\"review\": x[\"review\"][:1000]}, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcdb5d7-12e3-49e7-bdac-f46d6f627dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d7e8b8",
   "metadata": {
    "id": "96d7e8b8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tokenizer.pad_token = \u001b[43mtokenizer\u001b[49m.eos_token\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98c8a5f2-88e5-469a-9b03-70b3b154021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aloe-qwen-rl-trial-run/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3adda4dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f9aaecb343cd4b0f81bf4943087e6030",
      "4513b7c4492e496094d51ef28737dd8c",
      "82e75de342da494bb92b43c3b4dd57ae",
      "6d29a8b0454948d5af6821a55b90832a",
      "805d92625e0c425e9b2743adeb445e98",
      "d3775995f5734bd4a076b8895b99ff46",
      "4f98b11af0b34f4abcf8a5e9e1871972",
      "514f81fb8f124190a7ebc3b093167af3",
      "ff9906a7b9084238a6fd779101863267",
      "922210d0721148d2974d90143076da5c",
      "64349624aed54778ba4a099ae84bae75",
      "e661377a4a3344548dbc254e686d093a",
      "2748356f1285432c9f5ff6517b3fef75",
      "dc213134a34e4afbba379968c507d27a",
      "18138eff2c1d45099ca92c0b8085ed8b",
      "a9e6101dfe93483d8a4622f01e72d8b6",
      "f37b9111d36840e3916d1587a1b52548",
      "6d52c0833fdc4159aec56fc66f3587ea",
      "412f3b6e6e8940308ab8d108f8ad2d31",
      "fa70639d86a3430a9d42b35889600fdf",
      "74b5ada33e994668b35fe2a354c42f5b",
      "dfe9ff8cc4de42ef8c81876c5869c205"
     ]
    },
    "id": "3adda4dc",
    "outputId": "236d41b4-d16b-484c-be30-c0c2c91dd6f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5682.12 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5882.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "txt_in_len = 5\n",
    "txt_out_len = 32\n",
    "seed = 1\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"input_ids\": tokenizer.encode(\" \" + x[\"chosen\"], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=32)[0]},\n",
    "    batched=False,\n",
    ")\n",
    "dataset = dataset.map(lambda x: {\"query\": tokenizer.decode(x[\"input_ids\"])}, batched=False)\n",
    "dataset = dataset[:20480]\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(dataset)\n",
    "dataset.set_format(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e189a22b",
   "metadata": {
    "id": "e189a22b"
   },
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc612f5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "fa8c1e18c1f5459eaa7cfe037c5a6c1a",
      "41b6677670b8452aad060f8a8627abe2",
      "c6fc7e291f5d4a718e8c41ca8350f28b",
      "fc4a248fab0d44278e4ae304b8f22ca0",
      "a175fe7a3d1345acb87a1331c1e99da3",
      "da402758cac34e388bd6fcd2c9e4bd9c",
      "d0a6f2316afa41de9bb99c717a571907",
      "a08645f4a4f34ecb9a542995085066a1",
      "7d467840b5874d7c96eea2f3dd11b704",
      "d13aa41de87d4fc88c2f292105e1c5fc",
      "6445cc51d9f148e8a3426eb886826491",
      "b02ae57c444f4e41b5be1017b835767c",
      "0feaebeb8c3f41bbad984505915ee8a7",
      "ca9956392b204d03b8e7a057c23970c6",
      "affa3abcf1af4515943cdd4b7e60591f",
      "0fcfa0e9b856419fb58e9ff8de703575",
      "85083b7ed45444629f896daebecafda5",
      "f23c87fc18054e64adf130c8a6b36220",
      "79cdf366d19f4c72aea2416a6cbc275b",
      "e9a33ff87d8b4a989a5767741ddd0ad0",
      "cbe4ba3f7c824ea4a355859e38d9ba55",
      "8bccb99b8d30402f994a615c33225b6a",
      "718c70e51cc640da89930a8f5a983f9d",
      "05dd9568ad084f6788977551c93b7ca4",
      "0a6d68ee4a1a4198bd9318eae06eebe0",
      "04f90f04549249ada737886e7d1f4746",
      "b022e4e611af44a38b103ff7e5cbffd0",
      "6bf413f8f1174046a49c08e482674d76",
      "67ba4525e7ae4a01aff18828609e5b8b",
      "45446a474c0d4a758a387e43b4479577",
      "6dce6f68f97046c294c562ef57284b40",
      "f18d866d2fb548da91665e35c8477cb5",
      "5dce05cf2e7f4959ad03f6e00be7addd",
      "611662f527b746e885cf971ccdfe4e12",
      "4575a895f25845d49ecda955c0cd09c8",
      "ee154b555ffe4bf8979a830e282bd7af",
      "f8c101374a0644da8562b61f122c6a2d",
      "7efd123f6e82433ab1a1655f8d85bd53",
      "26a96f9b8470457f9bcbafb45052a5b9",
      "b946ddbc80b54fdfb9e6a5b81f76e298",
      "41567abf3eaf4de18808533ae4f09b13",
      "4c7528e89a7f40a9913d9dfe253c323d",
      "7e83b90947114746b127dad09e2fccf0",
      "85f7f1f4271c4621942065bc43ee39b6",
      "4c0c8e33ee57472ca9ea6b39cfb7bafc",
      "58fe722d3d4a4b35ad44f0abd405918f",
      "ab54a31a3cc34160a9bac532c3d97a1c",
      "af399cfa4fac474fac2924acc2ad5b3d",
      "5df45661115f48fb8a4d610c98abbda5",
      "59d8d73c659a4dde976d88fbb10bfd0e",
      "232c3f41c90f4b599ac2f66cfeaf4307",
      "03557a1856114a658d0689d00d866c0a",
      "92665d503e7b432789df1b5b3e18036a",
      "bbddd91608c0488ba4b8f8943cc9cb4a",
      "2ee5f553d436465d95f68302003f9718"
     ]
    },
    "id": "cc612f5f",
    "outputId": "f875e40a-f00e-4df7-df74-70ea4191f25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "WARNING:root:A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from 'aloe-qwen-rl-trial-run/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "WARNING:root:A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from 'aloe-qwen-rl-trial-run/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# rf_model_path = \"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rm_model\"\n",
    "starcoder_model = AutoModelForCausalLMWithValueHead.from_pretrained(\"aloe-qwen-rl-trial-run/\")  ##policy model from step 1\n",
    "starcoder_model = starcoder_model.to(device)\n",
    "# starcoder_model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(rf_model_path) ## reward model from step 2\n",
    "# starcoder_model_ref = starcoder_model_ref.to(device)\n",
    "starcoder_tokenizer = AutoTokenizer.from_pretrained(\"HPAI-BSC/Qwen2.5-Aloe-Beta-7B\") ## tokenizer of step 1 model., here since we are using same model for step 1 and 2 it doesnot matter\n",
    "starcoder_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2836e5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2836e5cc",
    "outputId": "b998d963-75ad-485c-edf8-ec237723d24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'chosen', 'rejected'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800d3e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4800d3e9",
    "outputId": "793fa054-1145-45d4-c3ec-f8f574703906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithValueHead(\n",
       "  (pretrained_model): GPTBigCodeForCausalLM(\n",
       "    (transformer): GPTBigCodeModel(\n",
       "      (wte): Embedding(49152, 768)\n",
       "      (wpe): Embedding(8192, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-19): 20 x GPTBigCodeBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPTBigCodeSdpaAttention(\n",
       "            (c_attn): Linear(in_features=768, out_features=896, bias=True)\n",
       "            (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPTBigCodeMLP(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act): PytorchGELUTanh()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=49152, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starcoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnUCcJ_09Loy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnUCcJ_09Loy",
    "outputId": "78159743-edfe-4a97-cb3f-e4da092c55f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithValueHead(\n",
       "  (pretrained_model): GPTBigCodeForCausalLM(\n",
       "    (transformer): GPTBigCodeModel(\n",
       "      (wte): Embedding(49152, 768)\n",
       "      (wpe): Embedding(8192, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-19): 20 x GPTBigCodeBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPTBigCodeSdpaAttention(\n",
       "            (c_attn): Linear(in_features=768, out_features=896, bias=True)\n",
       "            (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPTBigCodeMLP(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act): PytorchGELUTanh()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=49152, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starcoder_model_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e1a2e38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e1a2e38",
    "outputId": "f35d6daa-651a-4322-c96b-c789aef855b4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.SGD(starcoder_model.parameters(), lr=config.learning_rate)\n",
    "ppo_trainer = PPOTrainer(config, starcoder_model, starcoder_model, starcoder_tokenizer, dataset=dataset, data_collator=collator, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e72ad",
   "metadata": {
    "id": "e63e72ad"
   },
   "outputs": [],
   "source": [
    "# for i in ppo_trainer.dataloader:\n",
    "#   print(i)\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329e292",
   "metadata": {
    "id": "e329e292"
   },
   "outputs": [],
   "source": [
    "ctrl_str = [\"[negative]\", \"[positive]\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # this should be handled by accelerate\n",
    "ctrl_tokens = dict((s, starcoder_tokenizer.encode(s, return_tensors=\"pt\").squeeze().to(device)) for s in ctrl_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ac197",
   "metadata": {
    "id": "597ac197"
   },
   "outputs": [],
   "source": [
    "def pos_logit_to_reward(logit, task):\n",
    "    \"\"\"\n",
    "    Take the positive sentiment logit and scale it for the task.\n",
    "        task [negative]: reward = -logit\n",
    "        task [neutral]: reward = -2*abs(logit)+4\n",
    "        task [positive]: reward = logit\n",
    "    \"\"\"\n",
    "    for i in range(len(logit)):\n",
    "        if task[i] == \"[negative]\":\n",
    "            logit[i] = -logit[i]\n",
    "        elif task[i] == \"[positive]\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"task has to be in [0, 1, 2]!\")\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a916542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a916542",
    "outputId": "995886e2-9060-4de0-9776-8ee3b46ee574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.,  4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_logit_to_reward(torch.Tensor([4, 4]), ctrl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974cb44",
   "metadata": {
    "id": "2974cb44"
   },
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": starcoder_tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 32,\n",
    "    \"eos_token_id\": -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OnximsPym_Ok",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnximsPym_Ok",
    "outputId": "34f3fc1e-f539-40a7-d040-319c23fa9dc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20tkPg4HetsX",
   "metadata": {
    "id": "20tkPg4HetsX"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def convert_to_json(output_list, src_list=None, ref_list=None, context_list=None, \\\n",
    "            scores=None, doc_id=None, system_id=None):\n",
    "    \"\"\"\n",
    "        Convert the data into the json format.\n",
    "\n",
    "        output_list: a list of model output\n",
    "        src_list: source input for different NLG tasks. For example, source document for summarization\n",
    "                  and dialogue history for dialogue response generation\n",
    "        ref_list: human-annotated groundtruth\n",
    "        context_list: the context needed to evaluate several specific dimension. For example,\n",
    "                      additional factual information when evaluating engagingness and groundedness in dialogues\n",
    "        scores: human scores for evaluating the model output. They can be used to calculate the correlation\n",
    "                between evaluators and human judgements. The scores should be stored in a dictionary. For example,\n",
    "                {'fluency': 2.0, 'coherence': 3.0} could be the human score for a sample.\n",
    "        doc_id: the index of the input source. It can be used to calculate summary-level correlation for summarzation\n",
    "        system_id: the index of the generation system. It can be used to calculate system-level correlation.\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    for i in range(len(output_list)):\n",
    "        cur = {}\n",
    "        cur['system_output'] = output_list[i]\n",
    "        if src_list is not None:\n",
    "            cur['source'] = src_list[i]\n",
    "        if ref_list is not None:\n",
    "            cur['reference'] = ref_list[i]\n",
    "        if context_list is not None:\n",
    "            cur['context'] = context_list[i]\n",
    "        if scores is not None:\n",
    "            cur['scores'] = scores[i]\n",
    "        if doc_id is not None:\n",
    "            cur['doc_id'] = doc_id[i]\n",
    "        if system_id is not None:\n",
    "            cur['system_id'] = system_id[i]\n",
    "        json_data.append(cur)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def add_question(dimension, output, src=None, ref=None, context=None, task=None):\n",
    "    \"\"\"\n",
    "        Add questions to generate input in Bool-QA format for UniEval.\n",
    "\n",
    "        dimension: specific dimension to be evaluated\n",
    "        src: source input for different NLG tasks. For example, source document for summarization\n",
    "             and dialogue history for dialogue response generation.\n",
    "        output: output text generated by the models\n",
    "        ref: human-annotataed groundtruth\n",
    "        context: the context needed to evaluate several specific dimension. For example,\n",
    "                 additional factual information when evaluating engagingness and groundedness in dialogues.\n",
    "    \"\"\"\n",
    "\n",
    "    input_with_question = []\n",
    "    for i in range(len(output)):\n",
    "        # For summarization\n",
    "        if task == 'summarization':\n",
    "            if dimension == 'fluency':\n",
    "                cur_input = 'question: Is this a fluent paragraph? </s> paragraph: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent summary to the document? </s> summary: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            elif dimension == 'relevance':\n",
    "                cur_input = 'question: Is this summary relevant to the reference? </s> summary: ' + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For dialogues\n",
    "        elif task == 'dialogue':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a natural response in the dialogue? </s> response: ' + output[i]\n",
    "            elif dimension == 'coherence':\n",
    "                cur_input = 'question: Is this a coherent response given the dialogue history? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i]\n",
    "            elif dimension == 'engagingness':\n",
    "                cur_input = 'question: Is this an engaging and informative response according to the dialogue history and fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> dialogue history: ' + src[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'groundedness':\n",
    "                cur_input = 'question: Is this response consistent with knowledge in the fact? </s> response: '\\\n",
    "                            + output[i] + ' </s> fact: ' + context[i]\n",
    "            elif dimension == 'understandability':\n",
    "                cur_input = 'question: Is this an understandable response in the dialogue? </s> response: ' + output[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For data-to-text\n",
    "        elif task == 'data2text':\n",
    "            if dimension == 'naturalness':\n",
    "                cur_input = 'question: Is this a fluent utterance? </s> utterance: ' + output[i]\n",
    "            elif dimension == 'informativeness':\n",
    "                cur_input = 'question: Is this sentence informative according to the reference? </s> sentence: '\\\n",
    "                            + output[i] + ' </s> reference: ' + ref[i]\n",
    "            else:\n",
    "                raise NotImplementedError('The input format for this dimension is still undefined. Please customize it first.')\n",
    "        # For factual consistency detection\n",
    "        elif task == 'fact':\n",
    "            if dimension == 'consistency':\n",
    "                cur_input = 'question: Is this claim consistent with the document? </s> claim: ' + output[i] + ' </s> document: ' + src[i]\n",
    "            else:\n",
    "                raise NotImplementedError('No other dimensions for the factual consistency detection task.')\n",
    "        # For new customized tasks\n",
    "        else:\n",
    "            raise NotImplementedError('Other tasks are not implemented, please customize specific tasks here.')\n",
    "        input_with_question.append(cur_input)\n",
    "    return input_with_question\n",
    "\n",
    "\n",
    "def print_scores(scores):\n",
    "    table = PrettyTable(['Dimensions','Score'])\n",
    "    print('\\nEvaluation scores are shown below:')\n",
    "    dims = list(scores[0].keys())\n",
    "    for dim in dims:\n",
    "        cur_score = 0\n",
    "        for i in range(len(scores)):\n",
    "            cur_score += scores[i][dim]\n",
    "        table.add_row([dim, round(cur_score / len(scores), 6)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cHjNeU5TiYkl",
   "metadata": {
    "id": "cHjNeU5TiYkl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from scorer import UniEvaluator  # Make sure this import works after placing scorer.py in the same directory\n",
    "\n",
    "def evaluate(data, dims=None, overall=True, print_result=False, model_name_or_path=\"t5-small\", task='summarization', device='cuda:0'):\n",
    "    \"\"\"\n",
    "    Get the scores of all the given dimensions (fluency, consistency, coherence, relevance)\n",
    "\n",
    "    data: A list of dictionaries, where each dictionary contains:\n",
    "          - 'source': The original text\n",
    "          - 'system_output': The generated system output (summary)\n",
    "          - 'reference' (optional): Reference summary for relevance evaluation\n",
    "\n",
    "    dims: A list of dimensions to be evaluated. If dims is None, it evaluates four default dimensions:\n",
    "          coherence, consistency, fluency, relevance.\n",
    "\n",
    "    overall: Boolean to indicate whether the overall score is calculated as the average of all dimensions.\n",
    "\n",
    "    print_result: Boolean to print the results on the screen.\n",
    "\n",
    "    model_name_or_path: The model name or path to use for evaluation, e.g., 't5-small'\n",
    "\n",
    "    task: The task type (used in scoring if needed, like summarization or other NLP tasks).\n",
    "\n",
    "    device: The device to use for evaluation ('cpu' or 'cuda:0').\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the scorer\n",
    "    scorer = UniEvaluator(model_name_or_path=model_name_or_path, device=device)\n",
    "\n",
    "    n_data = len(data)\n",
    "    eval_scores = [{} for _ in range(n_data)]\n",
    "\n",
    "    # Default dimensions if not provided\n",
    "    if dims is None:\n",
    "        dims = ['coherence', 'consistency', 'fluency']   #add relevance\n",
    "\n",
    "    for dim in dims:\n",
    "        print(f'Evaluating {dim} of {n_data} samples !!!')\n",
    "\n",
    "        if dim == 'consistency' or dim == 'fluency':\n",
    "            # Sentence-level scores for consistency and fluency\n",
    "            src_list, output_list = [], []\n",
    "            n_sents = []  # number of sentences in each summary\n",
    "\n",
    "            for i in range(n_data):\n",
    "                if dim == 'consistency':\n",
    "                    source = data[i]['source']\n",
    "                else:\n",
    "                    source = ''\n",
    "                system_outputs = sent_tokenize(data[i]['system_output'])\n",
    "                n_sents.append(len(system_outputs))\n",
    "                for j in range(len(system_outputs)):\n",
    "                    src_list.append(source)\n",
    "                    output_list.append(system_outputs[j])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, task=task)\n",
    "            sent_score = scorer.score(input_list)\n",
    "\n",
    "            # Calculate average sentence-level scores for each sample\n",
    "            start_idx = 0\n",
    "            score = []\n",
    "            for cur_n_sent in n_sents:\n",
    "                score.append(sum(sent_score[start_idx:start_idx + cur_n_sent]) / cur_n_sent)\n",
    "                start_idx += cur_n_sent\n",
    "\n",
    "        elif dim == 'coherence' or dim == 'relevance':\n",
    "            # Summary-level scores for coherence and relevance\n",
    "            src_list, output_list, ref_list = [], [], []\n",
    "\n",
    "            for i in range(n_data):\n",
    "                src_list.append(data[i]['source'])\n",
    "                output_list.append(data[i]['system_output'])\n",
    "                if dim == 'relevance':\n",
    "                    ref_list.append(data[i]['reference'])\n",
    "\n",
    "            input_list = add_question(dimension=dim, output=output_list, src=src_list, ref=ref_list, task=task)\n",
    "            score = scorer.score(input_list)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"The input format for the dimension '{dim}' is still undefined. Please customize it.\")\n",
    "\n",
    "        # Store the scores for the current dimension\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i][dim] = score[i]\n",
    "\n",
    "    # Calculate overall score (average of all evaluated dimensions)\n",
    "    if overall:\n",
    "        for i in range(n_data):\n",
    "            eval_scores[i]['overall'] = np.mean([eval_scores[i][dim] for dim in dims])\n",
    "\n",
    "    # Print the result if requested\n",
    "    if print_result:\n",
    "        print_scores(eval_scores)\n",
    "\n",
    "    # Calculate average score across all the dimensions except 'overall'\n",
    "    avg_score = []\n",
    "    for i in range(n_data):\n",
    "        # Exclude 'overall' from the averaging\n",
    "        dimensions = [dim for dim in dims if dim != 'overall']\n",
    "        avg_score.append(np.mean([eval_scores[i][dim] for dim in dimensions]))\n",
    "\n",
    "    return avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "zdxA6LnigvNX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdxA6LnigvNX",
    "outputId": "8a4d38b4-5e0a-4c5c-ce22-5c4631a4fce2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSCE CSE.DESKTOP-IUB6THA\\.conda\\envs\\kshitij\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 4 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 4 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 4 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 71.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------+----------+\n",
      "|  Dimensions |  Score   |\n",
      "+-------------+----------+\n",
      "|  coherence  | 0.449252 |\n",
      "| consistency | 0.64936  |\n",
      "|   fluency   | 0.385504 |\n",
      "|   overall   | 0.494705 |\n",
      "+-------------+----------+\n",
      "[np.float64(0.6976819110569896), np.float64(0.5384448786819837), np.float64(0.5444390657640407), np.float64(0.19825604586050996)]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        'source': \"Doctor: Hello, how are you feeling today?\\nPatient: I've been feeling a bit tired and dizzy.\\nDoctor: How long has this been happening?\\nPatient: For about a week now. I also have trouble sleeping.\\nDoctor: I see. Have you been under a lot of stress lately?\\nPatient: Yes, work has been quite stressful.\\nDoctor: That could be contributing. Let’s do some tests to rule out other issues.\",\n",
    "        'system_output': \"Patient reports tiredness, dizziness, and difficulty sleeping for a week. Work-related stress may be a factor. Doctor will conduct tests to check for other problems.\"\n",
    "    },\n",
    "    {\n",
    "        'source': \"Doctor: What brings you in today?\\nPatient: I’ve been having some chest pain and shortness of breath.\\nDoctor: How severe is the pain?\\nPatient: It’s sharp, and it comes and goes.\\nDoctor: When did it start?\\nPatient: It started two days ago.\\nDoctor: Any history of heart problems?\\nPatient: Yes, my father had heart disease.\\nDoctor: We’ll need to do an ECG and some blood tests to check your heart health.\",\n",
    "        'system_output': \"Patient has sharp chest pain and shortness of breath for two days. Family history of heart disease. Doctor will perform an ECG and blood tests to assess heart health.\"\n",
    "    },\n",
    "    {\n",
    "        'source': \"Doctor: How are you feeling today?\\nPatient: I’ve had a sore throat and a cough for the past few days.\\nDoctor: Any fever or difficulty swallowing?\\nPatient: Yes, I’ve had a low fever, but swallowing is fine.\\nDoctor: Any history of allergies or similar symptoms?\\nPatient: Not really.\\nDoctor: It could be a viral infection. I recommend rest, fluids, and maybe some over-the-counter medicine.\",\n",
    "        'system_output': \"Patient reports sore throat, cough, and a low fever. Doctor advises rest, fluids, and over-the-counter medication as the symptoms suggest a viral infection.\"\n",
    "    },\n",
    "    {\n",
    "        'source': \"Doctor: What’s bothering you today?\\nPatient: I’ve been experiencing frequent headaches and some nausea.\\nDoctor: How often do you get the headaches?\\nPatient: It’s been almost every day for the past week.\\nDoctor: Any other symptoms like blurred vision or dizziness?\\nPatient: No, just the headache and nausea.\\nDoctor: We’ll schedule an MRI to get a better understanding of the issue.\",\n",
    "        'system_output': \"Patient complains of daily headaches and nausea for the past week. No blurred vision or dizziness. Doctor will schedule an MRI for further evaluation.\"\n",
    "    }\n",
    "]\n",
    "score = evaluate(data, print_result=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b1f30b8-0c80-4f70-9317-a1e371ec23f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf0762",
   "metadata": {
    "id": "27cf0762"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_score(model, tokenizer, responses):\n",
    "    \"\"\"\n",
    "    Calculates scores for responses based on a model and tokenizer.\n",
    "\n",
    "    Instead of directly evaluating the 'responses' (which are strings),\n",
    "    this function now creates a list of dictionaries with the format\n",
    "    expected by the 'evaluate' function. It assumes the original prompt\n",
    "    is available in a 'prompt' variable and uses it to construct the 'source'\n",
    "    field in the dictionaries.\n",
    "\n",
    "    Args:\n",
    "        model: The model used for evaluation.\n",
    "        tokenizer: The tokenizer associated with the model.\n",
    "        responses: A list of generated responses (strings).\n",
    "\n",
    "    Returns:\n",
    "        A list of scores for the responses.\n",
    "    \"\"\"\n",
    "    positive_logist = []\n",
    "\n",
    "    positive_logist = evaluate(responses)  # Call 'evaluate' with the correct data format0\n",
    "    # Convert the NumPy array to a PyTorch tensor before returning\n",
    "    return torch.tensor(positive_logist, dtype=torch.float32).to(device) # Assuming 'device' is defined as your target device (e.g., 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d47d37",
   "metadata": {
    "id": "41d47d37"
   },
   "outputs": [],
   "source": [
    "# responses =[\"ashish is a goo\", \"heelow how are you\", \"__IT_\\nr/\\n: r RelationshipRelationship]]0]\\nlsriend\\n2//M]\\n [ [ a\\n the was to the [. a friends to\\n\\n:\\n [lfriend [ me have a aried in his19 minutes.\\n\\nWhat Modified:** girlfriend was through the Facebook.. I my my friends.**** my  of lf**\\n\\n** was d1ing for my few personirl** I had for findoolpping my my the future** but I was that in\\n\\n** have ali  of to she  tolirt my me girl. and she found my about my.. me few of gir.1viously). was\\'t find her was).\\n\\n** was it about my twoirl and the had  Facebook. the  and she gand historyirl) was in April,\\n to, find, were flirted. I a messages.. f.ing on her.\\n girlM\\n; I1 girirllfriend and the19 months. to my Facebook.. my permission. she her messages. my.lirty with my fewirl.\\n found her with me. I through more with\\n\"]\n",
    "# get_score(starcoder_model, tokenizer, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sf4gAExj4mQF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf4gAExj4mQF",
    "outputId": "b32815a1-785f-403a-9964-f04901efd5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "rf_model_path = \"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rm_model\"\n",
    "starcoder_model = AutoModelForCausalLMWithValueHead.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/summarization_policy_new\")  ##policy model from step 1\n",
    "starcoder_model = starcoder_model.to(device)  # Explicitly move to GPU\n",
    "starcoder_model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(rf_model_path) ## reward model from step 2\n",
    "starcoder_model_ref = starcoder_model_ref.to(device)  # Explicitly move to GPU\n",
    "starcoder_tokenizer = AutoTokenizer.from_pretrained(\"bigcode/tiny_starcoder_py\") ## tokenizer of step 1 model., here since we are using same model for step 1 and 2 it doesnot matter\n",
    "starcoder_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bad48f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0bad48f",
    "outputId": "7300189c-bc1c-40df-a57a-3a63cdbf6793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/vocab.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/merges.txt',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/added_tokens.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###saving the model\n",
    "# starcoder_model.save_pretrained(\"rhlfmodel/\")\n",
    "# starcoder_tokenizer.save_pretrained(\"rhlfmodel/\")\n",
    "\n",
    "ppo_trainer.model.pretrained_model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/\")\n",
    "starcoder_tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i2x05-xl3VZ2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i2x05-xl3VZ2",
    "outputId": "748c68a8-638c-467c-9ef8-2a1360dfa45f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[negative]', '[positive]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n",
      "`eos_token_id` should consist of positive integers, but is tensor([-1], device='cuda:0'). Your generation will not stop until the maximum length is reached. Depending on other flags, it may even crash.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating coherence of 128 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 2/16 [00:00<00:00, 17.53it/s]\u001b[A\n",
      " 25%|██▌       | 4/16 [00:00<00:00, 18.57it/s]\u001b[A\n",
      " 44%|████▍     | 7/16 [00:00<00:00, 21.33it/s]\u001b[A\n",
      " 62%|██████▎   | 10/16 [00:00<00:00, 22.68it/s]\u001b[A\n",
      " 81%|████████▏ | 13/16 [00:00<00:00, 22.23it/s]\u001b[A\n",
      "100%|██████████| 16/16 [00:00<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating consistency of 128 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 30.73it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 28.95it/s]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 28.04it/s]\u001b[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 28.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fluency of 128 samples !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 37.59it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 36.77it/s]\u001b[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 36.79it/s]\u001b[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 37.38it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1140, -0.5964, -0.4760,  0.4730,  0.3701, -0.6378, -0.4970, -0.8522,\n",
      "         0.7088, -0.3443,  0.5310, -0.6662, -0.4598, -0.5201,  0.3532,  0.6290,\n",
      "         0.4458, -0.4076,  0.4418, -0.5959,  0.7573, -0.6279,  0.5680,  0.4816,\n",
      "         0.6701, -0.5965, -0.4724,  0.6003, -0.5661, -0.4443, -0.7133, -0.4767,\n",
      "        -0.7351, -0.7428, -0.5126, -0.4642,  0.4819,  0.5510, -0.5316, -0.6129,\n",
      "         0.5767, -0.6015, -0.6732, -0.6184,  0.3206, -0.6439, -0.5275, -0.5137,\n",
      "         0.4751, -0.5006, -0.6168, -0.3965, -0.5622,  0.5087,  0.3758, -0.3865,\n",
      "         0.5497,  0.3349,  0.5346, -0.6813, -0.4501,  0.5392, -0.5807, -0.5732,\n",
      "        -0.3888,  0.3660, -0.5514, -0.6128,  0.4821, -0.4926, -0.6747, -0.5794,\n",
      "         0.6234,  0.5111, -0.5365, -0.5109,  0.4887,  0.5621,  0.5795, -0.4082,\n",
      "         0.5549, -0.2743,  0.6639,  0.4904, -0.5654,  0.4000, -0.5261,  0.5667,\n",
      "        -0.4763,  0.5618, -0.5892, -0.5535,  0.5563,  0.5294, -0.4903, -0.5240,\n",
      "        -0.4411, -0.3146,  0.3763,  0.6448,  0.3616, -0.5416,  0.1495, -0.4157,\n",
      "        -0.4372,  0.3702, -0.3426,  0.4829, -0.6117, -0.5913, -0.4910,  0.6111,\n",
      "         0.4352,  0.6466,  0.5287, -0.5229,  0.4432, -0.6639,  0.6727,  0.6078,\n",
      "        -0.4494, -0.5100,  0.5923, -0.3742,  0.5659, -0.5214,  0.3296, -0.3942],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [01:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.55 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.49 GiB is free. Process 289527 has 13.25 GiB memory in use. Of the allocated memory 12.90 GiB is allocated by PyTorch, and 228.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-0881eef0f503>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#### Run PPO training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctrl_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, queries, responses, scores, response_masks)\u001b[0m\n\u001b[1;32m    823\u001b[0m                         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmini_batch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_inputs_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                         logprobs, logits, vpreds, _ = self.batched_forward_pass(\n\u001b[0m\u001b[1;32m    826\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                             \u001b[0mmini_batch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"queries\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36mbatched_forward_pass\u001b[0;34m(self, model, queries, responses, model_inputs, return_logits, response_masks)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogprobs_from_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/core.py\u001b[0m in \u001b[0;36mlogprobs_from_logits\u001b[0;34m(logits, labels, gather)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m563\u001b[0m\u001b[0;31m#issuecomment-330103591\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2246\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.55 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.49 GiB is free. Process 289527 has 13.25 GiB memory in use. Of the allocated memory 12.90 GiB is allocated by PyTorch, and 228.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "for epoch in range(1):\n",
    "    for batch in tqdm(ppo_trainer.dataloader):\n",
    "        (logs, game_data,) = (\n",
    "            dict(),\n",
    "            dict(),\n",
    "        )\n",
    "\n",
    "        print(ctrl_str)\n",
    "        #### prepend a random control token\n",
    "        task_list = choices(ctrl_str, k=config.batch_size)\n",
    "        game_data[\"query\"] = [t + q for t, q in zip(task_list, batch[\"query\"])]\n",
    "        # Move input_ids to the same device as ctrl_tokens\n",
    "        query_tensors = [torch.cat((ctrl_tokens[t], input_ids.to(device))) for t, input_ids in zip(task_list, batch[\"input_ids\"])]\n",
    "\n",
    "        #### get response from gpt2\n",
    "        response_tensors = []\n",
    "        for query in query_tensors:\n",
    "            response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "            response_tensors.append(response.squeeze()[-txt_out_len:])\n",
    "#         print(response_tensors)\n",
    "        game_data[\"response\"] = [starcoder_tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "        #### sentiment analysis\n",
    "        texts = [{\"source\": q, \"system_output\": r} for q, r in zip(batch[\"query\"], game_data[\"response\"])]\n",
    "        logits = get_score(starcoder_model,starcoder_tokenizer, texts)\n",
    "        rewards = pos_logit_to_reward(logits, task_list)\n",
    "        # Convert the single tensor into a list of tensors before passing it to ppo_trainer.step\n",
    "        rewards = [r.unsqueeze(0) for r in rewards]  # Each reward is now a single-element tensor within a list\n",
    "        print(logits)\n",
    "        #### Run PPO training\n",
    "        t = time.time()\n",
    "        stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "\n",
    "        for cs in ctrl_str:\n",
    "            key = \"env/reward_\" + cs.strip(\"[]\")\n",
    "            stats[key] = np.mean([r.cpu().numpy() for r, t in zip(rewards, task_list) if t == cs])\n",
    "        ppo_trainer.log_stats(stats, game_data, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qzsSWgt-KvXO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzsSWgt-KvXO",
    "outputId": "14566276-bd09-42d4-d57d-9ecb7485d599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /content/drive/MyDrive/Medical Dialogue Summarization using PPO/rhlfmodel to /content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel\n",
      "Copy operation completed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dirs = [\"/content/drive/MyDrive/Medical Dialogue Summarization using PPO/rhlfmodel\"]\n",
    "destination = \"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO\"\n",
    "\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "# Copy each directory to the destination\n",
    "for src in source_dirs:\n",
    "    if os.path.exists(src):\n",
    "        dest_path = os.path.join(destination, os.path.basename(src))\n",
    "        shutil.copytree(src, dest_path, dirs_exist_ok=True)  # Copy with merging existing directories\n",
    "        print(f\"Copied {src} to {dest_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {src}, does not exist.\")\n",
    "\n",
    "print(\"Copy operation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf2489",
   "metadata": {
    "id": "23bf2489"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "model_path = \"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel\"\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\",model=model_path, tokenizer=model_path, max_length=40, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e2c6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026e2c6c",
    "outputId": "7e279c1c-b0ec-4711-fec1-8ad11583839d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL;DR:  My girlfriend and I broke up after she went through my Facebook account without my permission.<|endoftext|>Citizens for the Republic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'TL;DR:  My girlfriend and I broke up after she went through my Facebook account without my permission.<|endoftext|>Citizens for the Republic'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[\"rejected\"][0]\n",
    "print(text)\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NpppcYveAzWa",
   "metadata": {
    "id": "NpppcYveAzWa"
   },
   "outputs": [],
   "source": [
    "save_directory = \"//content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(save_directory).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llCvj_yCJY9S",
   "metadata": {
    "id": "llCvj_yCJY9S"
   },
   "outputs": [],
   "source": [
    "conversation = '''\n",
    "Doctor: Hi, Mr. X, I'm Dr. Y. How are you feeling today?\n",
    "\n",
    "Patient: Not too good, doctor. I've been feeling really sick lately.\n",
    "\n",
    "Doctor: I understand. Can you tell me what symptoms you're experiencing?\n",
    "\n",
    "Patient: Yes, I've been having a fever, a dry cough, and dyspnea.\n",
    "\n",
    "Doctor: I see. You were hospitalized due to moderate ARDS from COVID-19, is that correct?\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: During your physical therapy, we encountered some difficulties. Can you tell me more about that?\n",
    "\n",
    "Patient: Yes, I had trouble with position changes and deep breathing. Every time I tried to change my position or take a deep breath, I would start coughing and it would make me really short of breath.\n",
    "\n",
    "Doctor: I understand. To avoid rapid deterioration and respiratory failure, we instructed you to change positions very slowly and step-by-step, right?\n",
    "\n",
    "Patient: Yes, that's right. It took about 30 minutes to change to the prone position.\n",
    "\n",
    "Doctor: And I see that this approach increased your oxygen saturation, for example, on day 5 with 6 L/min of oxygen from 93% to 97%.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: Good. We also had to adapt your breathing exercises to avoid prolonged coughing and oxygen desaturation. Can you tell me more about that?\n",
    "\n",
    "Patient: Yes, I was instructed to stop every deep breath before coughing and to hold my breath for better air distribution.\n",
    "\n",
    "Doctor: I see that you performed the breathing exercises well and managed to increase your oxygen saturation.\n",
    "\n",
    "Patient: Yes, I did my best.\n",
    "\n",
    "Doctor: You also had difficulty maintaining sufficient oxygen saturation during physical activity, is that correct?\n",
    "\n",
    "Patient: Yes, I did. But with close monitoring and frequent breaks, I was able to perform low-level strength and walking exercises without any significant deoxygenation.\n",
    "\n",
    "Doctor: I see that your exercise progression was low on days 1 to 5, but then increased daily until your hospital discharge to a rehabilitation clinic on day 10.\n",
    "\n",
    "Patient: Yes, that's correct.\n",
    "\n",
    "Doctor: Great. I'd like to keep monitoring your progress and see how you're doing. Can you keep me updated on any changes in your symptoms?\n",
    "\n",
    "Patient: Yes, of course, doctor.\n",
    "\n",
    "Doctor: Alright, let's keep in touch. If you have any questions or concerns, don't hesitate to reach out to me.\n",
    "\n",
    "Patient: Thank you, doctor.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DOxLTH1QAKh7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOxLTH1QAKh7",
    "outputId": "95bb9ec6-05fe-4006-bc35-c2f9b800a3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " Generate a summary for the below conversation. Dont give me the prompt back. I just want the summary to be returned to me\n",
      "\n",
      "\n",
      "Doctor: Hi, Mr. X, I'm Dr. Y. How are you feeling today?\n",
      "\n",
      "Patient: Not too good, doctor. I've been feeling really sick lately.\n",
      "\n",
      "Doctor: I understand. Can you tell me what symptoms you're experiencing?\n",
      "\n",
      "Patient: Yes, I've been having a fever, a dry cough, and dyspnea.\n",
      "\n",
      "Doctor: I see. You were hospitalized due to moderate ARDS from COVID-19, is that correct?\n",
      "\n",
      "Patient: Yes, that's correct.\n",
      "\n",
      "Doctor: During your physical therapy, we encountered some difficulties. Can you tell me more about that?\n",
      "\n",
      "Patient: Yes, I had trouble with position changes and deep breathing. Every time I tried to change my position or take a deep breath, I would start coughing and it would make me really short of breath.\n",
      "\n",
      "Doctor: I understand. To avoid rapid deterioration and respiratory failure, we instructed you to change positions very slowly and step-by-step, right?\n",
      "\n",
      "Patient: Yes, that's right. It took about 30 minutes to change to the prone position.\n",
      "\n",
      "Doctor: And I see that this approach increased your oxygen saturation, for example, on day 5 with 6 L/min of oxygen from 93% to 97%.\n",
      "\n",
      "Patient: Yes, that's correct.\n",
      "\n",
      "Doctor: Good. We also had to adapt your breathing exercises to avoid prolonged coughing and oxygen desaturation. Can you tell me more about that?\n",
      "\n",
      "Patient: Yes, I was instructed to stop every deep breath before coughing and to hold my breath for better air distribution.\n",
      "\n",
      "Doctor: I see that you performed the breathing exercises well and managed to increase your oxygen saturation.\n",
      "\n",
      "Patient: Yes, I did my best.\n",
      "\n",
      "Doctor: You also had difficulty maintaining sufficient oxygen saturation during physical activity, is that correct?\n",
      "\n",
      "Patient: Yes, I did. But with close monitoring and frequent breaks, I was able to perform low-level strength and walking exercises without any significant deoxygenation.\n",
      "\n",
      "Doctor: I see that your exercise progression was low on days 1 to 5, but then increased daily until your hospital discharge to a rehabilitation clinic on day 10.\n",
      "\n",
      "Patient: Yes, that's correct.\n",
      "\n",
      "Doctor: Great. I'd like to keep monitoring your progress and see how you're doing. Can you keep me updated on any changes in your symptoms?\n",
      "\n",
      "Patient: Yes, of course, doctor.\n",
      "\n",
      "Doctor: Alright, let's keep in touch. If you have any questions or concerns, don't hesitate to reach out to me.\n",
      "\n",
      "Patient: Thank you, doctor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt, model, tokenizer, max_new_tokens=1000, temperature=0.1):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            temperature=temperature,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"Generate a summary for the below conversation. Dont give me the prompt back. I just want the summary to be returned to me\\n\\n\" + conversation\n",
    "response = generate_response(prompt, model, tokenizer)\n",
    "print(\"Generated Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j9DpRTv5DCkF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9DpRTv5DCkF",
    "outputId": "9773c05b-cdfa-4a12-9e55-b6d441eec631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBREDDIT: r/relationships\n",
      "TITLE: My [21/M] girlfriend [19/F] broke up with me after she went throug\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"review\"][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dH7ZXN5XGf3q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dH7ZXN5XGf3q",
    "outputId": "5cf53cf6-6016-4a0f-edd9-ad6236a4f04e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Medical Dialogue Summarization using PPO/rhlfmodel\")\n",
    "model_path = \"bigcode/tiny_starcoder_py\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation=True, max_length=256, padding=\"max_length\")\n",
    "text = df.iloc[2][\"prompt\"]\n",
    "tokenized_text = tokenizer(text, return_tensors=\"pt\", max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zfm2IAxW9TQo",
   "metadata": {
    "id": "Zfm2IAxW9TQo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (kshitij)",
   "language": "python",
   "name": "kshitij"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00625022a7dc4d5199606952a22f80ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7846d74db1024f7abd48c41012faee4a",
       "IPY_MODEL_6549e8a2fe714ed7a54cf0839d949db9",
       "IPY_MODEL_ae688f7eba434a4a9ee146604c672e46"
      ],
      "layout": "IPY_MODEL_e85964b9fce9460fbefb051b68b0b3b6"
     }
    },
    "032839edec244213888db5edccc5f8f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03557a1856114a658d0689d00d866c0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04f90f04549249ada737886e7d1f4746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f18d866d2fb548da91665e35c8477cb5",
      "placeholder": "​",
      "style": "IPY_MODEL_5dce05cf2e7f4959ad03f6e00be7addd",
      "value": " 442k/442k [00:00&lt;00:00, 3.08MB/s]"
     }
    },
    "05b072bdee2f464fbd8d8a0a5f073446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43962267006440248906ff7c8c4dd8c6",
      "placeholder": "​",
      "style": "IPY_MODEL_b1664e0e4ccc4349a67407bf799f5bec",
      "value": " 1.03k/1.03k [00:00&lt;00:00, 114kB/s]"
     }
    },
    "05dd9568ad084f6788977551c93b7ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bf413f8f1174046a49c08e482674d76",
      "placeholder": "​",
      "style": "IPY_MODEL_67ba4525e7ae4a01aff18828609e5b8b",
      "value": "merges.txt: 100%"
     }
    },
    "07220bd5d9374cfb86bc3d935f61e3c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "090e95d21e074d45b4424a1208e2b0f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a6d68ee4a1a4198bd9318eae06eebe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45446a474c0d4a758a387e43b4479577",
      "max": 441848,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6dce6f68f97046c294c562ef57284b40",
      "value": 441848
     }
    },
    "0fcfa0e9b856419fb58e9ff8de703575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0feaebeb8c3f41bbad984505915ee8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85083b7ed45444629f896daebecafda5",
      "placeholder": "​",
      "style": "IPY_MODEL_f23c87fc18054e64adf130c8a6b36220",
      "value": "vocab.json: 100%"
     }
    },
    "0ff1a125eef34ba18e2d46cfee1398e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10003b1b208f4adcab19037fc8da5889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12ad38cbe85c4b9ab63138939053cccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8e42567b9344eb4abeb99efdb48e744",
      "max": 677,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50b95db77526424291212b467db215e1",
      "value": 677
     }
    },
    "130acc8ffbfd49b08ef5e4829f867f98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "156c1c0838e0439fa604616923cbf17c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163f6a03558545b498a83b39b9a856d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1806e01023874dbaa0e1e1a27fcfb7af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18138eff2c1d45099ca92c0b8085ed8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74b5ada33e994668b35fe2a354c42f5b",
      "placeholder": "​",
      "style": "IPY_MODEL_dfe9ff8cc4de42ef8c81876c5869c205",
      "value": " 1000/1000 [00:00&lt;00:00, 1339.87 examples/s]"
     }
    },
    "1a279ec52b2b466397bd52667b626d74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c5eb40b7f9b4dfa99ad6119308a42bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c6e7613dbcc4297a48dc95b4c223efa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d97a59cd150445d89a8cf3a306c408f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22237b431c8e4a37bad57b3a420803d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232c3f41c90f4b599ac2f66cfeaf4307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23308a73d9664a6caf52d89199cdab52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "237b0586ad444b588fdce72d637cb04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23ad95fdeee4464d9513e96e015bce96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10003b1b208f4adcab19037fc8da5889",
      "max": 776993,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7f98e0f85f64a4b83d7c1d78cbb8bd7",
      "value": 776993
     }
    },
    "23ec4ae465144516a3db9dc4c805b414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_addd67047e754832b862754ecbefaf3b",
       "IPY_MODEL_99f7484691804d619e4bc1968c83ca0b",
       "IPY_MODEL_45eb596290b042b9b20fd8b91624ddf5"
      ],
      "layout": "IPY_MODEL_f0cf686dc0a748d79d35c04b10512018"
     }
    },
    "26a96f9b8470457f9bcbafb45052a5b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26be8d89ca904c9d9ece12fc5c1a01ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "273fb44aecc947f4815d68ea9ca13670": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2748356f1285432c9f5ff6517b3fef75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f37b9111d36840e3916d1587a1b52548",
      "placeholder": "​",
      "style": "IPY_MODEL_6d52c0833fdc4159aec56fc66f3587ea",
      "value": "Map: 100%"
     }
    },
    "29b2f761b5b349bd8aa098de4770f244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_130acc8ffbfd49b08ef5e4829f867f98",
      "placeholder": "​",
      "style": "IPY_MODEL_4a0096bcfe934c159d14aa6d349d65ea",
      "value": " 677/677 [00:00&lt;00:00, 68.7kB/s]"
     }
    },
    "2cca1e938b53495e90f01f0e1f5e5ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ee036dcaea94adeb294a7844f837d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b404c085709e4493845ead1ad89a48e6",
       "IPY_MODEL_12ad38cbe85c4b9ab63138939053cccc",
       "IPY_MODEL_29b2f761b5b349bd8aa098de4770f244"
      ],
      "layout": "IPY_MODEL_1a279ec52b2b466397bd52667b626d74"
     }
    },
    "2ee5f553d436465d95f68302003f9718": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3987baa9a0fd49fbac56ed62fa864e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c8caecbdcad4d2989428d72786b00c1",
       "IPY_MODEL_4619ba9bdb1e4f1bbdbb0948c953f574",
       "IPY_MODEL_d2a849fe48964923b51af64144fe8125"
      ],
      "layout": "IPY_MODEL_090e95d21e074d45b4424a1208e2b0f5"
     }
    },
    "3a353215523b4b228a791ae60f8c8ef6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "401c8c8ee6844e96aa40bced0b7c3ade": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "412f3b6e6e8940308ab8d108f8ad2d31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41567abf3eaf4de18808533ae4f09b13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "419c8a47f5a247a18578afc8791db2f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41b6677670b8452aad060f8a8627abe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da402758cac34e388bd6fcd2c9e4bd9c",
      "placeholder": "​",
      "style": "IPY_MODEL_d0a6f2316afa41de9bb99c717a571907",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "43962267006440248906ff7c8c4dd8c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4513b7c4492e496094d51ef28737dd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3775995f5734bd4a076b8895b99ff46",
      "placeholder": "​",
      "style": "IPY_MODEL_4f98b11af0b34f4abcf8a5e9e1871972",
      "value": "Map: 100%"
     }
    },
    "45446a474c0d4a758a387e43b4479577": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4575a895f25845d49ecda955c0cd09c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26a96f9b8470457f9bcbafb45052a5b9",
      "placeholder": "​",
      "style": "IPY_MODEL_b946ddbc80b54fdfb9e6a5b81f76e298",
      "value": "tokenizer.json: 100%"
     }
    },
    "45eb596290b042b9b20fd8b91624ddf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_747d77f3993e4a2dbb9390a81aa02dde",
      "placeholder": "​",
      "style": "IPY_MODEL_d29c98a970694ce7ad8b26b7f645dfdf",
      "value": " 10/10 [00:00&lt;00:00, 163.21 examples/s]"
     }
    },
    "4619ba9bdb1e4f1bbdbb0948c953f574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b66974c6e3045f5a4fcf18750e36c28",
      "max": 532,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5622aade820f472db2a7a8aee703cefd",
      "value": 532
     }
    },
    "4653fda4c1dd448e80ef14ef606ea511": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48971a2be26b41dfa9fd106cbed6d2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26be8d89ca904c9d9ece12fc5c1a01ff",
      "placeholder": "​",
      "style": "IPY_MODEL_b2800791e45446da8005e119d32d3a8e",
      "value": "merges.txt: 100%"
     }
    },
    "4a0096bcfe934c159d14aa6d349d65ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c0c8e33ee57472ca9ea6b39cfb7bafc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58fe722d3d4a4b35ad44f0abd405918f",
       "IPY_MODEL_ab54a31a3cc34160a9bac532c3d97a1c",
       "IPY_MODEL_af399cfa4fac474fac2924acc2ad5b3d"
      ],
      "layout": "IPY_MODEL_5df45661115f48fb8a4d610c98abbda5"
     }
    },
    "4c7528e89a7f40a9913d9dfe253c323d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f98b11af0b34f4abcf8a5e9e1871972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fbc3ad1dd6747a7ac184bf90a737a4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50b95db77526424291212b467db215e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "514f81fb8f124190a7ebc3b093167af3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51ba5cd2426648769a50236999c38437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82f0521b6d3e47a79d12fdd677c504a1",
       "IPY_MODEL_ca5504c34424487fa8b2a045410c2624",
       "IPY_MODEL_6787c0d77a9f41df96f1c408243d40a3"
      ],
      "layout": "IPY_MODEL_7d1be533e8c94f9bb328b9b612eae6b6"
     }
    },
    "53630455dcc44a0a907800d718710082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcb3647203504274bfb3ff1fc6c44e08",
      "placeholder": "​",
      "style": "IPY_MODEL_273fb44aecc947f4815d68ea9ca13670",
      "value": "vocab.json: 100%"
     }
    },
    "551521a2eb034679a56fd55d61611326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5622aade820f472db2a7a8aee703cefd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56a9b7628bd547b7937bba6016ab5328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22237b431c8e4a37bad57b3a420803d6",
      "max": 111,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5c3aa5fcdd94a3d8fb331b054faf810",
      "value": 111
     }
    },
    "57a9590522364deebf5d963a44725d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e47fd10eefce4f04bfdd745e499a53bd",
       "IPY_MODEL_a1057f1a6a1847908edd764652d87ea2",
       "IPY_MODEL_f2389500717747cc94b49d3ec1917d69"
      ],
      "layout": "IPY_MODEL_eb1d82a8695745569e2f44a4aed34e42"
     }
    },
    "58fe722d3d4a4b35ad44f0abd405918f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59d8d73c659a4dde976d88fbb10bfd0e",
      "placeholder": "​",
      "style": "IPY_MODEL_232c3f41c90f4b599ac2f66cfeaf4307",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "59d8d73c659a4dde976d88fbb10bfd0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b0d43101036469c95b6a31f037ef0ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b66974c6e3045f5a4fcf18750e36c28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dce05cf2e7f4959ad03f6e00be7addd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df45661115f48fb8a4d610c98abbda5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "611662f527b746e885cf971ccdfe4e12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4575a895f25845d49ecda955c0cd09c8",
       "IPY_MODEL_ee154b555ffe4bf8979a830e282bd7af",
       "IPY_MODEL_f8c101374a0644da8562b61f122c6a2d"
      ],
      "layout": "IPY_MODEL_7efd123f6e82433ab1a1655f8d85bd53"
     }
    },
    "63d1a6412dd04fc6962a4e37a853fa75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fef6bb6f6f5b4ba09117ccf3846604e9",
      "max": 1030,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8294ac6ca34445f5a4802b44eac51c4e",
      "value": 1030
     }
    },
    "64349624aed54778ba4a099ae84bae75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6445cc51d9f148e8a3426eb886826491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6549e8a2fe714ed7a54cf0839d949db9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1806e01023874dbaa0e1e1a27fcfb7af",
      "max": 2057395,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d00cd587a0e440cf9bcc97a48c7b2d06",
      "value": 2057395
     }
    },
    "6787c0d77a9f41df96f1c408243d40a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf1ae3271e3e4b0bb9208410ad3c2fca",
      "placeholder": "​",
      "style": "IPY_MODEL_cd871da0e7f441418e14ffffa4d98a2f",
      "value": " 1000/1000 [00:00&lt;00:00, 5909.98 examples/s]"
     }
    },
    "67ba4525e7ae4a01aff18828609e5b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6967ad3dd572446089ff72ea632f3cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9150276882d141be82bfc82ed896a337",
      "placeholder": "​",
      "style": "IPY_MODEL_5b0d43101036469c95b6a31f037ef0ef",
      "value": " 777k/777k [00:00&lt;00:00, 3.38MB/s]"
     }
    },
    "6ac5f67698ad4d3b8ab52cc73ceea831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bf413f8f1174046a49c08e482674d76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c8caecbdcad4d2989428d72786b00c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c6e7613dbcc4297a48dc95b4c223efa",
      "placeholder": "​",
      "style": "IPY_MODEL_d91967e1f7c34d67a4f673b109e952d8",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "6d29a8b0454948d5af6821a55b90832a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_922210d0721148d2974d90143076da5c",
      "placeholder": "​",
      "style": "IPY_MODEL_64349624aed54778ba4a099ae84bae75",
      "value": " 1000/1000 [00:00&lt;00:00, 2213.04 examples/s]"
     }
    },
    "6d52c0833fdc4159aec56fc66f3587ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6dce6f68f97046c294c562ef57284b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "718c70e51cc640da89930a8f5a983f9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05dd9568ad084f6788977551c93b7ca4",
       "IPY_MODEL_0a6d68ee4a1a4198bd9318eae06eebe0",
       "IPY_MODEL_04f90f04549249ada737886e7d1f4746"
      ],
      "layout": "IPY_MODEL_b022e4e611af44a38b103ff7e5cbffd0"
     }
    },
    "73e9a6b36c7649af950272da35bb00df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "747d77f3993e4a2dbb9390a81aa02dde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b5ada33e994668b35fe2a354c42f5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d3860815a44df1a74fd825424c01df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b08f80b4caf44fc39575ecf7ee568602",
       "IPY_MODEL_a690f4a1b5884914bf6ba158efaea980",
       "IPY_MODEL_a58a2a7696fd450999502438dc7e4fed"
      ],
      "layout": "IPY_MODEL_f1edb1b0218a4a84a98a8962ace2aeeb"
     }
    },
    "7846d74db1024f7abd48c41012faee4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebd38b8bd46b4998a88818587318e79e",
      "placeholder": "​",
      "style": "IPY_MODEL_a410a688f326419e8e14385a46c850c0",
      "value": "tokenizer.json: 100%"
     }
    },
    "79bed7e6b98b4b43a11968c7fb9226e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79cdf366d19f4c72aea2416a6cbc275b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d1be533e8c94f9bb328b9b612eae6b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d467840b5874d7c96eea2f3dd11b704": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e83b90947114746b127dad09e2fccf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7efd123f6e82433ab1a1655f8d85bd53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f14f14bd8984cf5a48175d074f4338c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f99f8beda08491db4d43ebf22e1e7fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "805d92625e0c425e9b2743adeb445e98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8294ac6ca34445f5a4802b44eac51c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82da4d1b78e54f578fbd4aa260c2f9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e258ce9e8dd3427da51991741635c2be",
      "max": 441848,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_551521a2eb034679a56fd55d61611326",
      "value": 441848
     }
    },
    "82e75de342da494bb92b43c3b4dd57ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_514f81fb8f124190a7ebc3b093167af3",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff9906a7b9084238a6fd779101863267",
      "value": 1000
     }
    },
    "82f0521b6d3e47a79d12fdd677c504a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ac5f67698ad4d3b8ab52cc73ceea831",
      "placeholder": "​",
      "style": "IPY_MODEL_ce3aefd48c934dccbb8e04691c4b493b",
      "value": "Map: 100%"
     }
    },
    "85083b7ed45444629f896daebecafda5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f7f1f4271c4621942065bc43ee39b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "861f9a6fe2484be98f394c8ee28502ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48971a2be26b41dfa9fd106cbed6d2fc",
       "IPY_MODEL_82da4d1b78e54f578fbd4aa260c2f9b7",
       "IPY_MODEL_e2e6186a6bdf4898b6c2aaecd91dcca0"
      ],
      "layout": "IPY_MODEL_1d97a59cd150445d89a8cf3a306c408f"
     }
    },
    "88a330bb657a447cbe54a4186e6d0733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8974689e8d954cc7ba35a7224c3d6702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bccb99b8d30402f994a615c33225b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c8b7de980d84bf189b633d360e2c03a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e7341e3add74b2abca6d6b80b1cb0ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5eb40b7f9b4dfa99ad6119308a42bb",
      "placeholder": "​",
      "style": "IPY_MODEL_8974689e8d954cc7ba35a7224c3d6702",
      "value": " 111/111 [00:00&lt;00:00, 5.87kB/s]"
     }
    },
    "9150276882d141be82bfc82ed896a337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "922210d0721148d2974d90143076da5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92665d503e7b432789df1b5b3e18036a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94e72ccb8df1400b97164c2ffc0d2a95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9550de7afeff4fe5b1d4077c0305225a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99f7484691804d619e4bc1968c83ca0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f14f14bd8984cf5a48175d074f4338c",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f99f8beda08491db4d43ebf22e1e7fe",
      "value": 10
     }
    },
    "9adb359c88b24046b0f814383eb38f0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bcac87327ba469b8d38eec46341f7e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef779a51f2642e3b29b5f99a4926724": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a06498f69a104dceb7cbbc4b7861c100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f142622223614832a2c86be61e7ef21b",
       "IPY_MODEL_56a9b7628bd547b7937bba6016ab5328",
       "IPY_MODEL_8e7341e3add74b2abca6d6b80b1cb0ea"
      ],
      "layout": "IPY_MODEL_9bcac87327ba469b8d38eec46341f7e3"
     }
    },
    "a08645f4a4f34ecb9a542995085066a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1057f1a6a1847908edd764652d87ea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0791f63c8df4705891523af478a29e8",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9550de7afeff4fe5b1d4077c0305225a",
      "value": 1000
     }
    },
    "a175fe7a3d1345acb87a1331c1e99da3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a410a688f326419e8e14385a46c850c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4ef1cf1efaa427e8d2762826d6669d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a58a2a7696fd450999502438dc7e4fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_032839edec244213888db5edccc5f8f2",
      "placeholder": "​",
      "style": "IPY_MODEL_2cca1e938b53495e90f01f0e1f5e5ea5",
      "value": " 657M/657M [00:27&lt;00:00, 24.6MB/s]"
     }
    },
    "a690f4a1b5884914bf6ba158efaea980": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fbc3ad1dd6747a7ac184bf90a737a4a",
      "max": 656601304,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_163f6a03558545b498a83b39b9a856d2",
      "value": 656601304
     }
    },
    "a9e6101dfe93483d8a4622f01e72d8b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab54a31a3cc34160a9bac532c3d97a1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03557a1856114a658d0689d00d866c0a",
      "max": 532,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92665d503e7b432789df1b5b3e18036a",
      "value": 532
     }
    },
    "addd67047e754832b862754ecbefaf3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc3ce597378a478695879fdb4db904f2",
      "placeholder": "​",
      "style": "IPY_MODEL_8c8b7de980d84bf189b633d360e2c03a",
      "value": "Map: 100%"
     }
    },
    "ae688f7eba434a4a9ee146604c672e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e9a6b36c7649af950272da35bb00df",
      "placeholder": "​",
      "style": "IPY_MODEL_a4ef1cf1efaa427e8d2762826d6669d6",
      "value": " 2.06M/2.06M [00:00&lt;00:00, 9.55MB/s]"
     }
    },
    "af399cfa4fac474fac2924acc2ad5b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbddd91608c0488ba4b8f8943cc9cb4a",
      "placeholder": "​",
      "style": "IPY_MODEL_2ee5f553d436465d95f68302003f9718",
      "value": " 532/532 [00:00&lt;00:00, 44.7kB/s]"
     }
    },
    "affa3abcf1af4515943cdd4b7e60591f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbe4ba3f7c824ea4a355859e38d9ba55",
      "placeholder": "​",
      "style": "IPY_MODEL_8bccb99b8d30402f994a615c33225b6a",
      "value": " 777k/777k [00:00&lt;00:00, 3.47MB/s]"
     }
    },
    "b022e4e611af44a38b103ff7e5cbffd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02ae57c444f4e41b5be1017b835767c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0feaebeb8c3f41bbad984505915ee8a7",
       "IPY_MODEL_ca9956392b204d03b8e7a057c23970c6",
       "IPY_MODEL_affa3abcf1af4515943cdd4b7e60591f"
      ],
      "layout": "IPY_MODEL_0fcfa0e9b856419fb58e9ff8de703575"
     }
    },
    "b08f80b4caf44fc39575ecf7ee568602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e89d6959ed7a444992c43a7b2518f930",
      "placeholder": "​",
      "style": "IPY_MODEL_94e72ccb8df1400b97164c2ffc0d2a95",
      "value": "model.safetensors: 100%"
     }
    },
    "b1664e0e4ccc4349a67407bf799f5bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2800791e45446da8005e119d32d3a8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b396c7d525a94e3daa639377f5a8747c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b404c085709e4493845ead1ad89a48e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4653fda4c1dd448e80ef14ef606ea511",
      "placeholder": "​",
      "style": "IPY_MODEL_9adb359c88b24046b0f814383eb38f0a",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "b8737afab12f4f76941d89ec0d09bcf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b946ddbc80b54fdfb9e6a5b81f76e298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9561b3fb184448ab5fdeddf7dd240a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbddd91608c0488ba4b8f8943cc9cb4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc3ce597378a478695879fdb4db904f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcb3647203504274bfb3ff1fc6c44e08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0791f63c8df4705891523af478a29e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5c3aa5fcdd94a3d8fb331b054faf810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6fc7e291f5d4a718e8c41ca8350f28b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a08645f4a4f34ecb9a542995085066a1",
      "max": 677,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d467840b5874d7c96eea2f3dd11b704",
      "value": 677
     }
    },
    "ca5504c34424487fa8b2a045410c2624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9561b3fb184448ab5fdeddf7dd240a7",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_237b0586ad444b588fdce72d637cb04c",
      "value": 1000
     }
    },
    "ca9956392b204d03b8e7a057c23970c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79cdf366d19f4c72aea2416a6cbc275b",
      "max": 776993,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9a33ff87d8b4a989a5767741ddd0ad0",
      "value": 776993
     }
    },
    "cbe4ba3f7c824ea4a355859e38d9ba55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc8edf2b13414ed08b8e994302084194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_419c8a47f5a247a18578afc8791db2f1",
      "placeholder": "​",
      "style": "IPY_MODEL_23308a73d9664a6caf52d89199cdab52",
      "value": "config.json: 100%"
     }
    },
    "cd871da0e7f441418e14ffffa4d98a2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce3aefd48c934dccbb8e04691c4b493b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf1ae3271e3e4b0bb9208410ad3c2fca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d00cd587a0e440cf9bcc97a48c7b2d06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0a6f2316afa41de9bb99c717a571907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d13aa41de87d4fc88c2f292105e1c5fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d29c98a970694ce7ad8b26b7f645dfdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2a849fe48964923b51af64144fe8125": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79bed7e6b98b4b43a11968c7fb9226e5",
      "placeholder": "​",
      "style": "IPY_MODEL_88a330bb657a447cbe54a4186e6d0733",
      "value": " 532/532 [00:00&lt;00:00, 54.7kB/s]"
     }
    },
    "d3775995f5734bd4a076b8895b99ff46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d91967e1f7c34d67a4f673b109e952d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da402758cac34e388bd6fcd2c9e4bd9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da5f875c9faa4fe6b42be094adae0a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc8edf2b13414ed08b8e994302084194",
       "IPY_MODEL_63d1a6412dd04fc6962a4e37a853fa75",
       "IPY_MODEL_05b072bdee2f464fbd8d8a0a5f073446"
      ],
      "layout": "IPY_MODEL_b8737afab12f4f76941d89ec0d09bcf9"
     }
    },
    "dc213134a34e4afbba379968c507d27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_412f3b6e6e8940308ab8d108f8ad2d31",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa70639d86a3430a9d42b35889600fdf",
      "value": 1000
     }
    },
    "dfe9ff8cc4de42ef8c81876c5869c205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e258ce9e8dd3427da51991741635c2be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2e6186a6bdf4898b6c2aaecd91dcca0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ef779a51f2642e3b29b5f99a4926724",
      "placeholder": "​",
      "style": "IPY_MODEL_b396c7d525a94e3daa639377f5a8747c",
      "value": " 442k/442k [00:00&lt;00:00, 25.6MB/s]"
     }
    },
    "e47fd10eefce4f04bfdd745e499a53bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07220bd5d9374cfb86bc3d935f61e3c2",
      "placeholder": "​",
      "style": "IPY_MODEL_156c1c0838e0439fa604616923cbf17c",
      "value": "Filter: 100%"
     }
    },
    "e661377a4a3344548dbc254e686d093a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2748356f1285432c9f5ff6517b3fef75",
       "IPY_MODEL_dc213134a34e4afbba379968c507d27a",
       "IPY_MODEL_18138eff2c1d45099ca92c0b8085ed8b"
      ],
      "layout": "IPY_MODEL_a9e6101dfe93483d8a4622f01e72d8b6"
     }
    },
    "e85964b9fce9460fbefb051b68b0b3b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e89d6959ed7a444992c43a7b2518f930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8a0f2f8c5d74ced9ffba971450c51e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9a33ff87d8b4a989a5767741ddd0ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb1d82a8695745569e2f44a4aed34e42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebd38b8bd46b4998a88818587318e79e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb29c53bf9949ef9135023ef1ebe9cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee154b555ffe4bf8979a830e282bd7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41567abf3eaf4de18808533ae4f09b13",
      "max": 2057395,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c7528e89a7f40a9913d9dfe253c323d",
      "value": 2057395
     }
    },
    "f0cf686dc0a748d79d35c04b10512018": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f142622223614832a2c86be61e7ef21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a353215523b4b228a791ae60f8c8ef6",
      "placeholder": "​",
      "style": "IPY_MODEL_e8a0f2f8c5d74ced9ffba971450c51e7",
      "value": "generation_config.json: 100%"
     }
    },
    "f18d866d2fb548da91665e35c8477cb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1edb1b0218a4a84a98a8962ace2aeeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2389500717747cc94b49d3ec1917d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ff1a125eef34ba18e2d46cfee1398e0",
      "placeholder": "​",
      "style": "IPY_MODEL_ecb29c53bf9949ef9135023ef1ebe9cc",
      "value": " 1000/1000 [00:00&lt;00:00, 20546.62 examples/s]"
     }
    },
    "f23c87fc18054e64adf130c8a6b36220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f37b9111d36840e3916d1587a1b52548": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f63062b8b9b94fc88a99829df2b471fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53630455dcc44a0a907800d718710082",
       "IPY_MODEL_23ad95fdeee4464d9513e96e015bce96",
       "IPY_MODEL_6967ad3dd572446089ff72ea632f3cb8"
      ],
      "layout": "IPY_MODEL_401c8c8ee6844e96aa40bced0b7c3ade"
     }
    },
    "f7f98e0f85f64a4b83d7c1d78cbb8bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8c101374a0644da8562b61f122c6a2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e83b90947114746b127dad09e2fccf0",
      "placeholder": "​",
      "style": "IPY_MODEL_85f7f1f4271c4621942065bc43ee39b6",
      "value": " 2.06M/2.06M [00:00&lt;00:00, 9.18MB/s]"
     }
    },
    "f8e42567b9344eb4abeb99efdb48e744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9aaecb343cd4b0f81bf4943087e6030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4513b7c4492e496094d51ef28737dd8c",
       "IPY_MODEL_82e75de342da494bb92b43c3b4dd57ae",
       "IPY_MODEL_6d29a8b0454948d5af6821a55b90832a"
      ],
      "layout": "IPY_MODEL_805d92625e0c425e9b2743adeb445e98"
     }
    },
    "fa70639d86a3430a9d42b35889600fdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa8c1e18c1f5459eaa7cfe037c5a6c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41b6677670b8452aad060f8a8627abe2",
       "IPY_MODEL_c6fc7e291f5d4a718e8c41ca8350f28b",
       "IPY_MODEL_fc4a248fab0d44278e4ae304b8f22ca0"
      ],
      "layout": "IPY_MODEL_a175fe7a3d1345acb87a1331c1e99da3"
     }
    },
    "fc4a248fab0d44278e4ae304b8f22ca0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d13aa41de87d4fc88c2f292105e1c5fc",
      "placeholder": "​",
      "style": "IPY_MODEL_6445cc51d9f148e8a3426eb886826491",
      "value": " 677/677 [00:00&lt;00:00, 39.0kB/s]"
     }
    },
    "fef6bb6f6f5b4ba09117ccf3846604e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff9906a7b9084238a6fd779101863267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
